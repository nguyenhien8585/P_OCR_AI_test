import streamlit as st
import requests
import base64
import io
import json
from PIL import Image, ImageDraw, ImageFilter, ImageEnhance
import fitz  # PyMuPDF
import tempfile
import os
import re
import time
import math

# Import python-docx
try:
    from docx import Document
    from docx.shared import Pt, RGBColor, Inches
    from docx.oxml import OxmlElement
    from docx.oxml.ns import qn
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False

try:
    import cv2
    import numpy as np
    from scipy import ndimage
    from skimage import filters, measure, morphology
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="PDF/LaTeX Converter - Content-Based Filter",
    page_icon="üìù",
    layout="wide"
)

# CSS c·∫£i ti·∫øn
st.markdown("""
<style>
    .main-header {
        text-align: center;
        color: #2E86AB;
        font-size: 2.5rem;
        margin-bottom: 2rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    
    .latex-output {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 1.5rem;
        border-radius: 12px;
        font-family: 'Consolas', 'Monaco', monospace;
        border-left: 4px solid #2E86AB;
        max-height: 400px;
        overflow-y: auto;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    
    .extracted-image {
        border: 3px solid #28a745;
        border-radius: 12px;
        margin: 15px 0;
        padding: 10px;
        background: linear-gradient(135deg, #f8f9fa 0%, #ffffff 100%);
        box-shadow: 0 6px 12px rgba(0,0,0,0.15);
        transition: transform 0.3s ease;
    }
    
    .extracted-image:hover {
        transform: translateY(-5px);
        box-shadow: 0 8px 16px rgba(0,0,0,0.2);
    }
    
    .debug-info {
        background: linear-gradient(135deg, #e3f2fd 0%, #f3e5f5 100%);
        padding: 1rem;
        border-radius: 8px;
        font-size: 0.85rem;
        margin-top: 8px;
        border-left: 3px solid #2196F3;
    }
    
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 12px;
        text-align: center;
        margin: 8px;
        box-shadow: 0 4px 8px rgba(0,0,0,0.15);
        transition: transform 0.2s ease;
    }
    
    .metric-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 12px rgba(0,0,0,0.2);
    }
    
    .figure-preview {
        border: 2px solid #007bff;
        border-radius: 8px;
        padding: 8px;
        margin: 8px 0;
        background: white;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    .figure-info {
        background: linear-gradient(135deg, #fff3cd 0%, #ffeaa7 100%);
        padding: 0.8rem;
        border-radius: 6px;
        margin: 5px 0;
        font-size: 0.85rem;
        border-left: 3px solid #ffc107;
    }
    
    .status-success {
        background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%);
        color: #155724;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #28a745;
        margin: 10px 0;
    }
    
    .status-warning {
        background: linear-gradient(135deg, #fff3cd 0%, #ffeaa7 100%);
        color: #856404;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #ffc107;
        margin: 10px 0;
    }
    
    .processing-container {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        padding: 2rem;
        border-radius: 12px;
        margin: 20px 0;
        border: 2px solid #dee2e6;
    }
</style>
""", unsafe_allow_html=True)

class ContentBasedFigureFilter:
    """
    B·ªô l·ªçc th√¥ng minh - Ph√¢n t√≠ch n·ªôi dung ƒë·ªÉ ƒë·∫øm s·ªë ·∫£nh minh h·ªça th·ª±c t·∫ø
    """
    
    def __init__(self):
        self.text_to_image_ratio_threshold = 0.6  # TƒÉng t·ª´ 0.3 l√™n 0.6
        self.min_visual_complexity = 0.2         # Gi·∫£m t·ª´ 0.4 xu·ªëng 0.2
        self.diagram_detection_threshold = 0.3   # Gi·∫£m t·ª´ 0.5 xu·ªëng 0.3
        self.enable_fallback = True              # B·∫≠t fallback mechanism
        self.min_estimated_count = 1             # T·ªëi thi·ªÉu 1 figure
        
    def analyze_content_and_filter(self, image_bytes, candidates):
        """
        Ph√¢n t√≠ch n·ªôi dung ·∫£nh v√† l·ªçc ra ƒë√∫ng s·ªë l∆∞·ª£ng figures th·ª±c t·∫ø - C·∫¢I TI·∫æN
        """
        if not CV2_AVAILABLE:
            return candidates
        
        try:
            # Ph√¢n t√≠ch ·∫£nh g·ªëc
            img_pil = Image.open(io.BytesIO(image_bytes)).convert("RGB")
            img = np.array(img_pil)
            h, w = img.shape[:2]
            
            # B∆∞·ªõc 1: ∆Ø·ªõc t√≠nh s·ªë l∆∞·ª£ng figures th·ª±c t·∫ø trong ·∫£nh
            estimated_figure_count = self._estimate_actual_figure_count(img)
            st.write(f"üìä ∆Ø·ªõc t√≠nh s·ªë figures th·ª±c t·∫ø: {estimated_figure_count}")
            
            # FALLBACK: N·∫øu kh√¥ng ∆∞·ªõc t√≠nh ƒë∆∞·ª£c, d√πng s·ªë l∆∞·ª£ng hi·ªán t·∫°i
            if estimated_figure_count == 0:
                estimated_figure_count = min(len(candidates), 5)
                st.write(f"üîÑ Fallback: S·ª≠ d·ª•ng {estimated_figure_count} figures")
            
            # B∆∞·ªõc 2: Ph√¢n t√≠ch t·ª´ng candidate
            analyzed_candidates = []
            for candidate in candidates:
                analysis = self._analyze_candidate_content(img, candidate)
                candidate.update(analysis)
                analyzed_candidates.append(candidate)
            
            # B∆∞·ªõc 3: L·ªçc theo content analysis - RELAXED
            filtered_candidates = self._filter_by_content_analysis_relaxed(analyzed_candidates)
            st.write(f"üìä Sau l·ªçc content (relaxed): {len(filtered_candidates)} candidates")
            
            # FALLBACK: N·∫øu l·ªçc qu√° √≠t, l·∫•y l·∫°i m·ªôt s·ªë candidates t·ªët nh·∫•t
            if len(filtered_candidates) < estimated_figure_count and self.enable_fallback:
                st.write("üîÑ Fallback: L·∫•y th√™m candidates do l·ªçc qu√° √≠t")
                # L·∫•y th√™m t·ª´ analyzed_candidates
                remaining = [c for c in analyzed_candidates if c not in filtered_candidates]
                remaining = sorted(remaining, key=lambda x: x.get('final_confidence', 0), reverse=True)
                needed = estimated_figure_count - len(filtered_candidates)
                filtered_candidates.extend(remaining[:needed])
                st.write(f"üìä Sau fallback: {len(filtered_candidates)} candidates")
            
            # B∆∞·ªõc 4: Gi·ªõi h·∫°n theo s·ªë l∆∞·ª£ng ∆∞·ªõc t√≠nh
            final_candidates = self._limit_by_estimated_count(filtered_candidates, estimated_figure_count)
            st.write(f"üìä Final: {len(final_candidates)} figures (d·ª± t√≠nh: {estimated_figure_count})")
            
            return final_candidates
            
        except Exception as e:
            st.error(f"‚ùå L·ªói content filter: {str(e)}")
            st.write("üîÑ Fallback: Tr·∫£ v·ªÅ candidates g·ªëc")
            return candidates  # Fallback v·ªÅ candidates g·ªëc
    
    def _estimate_actual_figure_count(self, img):
        """
        ∆Ø·ªõc t√≠nh s·ªë l∆∞·ª£ng figures th·ª±c t·∫ø trong ·∫£nh - C·∫¢I TI·∫æN RELAXED
        """
        try:
            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
            h, w = gray.shape
            
            # Ph∆∞∆°ng ph√°p 1: Ph√¢n t√≠ch layout structure
            layout_count = self._analyze_layout_structure(gray)
            
            # Ph∆∞∆°ng ph√°p 2: Ph√°t hi·ªán visual blocks
            visual_blocks = self._detect_visual_blocks(gray)
            
            # Ph∆∞∆°ng ph√°p 3: Ph√¢n t√≠ch text density
            text_regions = self._analyze_text_regions(gray)
            non_text_regions = self._estimate_non_text_regions(gray, text_regions)
            
            # Ph∆∞∆°ng ph√°p 4: Geometric analysis
            geometric_count = self._count_geometric_structures(gray)
            
            # K·∫øt h·ª£p c√°c ph∆∞∆°ng ph√°p - RELAXED
            method_results = [layout_count, visual_blocks, non_text_regions, geometric_count]
            
            # L·∫•y gi√° tr·ªã trung b√¨nh thay v√¨ min ƒë·ªÉ tr√°nh b·ªã qu√° strict
            estimated_count = max(1, int(sum(method_results) / len(method_results)))
            
            # ƒêi·ªÅu ch·ªânh d·ª±a tr√™n k√≠ch th∆∞·ªõc ·∫£nh
            if h * w > 2000000:  # ·∫¢nh l·ªõn
                estimated_count = min(estimated_count + 1, 10)  # TƒÉng limit
            elif h * w < 500000:  # ·∫¢nh nh·ªè
                estimated_count = max(estimated_count, 2)  # T·ªëi thi·ªÉu 2 thay v√¨ 1
            
            st.write(f"üîç Method results: layout={layout_count}, visual={visual_blocks}, text={non_text_regions}, geo={geometric_count}")
            
            return estimated_count
            
        except Exception as e:
            st.warning(f"‚ö†Ô∏è L·ªói estimate count: {str(e)}")
            return 3  # Fallback tƒÉng l√™n 3
    
    def _analyze_layout_structure(self, gray):
        """
        Ph√¢n t√≠ch c·∫•u tr√∫c layout ƒë·ªÉ ∆∞·ªõc t√≠nh s·ªë figures
        """
        # Ph√°t hi·ªán horizontal separators
        h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (gray.shape[1]//10, 1))
        h_lines = cv2.morphologyEx(gray, cv2.MORPH_OPEN, h_kernel)
        h_separators = len(cv2.findContours(h_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0])
        
        # Ph√°t hi·ªán vertical separators
        v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, gray.shape[0]//10))
        v_lines = cv2.morphologyEx(gray, cv2.MORPH_OPEN, v_kernel)
        v_separators = len(cv2.findContours(v_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0])
        
        # ∆Ø·ªõc t√≠nh d·ª±a tr√™n separators
        estimated = max(1, min(h_separators + 1, v_separators + 1, 6))
        return estimated
    
    def _detect_visual_blocks(self, gray):
        """
        Ph√°t hi·ªán c√°c visual blocks ƒë·ªôc l·∫≠p
        """
        # Threshold ƒë·ªÉ t·∫°o binary image
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # Morphological operations ƒë·ªÉ nh√≥m c√°c elements
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 20))
        closed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        
        # T√¨m connected components
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(closed)
        
        # L·ªçc components c√≥ k√≠ch th∆∞·ªõc h·ª£p l√Ω
        min_area = gray.shape[0] * gray.shape[1] * 0.01  # 1% c·ªßa ·∫£nh
        valid_blocks = 0
        
        for i in range(1, num_labels):  # B·ªè background
            area = stats[i, cv2.CC_STAT_AREA]
            if area > min_area:
                valid_blocks += 1
        
        return max(1, min(valid_blocks, 8))
    
    def _analyze_text_regions(self, gray):
        """
        Ph√¢n t√≠ch v√πng text ƒë·ªÉ lo·∫°i tr·ª´
        """
        # Ph√°t hi·ªán text patterns
        text_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 3))
        text_regions = cv2.morphologyEx(gray, cv2.MORPH_OPEN, text_kernel)
        
        # T√≠nh t·ª∑ l·ªá text
        text_pixels = np.sum(text_regions > 0)
        total_pixels = gray.shape[0] * gray.shape[1]
        text_ratio = text_pixels / total_pixels
        
        return text_ratio
    
    def _estimate_non_text_regions(self, gray, text_ratio):
        """
        ∆Ø·ªõc t√≠nh s·ªë v√πng kh√¥ng ph·∫£i text
        """
        if text_ratio > 0.7:  # Ch·ªß y·∫øu l√† text
            return 1
        elif text_ratio > 0.5:  # V·ª´a text v·ª´a figures
            return 2
        elif text_ratio > 0.3:  # √çt text, nhi·ªÅu figures
            return 3
        else:  # Ch·ªß y·∫øu l√† figures
            return 4
    
    def _count_geometric_structures(self, gray):
        """
        ƒê·∫øm s·ªë c·∫•u tr√∫c h√¨nh h·ªçc
        """
        # Edge detection
        edges = cv2.Canny(gray, 50, 150)
        
        # Ph√°t hi·ªán lines
        lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=50, minLineLength=30, maxLineGap=10)
        line_count = len(lines) if lines is not None else 0
        
        # Ph√°t hi·ªán circles
        circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, dp=1, minDist=30, param1=50, param2=30, minRadius=10, maxRadius=100)
        circle_count = len(circles[0]) if circles is not None else 0
        
        # Ph√°t hi·ªán contours ph·ª©c t·∫°p
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        complex_contours = 0
        
        for contour in contours:
            area = cv2.contourArea(contour)
            if area > 1000:  # Ch·ªâ ƒë·∫øm contours l·ªõn
                complex_contours += 1
        
        # K·∫øt h·ª£p ƒë·ªÉ ∆∞·ªõc t√≠nh
        geometric_score = (line_count // 10) + (circle_count * 2) + (complex_contours // 5)
        return max(1, min(geometric_score, 6))
    
    def _analyze_candidate_content(self, img, candidate):
        """
        Ph√¢n t√≠ch n·ªôi dung c·ªßa t·ª´ng candidate
        """
        x, y, w, h = candidate['bbox']
        roi = img[y:y+h, x:x+w]
        
        # Ph√¢n t√≠ch 1: Visual complexity
        visual_complexity = self._calculate_visual_complexity(roi)
        
        # Ph√¢n t√≠ch 2: Text density
        text_density = self._calculate_text_density(roi)
        
        # Ph√¢n t√≠ch 3: Diagram likelihood
        diagram_score = self._calculate_diagram_score(roi)
        
        # Ph√¢n t√≠ch 4: Figure quality
        figure_quality = self._calculate_figure_quality(roi)
        
        # Ph√¢n t√≠ch 5: Content type classification
        content_type = self._classify_content_type(roi, visual_complexity, text_density, diagram_score)
        
        return {
            'visual_complexity': visual_complexity,
            'text_density': text_density,
            'diagram_score': diagram_score,
            'figure_quality': figure_quality,
            'content_type': content_type,
            'is_likely_figure': content_type in ['diagram', 'chart', 'image', 'table']
        }
    
    def _calculate_visual_complexity(self, roi):
        """
        T√≠nh ƒë·ªô ph·ª©c t·∫°p visual
        """
        if roi.size == 0:
            return 0
        
        # Chuy·ªÉn sang grayscale
        gray = cv2.cvtColor(roi, cv2.COLOR_RGB2GRAY) if len(roi.shape) == 3 else roi
        
        # T√≠nh gradient
        grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
        
        # T√≠nh entropy
        hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
        hist = hist.ravel()
        hist = hist[hist > 0]
        entropy = -np.sum(hist * np.log2(hist + 1e-10))
        
        # K·∫øt h·ª£p
        complexity = (np.mean(gradient_magnitude) / 255.0) * 0.7 + (entropy / 8.0) * 0.3
        return min(1.0, complexity)
    
    def _calculate_text_density(self, roi):
        """
        T√≠nh m·∫≠t ƒë·ªô text
        """
        if roi.size == 0:
            return 1.0
        
        gray = cv2.cvtColor(roi, cv2.COLOR_RGB2GRAY) if len(roi.shape) == 3 else roi
        
        # Ph√°t hi·ªán text patterns
        text_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (max(1, roi.shape[1]//10), 1))
        text_regions = cv2.morphologyEx(gray, cv2.MORPH_OPEN, text_kernel)
        
        text_pixels = np.sum(text_regions > 0)
        total_pixels = gray.shape[0] * gray.shape[1]
        
        return text_pixels / total_pixels if total_pixels > 0 else 0
    
    def _calculate_diagram_score(self, roi):
        """
        T√≠nh ƒëi·ªÉm diagram likelihood
        """
        if roi.size == 0:
            return 0
        
        gray = cv2.cvtColor(roi, cv2.COLOR_RGB2GRAY) if len(roi.shape) == 3 else roi
        
        # Ph√°t hi·ªán lines
        edges = cv2.Canny(gray, 50, 150)
        lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=20, minLineLength=15, maxLineGap=5)
        line_score = len(lines) if lines is not None else 0
        
        # Ph√°t hi·ªán shapes
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        shape_score = len([c for c in contours if cv2.contourArea(c) > 100])
        
        # K·∫øt h·ª£p
        diagram_score = (line_score * 0.1 + shape_score * 0.2) / max(roi.shape[0], roi.shape[1])
        return min(1.0, diagram_score)
    
    def _calculate_figure_quality(self, roi):
        """
        T√≠nh ch·∫•t l∆∞·ª£ng figure
        """
        if roi.size == 0:
            return 0
        
        gray = cv2.cvtColor(roi, cv2.COLOR_RGB2GRAY) if len(roi.shape) == 3 else roi
        
        # T√≠nh sharpness
        laplacian = cv2.Laplacian(gray, cv2.CV_64F)
        sharpness = np.var(laplacian)
        
        # T√≠nh contrast
        contrast = np.std(gray)
        
        # T√≠nh resolution score
        resolution_score = min(1.0, (roi.shape[0] * roi.shape[1]) / 10000)
        
        # K·∫øt h·ª£p
        quality = (sharpness / 1000.0) * 0.4 + (contrast / 128.0) * 0.4 + resolution_score * 0.2
        return min(1.0, quality)
    
    def _classify_content_type(self, roi, visual_complexity, text_density, diagram_score):
        """
        Ph√¢n lo·∫°i lo·∫°i n·ªôi dung
        """
        if text_density > 0.6:
            return 'text'
        elif diagram_score > 0.5:
            return 'diagram'
        elif visual_complexity > 0.6 and text_density < 0.3:
            if diagram_score > 0.3:
                return 'chart'
            else:
                return 'image'
        elif visual_complexity > 0.4 and diagram_score > 0.2:
            return 'table'
        elif visual_complexity < 0.2:
            return 'noise'
        else:
            return 'mixed'
    
    def _filter_by_content_analysis_relaxed(self, candidates):
        """
        L·ªçc candidates d·ª±a tr√™n content analysis - RELAXED VERSION
        """
        filtered = []
        
        for candidate in candidates:
            # L·ªçc theo content type - RELAXED
            if not candidate.get('is_likely_figure', False):
                # N·∫øu kh√¥ng ph·∫£i figure, ki·ªÉm tra fallback conditions
                visual_complexity = candidate.get('visual_complexity', 0)
                text_density = candidate.get('text_density', 1)
                
                # N·∫øu c√≥ visual complexity cao ho·∫∑c text density th·∫•p, v·∫´n gi·ªØ l·∫°i
                if visual_complexity > 0.3 or text_density < 0.7:
                    st.write(f"üîÑ Fallback: Gi·ªØ l·∫°i candidate m·∫∑c d√π is_likely_figure=False")
                else:
                    continue
            
            # L·ªçc theo visual complexity - RELAXED
            if candidate.get('visual_complexity', 0) < self.min_visual_complexity:
                # N·∫øu visual complexity th·∫•p, ki·ªÉm tra c√≥ ph·∫£i diagram kh√¥ng
                if candidate.get('diagram_score', 0) < 0.2:
                    continue
                else:
                    st.write(f"üîÑ Gi·ªØ l·∫°i do c√≥ diagram score cao")
            
            # L·ªçc theo text density - RELAXED
            if candidate.get('text_density', 1) > self.text_to_image_ratio_threshold:
                # N·∫øu text density cao, ki·ªÉm tra c√≥ ph·∫£i table kh√¥ng
                if candidate.get('content_type') != 'table' and candidate.get('aspect_ratio', 1) < 1.5:
                    continue
                else:
                    st.write(f"üîÑ Gi·ªØ l·∫°i do c√≥ th·ªÉ l√† table")
            
            # L·ªçc theo figure quality - RELAXED
            if candidate.get('figure_quality', 0) < 0.1:  # Gi·∫£m t·ª´ 0.3 xu·ªëng 0.1
                continue
            
            # T√≠nh content score t·ªïng h·ª£p - RELAXED
            content_score = (
                candidate.get('visual_complexity', 0) * 0.25 +  # Gi·∫£m weight
                candidate.get('diagram_score', 0) * 0.25 +      # Gi·∫£m weight
                candidate.get('figure_quality', 0) * 0.25 +     # Gi·∫£m weight
                (1 - candidate.get('text_density', 1)) * 0.25   # Gi·∫£m weight
            )
            
            candidate['content_score'] = content_score
            
            # Threshold th·∫•p h∆°n
            if content_score > 0.2:  # Gi·∫£m t·ª´ 0.4 xu·ªëng 0.2
                filtered.append(candidate)
            else:
                st.write(f"üîÑ Lo·∫°i b·ªè candidate v·ªõi content_score={content_score:.2f}")
        
        return filtered
    
    def _filter_by_content_analysis(self, candidates):
        """
        L·ªçc candidates d·ª±a tr√™n content analysis - ORIGINAL VERSION
        """
        filtered = []
        
        for candidate in candidates:
            # L·ªçc theo content type
            if not candidate.get('is_likely_figure', False):
                continue
            
            # L·ªçc theo visual complexity
            if candidate.get('visual_complexity', 0) < self.min_visual_complexity:
                continue
            
            # L·ªçc theo text density
            if candidate.get('text_density', 1) > self.text_to_image_ratio_threshold:
                continue
            
            # L·ªçc theo figure quality
            if candidate.get('figure_quality', 0) < 0.3:
                continue
            
            # T√≠nh content score t·ªïng h·ª£p
            content_score = (
                candidate.get('visual_complexity', 0) * 0.3 +
                candidate.get('diagram_score', 0) * 0.3 +
                candidate.get('figure_quality', 0) * 0.2 +
                (1 - candidate.get('text_density', 1)) * 0.2
            )
            
            candidate['content_score'] = content_score
            
            if content_score > 0.4:
                filtered.append(candidate)
        
        return filtered
    
    def _limit_by_estimated_count(self, candidates, estimated_count):
        """
        Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng theo estimated count
        """
        if len(candidates) <= estimated_count:
            return candidates
        
        # S·∫Øp x·∫øp theo combined score
        for candidate in candidates:
            combined_score = (
                candidate.get('final_confidence', 0) * 0.4 +
                candidate.get('content_score', 0) * 0.6
            )
            candidate['combined_score'] = combined_score
        
        # S·∫Øp x·∫øp v√† l·∫•y top
        sorted_candidates = sorted(candidates, key=lambda x: x['combined_score'], reverse=True)
        
        return sorted_candidates[:estimated_count]

class SuperEnhancedImageExtractor:
    """
    Thu·∫≠t to√°n t√°ch ·∫£nh SI√äU C·∫¢I TI·∫æN - ƒê·∫£m b·∫£o c·∫Øt ƒë∆∞·ª£c ·∫£nh
    """
    
    def __init__(self):
        # Tham s·ªë si√™u relaxed ƒë·ªÉ t√°ch ƒë∆∞·ª£c nhi·ªÅu ·∫£nh
        self.min_area_ratio = 0.0008      # 0.08% di·ªán t√≠ch
        self.min_area_abs = 400           # 400 pixels
        self.min_width = 25               # 25 pixels
        self.min_height = 25              # 25 pixels
        self.max_figures = 30             # T·ªëi ƒëa 30 ·∫£nh
        self.max_area_ratio = 0.80        # T·ªëi ƒëa 80% di·ªán t√≠ch
        
        # Tham s·ªë c·∫Øt ·∫£nh
        self.smart_padding = 30           # Padding l·ªõn h∆°n
        self.quality_threshold = 0.15     # Ng∆∞·ª°ng ch·∫•t l∆∞·ª£ng C·ª∞C TH·∫§P
        self.edge_margin = 0.005          # Margin t·ª´ r√¨a C·ª∞C NH·ªé
        
        # Tham s·ªë ph√¢n t√≠ch
        self.text_ratio_threshold = 0.8   # Ng∆∞·ª°ng t·ª∑ l·ªá text cao
        self.line_density_threshold = 0.01 # Ng∆∞·ª°ng m·∫≠t ƒë·ªô line C·ª∞C TH·∫§P
        self.confidence_threshold = 20    # Ng∆∞·ª°ng confidence C·ª∞C TH·∫§P
        
        # Tham s·ªë morphology nh·∫π
        self.morph_kernel_size = 2
        self.dilate_iterations = 1
        self.erode_iterations = 1
        
        # Tham s·ªë m·ªõi cho edge detection
        self.canny_low = 30
        self.canny_high = 80
        self.blur_kernel = 3
        
        # Kh·ªüi t·∫°o Content-Based Filter
        self.content_filter = ContentBasedFigureFilter()
        self.enable_content_filter = True
    
    def extract_figures_and_tables(self, image_bytes):
        """
        T√°ch ·∫£nh v·ªõi thu·∫≠t to√°n SI√äU C·∫¢I TI·∫æN + Content-Based Filter
        """
        if not CV2_AVAILABLE:
            st.error("‚ùå OpenCV kh√¥ng c√≥ s·∫µn! C·∫ßn c√†i ƒë·∫∑t: pip install opencv-python")
            return [], 0, 0
        
        try:
            # ƒê·ªçc ·∫£nh
            img_pil = Image.open(io.BytesIO(image_bytes)).convert("RGB")
            img = np.array(img_pil)
            h, w = img.shape[:2]
            
            st.write(f"üîç Ph√¢n t√≠ch ·∫£nh k√≠ch th∆∞·ªõc: {w}x{h}")
            
            # Ti·ªÅn x·ª≠ l√Ω
            enhanced_img = self._super_enhance_image(img)
            
            # T√°ch ·∫£nh b·∫±ng nhi·ªÅu ph∆∞∆°ng ph√°p
            all_candidates = []
            
            # Ph∆∞∆°ng ph√°p 1: Edge-based
            edge_candidates = self._detect_by_edges(enhanced_img, w, h)
            all_candidates.extend(edge_candidates)
            st.write(f"   üìç Edge detection: {len(edge_candidates)} candidates")
            
            # Ph∆∞∆°ng ph√°p 2: Contour-based
            contour_candidates = self._detect_by_contours(enhanced_img, w, h)
            all_candidates.extend(contour_candidates)
            st.write(f"   üìç Contour detection: {len(contour_candidates)} candidates")
            
            # Ph∆∞∆°ng ph√°p 3: Grid-based
            grid_candidates = self._detect_by_grid(enhanced_img, w, h)
            all_candidates.extend(grid_candidates)
            st.write(f"   üìç Grid detection: {len(grid_candidates)} candidates")
            
            # Ph∆∞∆°ng ph√°p 4: Blob detection
            blob_candidates = self._detect_by_blobs(enhanced_img, w, h)
            all_candidates.extend(blob_candidates)
            st.write(f"   üìç Blob detection: {len(blob_candidates)} candidates")
            
            st.write(f"üìä T·ªïng candidates tr∆∞·ªõc l·ªçc: {len(all_candidates)}")
            
            # L·ªçc v√† merge
            filtered_candidates = self._filter_and_merge_candidates(all_candidates, w, h)
            st.write(f"üìä Sau l·ªçc v√† merge: {len(filtered_candidates)}")
            
            # B∆Ø·ªöC M·ªöI: Content-Based Filter
            if self.enable_content_filter:
                st.write("üß† ƒêang ph√¢n t√≠ch n·ªôi dung v√† l·ªçc theo s·ªë l∆∞·ª£ng th·ª±c t·∫ø...")
                content_filtered = self.content_filter.analyze_content_and_filter(image_bytes, filtered_candidates)
                st.write(f"üìä Sau content filter: {len(content_filtered)} figures")
                
                # Hi·ªÉn th·ªã th√¥ng tin content analysis
                if content_filtered:
                    st.write("üìã Content Analysis Results:")
                    for i, candidate in enumerate(content_filtered):
                        content_type = candidate.get('content_type', 'unknown')
                        content_score = candidate.get('content_score', 0)
                        visual_complexity = candidate.get('visual_complexity', 0)
                        text_density = candidate.get('text_density', 0)
                        
                        st.write(f"   {i+1}. Type: {content_type}, Score: {content_score:.2f}, "
                                f"Visual: {visual_complexity:.2f}, Text: {text_density:.2f}")
                
                filtered_candidates = content_filtered
            
            # T·∫°o final figures
            final_figures = self._create_final_figures_enhanced(filtered_candidates, img, w, h)
            
            # Th√¥ng b√°o k·∫øt qu·∫£
            if self.enable_content_filter:
                st.success(f"‚úÖ ƒê√£ t√°ch {len(final_figures)} figures (ph√¢n t√≠ch n·ªôi dung)")
                st.write("üí° Content filter ƒë√£ l·ªçc ra ƒë√∫ng s·ªë l∆∞·ª£ng ·∫£nh minh h·ªça th·ª±c t·∫ø")
            else:
                st.write(f"‚úÖ Final figures: {len(final_figures)}")
            
            return final_figures, h, w
            
        except Exception as e:
            st.error(f"‚ùå L·ªói trong qu√° tr√¨nh t√°ch ·∫£nh: {str(e)}")
            return [], 0, 0
    
    def _super_enhance_image(self, img):
        """
        Ti·ªÅn x·ª≠ l√Ω ·∫£nh
        """
        # Chuy·ªÉn sang grayscale
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        
        # Blur nh·∫π
        blurred = cv2.GaussianBlur(gray, (self.blur_kernel, self.blur_kernel), 0)
        
        # TƒÉng c∆∞·ªùng contrast
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(blurred)
        
        # Normalize
        normalized = cv2.normalize(enhanced, None, 0, 255, cv2.NORM_MINMAX)
        
        return normalized
    
    def _detect_by_edges(self, gray_img, w, h):
        """
        Ph√°t hi·ªán b·∫±ng edge detection
        """
        edges = cv2.Canny(gray_img, self.canny_low, self.canny_high)
        
        # Dilate ƒë·ªÉ n·ªëi c√°c edge
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        edges_dilated = cv2.dilate(edges, kernel, iterations=1)
        
        # T√¨m contours
        contours, _ = cv2.findContours(edges_dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        candidates = []
        for cnt in contours:
            x, y, ww, hh = cv2.boundingRect(cnt)
            area = ww * hh
            
            if self._is_valid_candidate(x, y, ww, hh, area, w, h):
                candidates.append({
                    'bbox': (x, y, ww, hh),
                    'area': area,
                    'method': 'edge',
                    'confidence': 30
                })
        
        return candidates
    
    def _detect_by_contours(self, gray_img, w, h):
        """
        Ph√°t hi·ªán b·∫±ng contour analysis
        """
        # Threshold v·ªõi Otsu
        _, binary = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # Morphological operations
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (self.morph_kernel_size, self.morph_kernel_size))
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        
        # T√¨m contours
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        candidates = []
        for cnt in contours:
            x, y, ww, hh = cv2.boundingRect(cnt)
            area = ww * hh
            
            if self._is_valid_candidate(x, y, ww, hh, area, w, h):
                candidates.append({
                    'bbox': (x, y, ww, hh),
                    'area': area,
                    'method': 'contour',
                    'confidence': 40
                })
        
        return candidates
    
    def _detect_by_grid(self, gray_img, w, h):
        """
        Ph√°t hi·ªán tables b·∫±ng grid analysis
        """
        # Horizontal lines
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (w//20, 1))
        horizontal_lines = cv2.morphologyEx(gray_img, cv2.MORPH_OPEN, horizontal_kernel)
        
        # Vertical lines
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, h//20))
        vertical_lines = cv2.morphologyEx(gray_img, cv2.MORPH_OPEN, vertical_kernel)
        
        # Combine lines
        grid_mask = cv2.bitwise_or(horizontal_lines, vertical_lines)
        
        # Dilate ƒë·ªÉ t·∫°o regions
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
        grid_dilated = cv2.dilate(grid_mask, kernel, iterations=2)
        
        # T√¨m contours
        contours, _ = cv2.findContours(grid_dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        candidates = []
        for cnt in contours:
            x, y, ww, hh = cv2.boundingRect(cnt)
            area = ww * hh
            
            if self._is_valid_candidate(x, y, ww, hh, area, w, h):
                aspect_ratio = ww / (hh + 1e-6)
                confidence = 50 if aspect_ratio > 1.5 else 30
                
                candidates.append({
                    'bbox': (x, y, ww, hh),
                    'area': area,
                    'method': 'grid',
                    'confidence': confidence,
                    'is_table': aspect_ratio > 1.5
                })
        
        return candidates
    
    def _detect_by_blobs(self, gray_img, w, h):
        """
        Ph√°t hi·ªán b·∫±ng blob detection
        """
        # Threshold adaptively
        adaptive_thresh = cv2.adaptiveThreshold(
            gray_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
        )
        
        # Invert
        inverted = cv2.bitwise_not(adaptive_thresh)
        
        # Morphological operations
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        opened = cv2.morphologyEx(inverted, cv2.MORPH_OPEN, kernel)
        
        # T√¨m contours
        contours, _ = cv2.findContours(opened, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        candidates = []
        for cnt in contours:
            x, y, ww, hh = cv2.boundingRect(cnt)
            area = ww * hh
            
            if self._is_valid_candidate(x, y, ww, hh, area, w, h):
                candidates.append({
                    'bbox': (x, y, ww, hh),
                    'area': area,
                    'method': 'blob',
                    'confidence': 35
                })
        
        return candidates
    
    def _is_valid_candidate(self, x, y, ww, hh, area, img_w, img_h):
        """
        Ki·ªÉm tra candidate c√≥ h·ª£p l·ªá kh√¥ng
        """
        area_ratio = area / (img_w * img_h)
        
        # ƒêi·ªÅu ki·ªán c∆° b·∫£n
        if (area < self.min_area_abs or 
            area_ratio < self.min_area_ratio or 
            area_ratio > self.max_area_ratio or
            ww < self.min_width or 
            hh < self.min_height):
            return False
        
        # Ki·ªÉm tra v·ªã tr√≠
        if (x < self.edge_margin * img_w or 
            y < self.edge_margin * img_h or 
            (x + ww) > (1 - self.edge_margin) * img_w or 
            (y + hh) > (1 - self.edge_margin) * img_h):
            return False
        
        return True
    
    def _filter_and_merge_candidates(self, candidates, w, h):
        """
        L·ªçc v√† merge candidates
        """
        if not candidates:
            return []
        
        # S·∫Øp x·∫øp theo area gi·∫£m d·∫ßn
        candidates = sorted(candidates, key=lambda x: x['area'], reverse=True)
        
        # Lo·∫°i b·ªè overlap
        filtered = []
        for candidate in candidates:
            if not self._is_overlapping_with_list(candidate, filtered):
                # T√≠nh confidence t·ªïng h·ª£p
                candidate['final_confidence'] = self._calculate_final_confidence(candidate, w, h)
                if candidate['final_confidence'] >= self.confidence_threshold:
                    filtered.append(candidate)
        
        # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng
        return filtered[:self.max_figures]
    
    def _is_overlapping_with_list(self, candidate, existing_list):
        """
        Ki·ªÉm tra overlap v·ªõi danh s√°ch existing
        """
        x1, y1, w1, h1 = candidate['bbox']
        
        for existing in existing_list:
            x2, y2, w2, h2 = existing['bbox']
            
            # T√≠nh IoU
            intersection_area = max(0, min(x1+w1, x2+w2) - max(x1, x2)) * max(0, min(y1+h1, y2+h2) - max(y1, y2))
            union_area = w1*h1 + w2*h2 - intersection_area
            
            if union_area > 0:
                iou = intersection_area / union_area
                if iou > 0.25:
                    return True
        
        return False
    
    def _calculate_final_confidence(self, candidate, w, h):
        """
        T√≠nh confidence cu·ªëi c√πng
        """
        x, y, ww, hh = candidate['bbox']
        area_ratio = candidate['area'] / (w * h)
        aspect_ratio = ww / (hh + 1e-6)
        
        confidence = candidate.get('confidence', 30)
        
        # Bonus cho size ph√π h·ª£p
        if 0.01 < area_ratio < 0.3:
            confidence += 20
        elif 0.005 < area_ratio < 0.5:
            confidence += 10
        
        # Bonus cho aspect ratio
        if 0.5 < aspect_ratio < 3.0:
            confidence += 15
        elif 0.3 < aspect_ratio < 5.0:
            confidence += 5
        
        # Bonus cho method
        if candidate['method'] == 'grid':
            confidence += 10
        elif candidate['method'] == 'edge':
            confidence += 5
        
        return min(100, confidence)
    
    def _create_final_figures_enhanced(self, candidates, img, w, h):
        """
        T·∫°o final figures v·ªõi c·∫Øt ·∫£nh c·∫£i ti·∫øn
        """
        # S·∫Øp x·∫øp theo v·ªã tr√≠
        candidates = sorted(candidates, key=lambda x: (x['bbox'][1], x['bbox'][0]))
        
        final_figures = []
        img_idx = 0
        table_idx = 0
        
        for candidate in candidates:
            # C·∫Øt ·∫£nh v·ªõi smart padding
            cropped_img = self._smart_crop_enhanced(img, candidate, w, h)
            
            if cropped_img is None:
                continue
            
            # Chuy·ªÉn th√†nh base64
            buf = io.BytesIO()
            Image.fromarray(cropped_img).save(buf, format="JPEG", quality=95)
            b64 = base64.b64encode(buf.getvalue()).decode()
            
            # X√°c ƒë·ªãnh lo·∫°i v√† t√™n
            is_table = candidate.get('is_table', False) or candidate.get('method') == 'grid'
            
            if is_table:
                name = f"table-{table_idx+1}.jpeg"
                table_idx += 1
            else:
                name = f"figure-{img_idx+1}.jpeg"
                img_idx += 1
            
            final_figures.append({
                "name": name,
                "base64": b64,
                "is_table": is_table,
                "bbox": candidate["bbox"],
                "confidence": candidate["final_confidence"],
                "area_ratio": candidate["area"] / (w * h),
                "aspect_ratio": candidate["bbox"][2] / (candidate["bbox"][3] + 1e-6),
                "method": candidate["method"],
                "center_y": candidate["bbox"][1] + candidate["bbox"][3] // 2,
                "center_x": candidate["bbox"][0] + candidate["bbox"][2] // 2
            })
        
        return final_figures
    
    def _smart_crop_enhanced(self, img, candidate, img_w, img_h):
        """
        C·∫Øt ·∫£nh th√¥ng minh c·∫£i ti·∫øn
        """
        x, y, w, h = candidate['bbox']
        
        # T√≠nh padding th√¥ng minh
        padding_x = min(self.smart_padding, w // 4)
        padding_y = min(self.smart_padding, h // 4)
        
        # ƒêi·ªÅu ch·ªânh boundaries
        x0 = max(0, x - padding_x)
        y0 = max(0, y - padding_y)
        x1 = min(img_w, x + w + padding_x)
        y1 = min(img_h, y + h + padding_y)
        
        # C·∫Øt ·∫£nh
        cropped = img[y0:y1, x0:x1]
        
        if cropped.size == 0:
            return None
        
        # L√†m s·∫°ch v√† tƒÉng c∆∞·ªùng
        cleaned = self._clean_and_enhance_cropped(cropped)
        
        return cleaned
    
    def _clean_and_enhance_cropped(self, cropped_img):
        """
        L√†m s·∫°ch v√† tƒÉng c∆∞·ªùng ·∫£nh ƒë√£ c·∫Øt
        """
        # Chuy·ªÉn sang PIL
        pil_img = Image.fromarray(cropped_img)
        
        # TƒÉng c∆∞·ªùng contrast nh·∫π
        enhancer = ImageEnhance.Contrast(pil_img)
        enhanced = enhancer.enhance(1.1)
        
        # Sharpen nh·∫π
        sharpened = enhanced.filter(ImageFilter.UnsharpMask(radius=0.5, percent=100, threshold=2))
        
        return np.array(sharpened)
    
    def create_beautiful_debug_visualization(self, image_bytes, figures):
        """
        T·∫°o debug visualization ƒê·∫∏P
        """
        img_pil = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        draw = ImageDraw.Draw(img_pil)
        
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7', '#DDA0DD', '#98D8C8', '#F7DC6F']
        
        for i, fig in enumerate(figures):
            color = colors[i % len(colors)]
            x, y, w, h = fig['bbox']
            
            # V·∫Ω bounding box v·ªõi style ƒë·∫πp
            draw.rectangle([x, y, x+w, y+h], outline=color, width=4)
            
            # V·∫Ω corner markers
            corner_size = 10
            draw.rectangle([x, y, x+corner_size, y+corner_size], fill=color)
            draw.rectangle([x+w-corner_size, y, x+w, y+corner_size], fill=color)
            draw.rectangle([x, y+h-corner_size, x+corner_size, y+h], fill=color)
            draw.rectangle([x+w-corner_size, y+h-corner_size, x+w, y+h], fill=color)
            
            # V·∫Ω center point
            center_x, center_y = fig['center_x'], fig['center_y']
            draw.ellipse([center_x-8, center_y-8, center_x+8, center_y+8], fill=color, outline='white', width=2)
            
            # Label v·ªõi background ƒë·∫πp
            label_lines = [
                f"üì∑ {fig['name']}",
                f"{'üìä' if fig['is_table'] else 'üñºÔ∏è'} {fig['confidence']:.0f}%",
                f"üìè {fig['aspect_ratio']:.2f}",
                f"üìê {fig['area_ratio']:.3f}",
                f"‚öôÔ∏è {fig['method']}"
            ]
            
            # T√≠nh k√≠ch th∆∞·ªõc label
            text_height = len(label_lines) * 18
            text_width = max(len(line) for line in label_lines) * 10
            
            # V·∫Ω background
            label_x = x
            label_y = y - text_height - 10
            if label_y < 0:
                label_y = y + h + 10
            
            # Background v·ªõi alpha
            overlay = Image.new('RGBA', img_pil.size, (0, 0, 0, 0))
            overlay_draw = ImageDraw.Draw(overlay)
            
            try:
                overlay_draw.rounded_rectangle(
                    [label_x, label_y, label_x + text_width, label_y + text_height],
                    radius=8, fill=(*tuple(int(color.lstrip('#')[i:i+2], 16) for i in (0, 2, 4)), 200)
                )
            except:
                # Fallback n·∫øu rounded_rectangle kh√¥ng c√≥
                overlay_draw.rectangle(
                    [label_x, label_y, label_x + text_width, label_y + text_height],
                    fill=(*tuple(int(color.lstrip('#')[i:i+2], 16) for i in (0, 2, 4)), 200)
                )
            
            img_pil = Image.alpha_composite(img_pil.convert('RGBA'), overlay).convert('RGB')
            draw = ImageDraw.Draw(img_pil)
            
            # V·∫Ω text
            for j, line in enumerate(label_lines):
                draw.text((label_x + 5, label_y + j * 16), line, fill='white', stroke_width=1, stroke_fill='black')
        
        return img_pil
    
    def insert_figures_into_text_precisely(self, text, figures, img_h, img_w):
        """
        Ch√®n ·∫£nh v√†o vƒÉn b·∫£n v·ªõi ƒë·ªô ch√≠nh x√°c cao - C·∫¢I TI·∫æN
        """
        if not figures:
            return text
        
        lines = text.split('\n')
        
        # S·∫Øp x·∫øp figures theo v·ªã tr√≠ Y
        sorted_figures = sorted(figures, key=lambda f: f['center_y'])
        
        result_lines = lines[:]
        offset = 0
        
        # Debug info
        st.write(f"üîç Ch√®n {len(sorted_figures)} figures v√†o text ({len(lines)} d√≤ng)")
        
        # Chi·∫øn l∆∞·ª£c ch√®n c·∫£i ti·∫øn
        for i, figure in enumerate(sorted_figures):
            # T√≠nh v·ªã tr√≠ ch√®n
            insertion_line = self._calculate_insertion_position(figure, lines, i, len(sorted_figures))
            
            # ƒêi·ªÅu ch·ªânh v·ªõi offset
            actual_insertion = insertion_line + offset
            
            # ƒê·∫£m b·∫£o kh√¥ng v∆∞·ª£t qu√°
            if actual_insertion > len(result_lines):
                actual_insertion = len(result_lines)
            
            # T·∫°o tag ƒë·∫πp - C·∫¢I TI·∫æN format
            if figure['is_table']:
                tag = f"[üìä B·∫¢NG: {figure['name']}]"
                debug_tag = f"<!-- Table: {figure['name']}, Confidence: {figure['confidence']:.1f}%, Method: {figure['method']} -->"
            else:
                tag = f"[üñºÔ∏è H√åNH: {figure['name']}]"
                debug_tag = f"<!-- Figure: {figure['name']}, Confidence: {figure['confidence']:.1f}%, Method: {figure['method']} -->"
            
            # Ch√®n v·ªõi format ƒë·∫πp
            result_lines.insert(actual_insertion, "")
            result_lines.insert(actual_insertion + 1, tag)
            result_lines.insert(actual_insertion + 2, debug_tag)
            result_lines.insert(actual_insertion + 3, "")
            
            offset += 4
            
            # Debug info
            st.write(f"   {i+1}. {figure['name']} ‚Üí d√≤ng {actual_insertion + 1}")
        
        return '\n'.join(result_lines)
    
    def _calculate_insertion_position(self, figure, lines, fig_index, total_figures):
        """
        T√≠nh v·ªã tr√≠ ch√®n th√¥ng minh
        """
        # T√¨m c√¢u h·ªèi patterns
        question_lines = []
        for i, line in enumerate(lines):
            if re.match(r'^(c√¢u|b√†i|question)\s*\d+', line.strip().lower()):
                question_lines.append(i)
        
        # N·∫øu c√≥ c√¢u h·ªèi, ch√®n sau c√¢u h·ªèi
        if question_lines:
            if fig_index < len(question_lines):
                return question_lines[fig_index] + 1
            else:
                # Ch√®n sau c√¢u h·ªèi cu·ªëi
                return question_lines[-1] + 2
        
        # Fallback: ch√®n ƒë·ªÅu
        section_size = len(lines) // (total_figures + 1)
        return min(section_size * (fig_index + 1), len(lines) - 1)

class GeminiAPI:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"
    
    def encode_image(self, image_data: bytes) -> str:
        return base64.b64encode(image_data).decode('utf-8')
    
    def convert_to_latex(self, content_data: bytes, content_type: str, prompt: str) -> str:
        headers = {"Content-Type": "application/json"}
        
        if content_type.startswith('image/'):
            mime_type = content_type
        else:
            mime_type = "image/png"
        
        encoded_content = self.encode_image(content_data)
        
        payload = {
            "contents": [
                {
                    "parts": [
                        {"text": prompt},
                        {
                            "inline_data": {
                                "mime_type": mime_type,
                                "data": encoded_content
                            }
                        }
                    ]
                }
            ],
            "generationConfig": {
                "temperature": 0.1,
                "topK": 1,
                "topP": 0.8,
                "maxOutputTokens": 8192,
            }
        }
        
        try:
            response = requests.post(
                f"{self.base_url}?key={self.api_key}",
                headers=headers,
                json=payload,
                timeout=90
            )
            
            if response.status_code == 200:
                result = response.json()
                if 'candidates' in result and len(result['candidates']) > 0:
                    content = result['candidates'][0]['content']['parts'][0]['text']
                    return content.strip()
                else:
                    raise Exception("API kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£ h·ª£p l·ªá")
            elif response.status_code == 401:
                raise Exception("API key kh√¥ng h·ª£p l·ªá ho·∫∑c ƒë√£ h·∫øt h·∫°n")
            elif response.status_code == 429:
                raise Exception("ƒê√£ v∆∞·ª£t qu√° gi·ªõi h·∫°n rate limit")
            else:
                raise Exception(f"API Error {response.status_code}: {response.text}")
        
        except requests.exceptions.Timeout:
            raise Exception("Request timeout - th·ª≠ l·∫°i sau √≠t ph√∫t")
        except requests.exceptions.ConnectionError:
            raise Exception("L·ªói k·∫øt n·ªëi m·∫°ng")
        except Exception as e:
            raise Exception(str(e))

class PDFProcessor:
    @staticmethod
    def extract_images_and_text(pdf_file):
        pdf_document = fitz.open(stream=pdf_file.read(), filetype="pdf")
        images = []
        
        for page_num in range(pdf_document.page_count):
            page = pdf_document[page_num]
            mat = fitz.Matrix(3.5, 3.5)
            pix = page.get_pixmap(matrix=mat)
            img_data = pix.tobytes("png")
            img = Image.open(io.BytesIO(img_data))
            images.append((img, page_num + 1))
        
        pdf_document.close()
        return images

class EnhancedWordExporter:
    """
    Xu·∫•t Word document v·ªõi LaTeX v√† h√¨nh ·∫£nh - ƒê√É FIX L·ªñI
    """
    
    @staticmethod
    def create_word_document(latex_content: str, extracted_figures=None, images=None) -> io.BytesIO:
        try:
            # T·∫°o document m·ªõi
            doc = Document()
            
            # C·∫•u h√¨nh font v√† style
            style = doc.styles['Normal']
            style.font.name = 'Times New Roman'
            style.font.size = Pt(12)
            
            # KH√îNG th√™m ti√™u ƒë·ªÅ metadata - B·ªé PH·∫¶N N√ÄY
            # Ch·ªâ th√™m ti√™u ƒë·ªÅ ƒë∆°n gi·∫£n n·∫øu c·∫ßn
            # title_para = doc.add_heading('T√†i li·ªáu LaTeX ƒë√£ chuy·ªÉn ƒë·ªïi', 0)
            # title_para.alignment = 1
            
            # B·ªé PH·∫¶N metadata info
            # info_para = doc.add_paragraph()
            # info_para.alignment = 1
            # info_run = info_para.add_run(...)
            
            # Debug info (ch·ªâ hi·ªÉn th·ªã trong console, kh√¥ng in ra)
            st.write(f"üîç X·ª≠ l√Ω Word document v·ªõi {len(extracted_figures) if extracted_figures else 0} figures")
            if extracted_figures:
                st.write("üìä Danh s√°ch figures:")
                for i, fig in enumerate(extracted_figures):
                    st.write(f"   {i+1}. {fig['name']} (confidence: {fig['confidence']:.1f}%)")
            
            # X·ª≠ l√Ω n·ªôi dung LaTeX
            lines = latex_content.split('\n')
            current_paragraph = None
            
            for line_num, line in enumerate(lines):
                original_line = line
                line = line.strip()
                
                # Debug: hi·ªÉn th·ªã line ƒëang x·ª≠ l√Ω
                if line.startswith('[') and (('H√åNH:' in line) or ('B·∫¢NG:' in line)):
                    st.write(f"üîç Processing line {line_num}: {line}")
                
                # B·ªè qua c√°c d√≤ng tr·ªëng
                if not line:
                    continue
                
                # B·ªé QUA comment trang v√† debug comments
                if line.startswith('<!--'):
                    continue
                
                # B·ªé QUA c√°c d√≤ng ```latex
                if line.startswith('```'):
                    continue
                
                # X·ª≠ l√Ω tags h√¨nh ·∫£nh - C·∫¢I TI·∫æN
                if line.startswith('[') and line.endswith(']'):
                    if 'H√åNH:' in line or 'B·∫¢NG:' in line:
                        st.write(f"üéØ T√¨m th·∫•y figure tag: {line}")
                        EnhancedWordExporter._insert_figure_to_word(doc, line, extracted_figures, clean_mode=True)
                        continue
                
                # X·ª≠ l√Ω c√¢u h·ªèi
                if re.match(r'^(c√¢u|b√†i)\s+\d+', line.lower()):
                    current_paragraph = doc.add_heading(line, level=3)
                    current_paragraph.alignment = 0
                    continue
                
                # X·ª≠ l√Ω paragraph th∆∞·ªùng
                if line:
                    para = doc.add_paragraph()
                    EnhancedWordExporter._process_latex_content(para, line)
                    current_paragraph = para
            
            # B·ªé PH·∫¶N appendix v·ªõi th√¥ng tin figures
            # if extracted_figures:
            #     EnhancedWordExporter._add_figures_appendix(doc, extracted_figures)
            
            # B·ªé PH·∫¶N ·∫£nh g·ªëc
            # if images and not extracted_figures:
            #     EnhancedWordExporter._add_original_images(doc, images)
            
            # L∆∞u v√†o buffer
            buffer = io.BytesIO()
            doc.save(buffer)
            buffer.seek(0)
            
            st.success("‚úÖ Word document (clean version) ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
            return buffer
            
        except Exception as e:
            st.error(f"‚ùå L·ªói t·∫°o Word document: {str(e)}")
            raise e
    
    @staticmethod
    def create_word_document_full(latex_content: str, extracted_figures=None, images=None) -> io.BytesIO:
        """
        T·∫°o Word document FULL VERSION v·ªõi metadata v√† appendix
        """
        try:
            # T·∫°o document m·ªõi
            doc = Document()
            
            # C·∫•u h√¨nh font v√† style
            style = doc.styles['Normal']
            style.font.name = 'Times New Roman'
            style.font.size = Pt(12)
            
            # Th√™m ti√™u ƒë·ªÅ
            title_para = doc.add_heading('T√†i li·ªáu LaTeX ƒë√£ chuy·ªÉn ƒë·ªïi', 0)
            title_para.alignment = 1
            
            # Th√¥ng tin metadata
            info_para = doc.add_paragraph()
            info_para.alignment = 1
            info_run = info_para.add_run(
                f"ƒê∆∞·ª£c t·∫°o b·ªüi Enhanced PDF/LaTeX Converter\n"
                f"Th·ªùi gian: {time.strftime('%Y-%m-%d %H:%M:%S')}\n"
                f"Figures: {len(extracted_figures) if extracted_figures else 0}"
            )
            info_run.font.size = Pt(10)
            info_run.font.color.rgb = RGBColor(128, 128, 128)
            
            # Th√™m line break
            doc.add_paragraph("")
            
            # X·ª≠ l√Ω n·ªôi dung LaTeX
            lines = latex_content.split('\n')
            current_paragraph = None
            
            for line_num, line in enumerate(lines):
                original_line = line
                line = line.strip()
                
                # B·ªè qua c√°c d√≤ng tr·ªëng
                if not line:
                    continue
                
                # X·ª≠ l√Ω comment trang
                if line.startswith('<!--'):
                    if ('Trang' in line or 'Page' in line) and not ('Figure:' in line or 'Table:' in line):
                        # Th√™m page break cho trang m·ªõi
                        if current_paragraph:
                            doc.add_page_break()
                        heading = doc.add_heading(line.replace('<!--', '').replace('-->', '').strip(), level=2)
                        heading.alignment = 1
                    continue
                
                # B·ªé QUA c√°c d√≤ng ```latex
                if line.startswith('```'):
                    continue
                
                # X·ª≠ l√Ω tags h√¨nh ·∫£nh
                if line.startswith('[') and line.endswith(']'):
                    if 'H√åNH:' in line or 'B·∫¢NG:' in line:
                        EnhancedWordExporter._insert_figure_to_word(doc, line, extracted_figures, clean_mode=False)
                        continue
                
                # X·ª≠ l√Ω c√¢u h·ªèi
                if re.match(r'^(c√¢u|b√†i)\s+\d+', line.lower()):
                    current_paragraph = doc.add_heading(line, level=3)
                    current_paragraph.alignment = 0
                    continue
                
                # X·ª≠ l√Ω paragraph th∆∞·ªùng
                if line:
                    para = doc.add_paragraph()
                    EnhancedWordExporter._process_latex_content(para, line)
                    current_paragraph = para
            
            # Th√™m appendix n·∫øu c√≥ figures
            if extracted_figures:
                EnhancedWordExporter._add_figures_appendix(doc, extracted_figures)
            
            # Th√™m ·∫£nh g·ªëc n·∫øu kh√¥ng c√≥ extracted figures
            if images and not extracted_figures:
                EnhancedWordExporter._add_original_images(doc, images)
            
            # L∆∞u v√†o buffer
            buffer = io.BytesIO()
            doc.save(buffer)
            buffer.seek(0)
            
            st.success("‚úÖ Word document (full version) ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
            return buffer
            
        except Exception as e:
            st.error(f"‚ùå L·ªói t·∫°o Word document: {str(e)}")
            raise e
    
    @staticmethod
    def _process_latex_content(para, content):
        """
        X·ª≠ l√Ω n·ªôi dung LaTeX trong paragraph
        """
        # T√°ch content th√†nh c√°c ph·∫ßn text v√† LaTeX
        parts = re.split(r'(\$\{[^}]+\}\$)', content)
        
        for part in parts:
            if part.startswith('${') and part.endswith('}$'):
                # Ph·∫ßn LaTeX - gi·ªØ nguy√™n format
                latex_run = para.add_run(part)
                latex_run.font.name = 'Cambria Math'
                latex_run.font.size = Pt(12)
                latex_run.font.color.rgb = RGBColor(0, 0, 128)
            else:
                # Ph·∫ßn text th∆∞·ªùng
                if part.strip():
                    text_run = para.add_run(part)
                    text_run.font.name = 'Times New Roman'
                    text_run.font.size = Pt(12)
    
    @staticmethod
    def _insert_figure_to_word(doc, tag_line, extracted_figures, clean_mode=True):
        """
        Ch√®n h√¨nh ·∫£nh v√†o Word document - C·∫¢I TI·∫æN
        """
        try:
            # Debug: hi·ªÉn th·ªã tag line
            st.write(f"üîç Processing tag: {tag_line}")
            
            # Extract figure name from tag - C·∫¢I TI·∫æN parsing
            fig_name = None
            caption_prefix = None
            
            if 'H√åNH:' in tag_line:
                # Parse: [üñºÔ∏è H√åNH: figure-1.jpeg]
                parts = tag_line.split('H√åNH:')[1].split(']')[0].strip()
                fig_name = parts.strip()
                caption_prefix = "H√¨nh"
            elif 'B·∫¢NG:' in tag_line:
                # Parse: [üìä B·∫¢NG: table-1.jpeg]
                parts = tag_line.split('B·∫¢NG:')[1].split(']')[0].strip()
                fig_name = parts.strip()
                caption_prefix = "B·∫£ng"
            else:
                st.warning(f"‚ö†Ô∏è Kh√¥ng nh·∫≠n d·∫°ng ƒë∆∞·ª£c tag: {tag_line}")
                return
            
            st.write(f"üì∑ T√¨m figure: '{fig_name}' (lo·∫°i: {caption_prefix})")
            
            # T√¨m figure trong extracted_figures - C·∫¢I TI·∫æN matching
            target_figure = None
            if extracted_figures:
                st.write(f"üìä C√≥ {len(extracted_figures)} figures ƒë√£ t√°ch:")
                for i, fig in enumerate(extracted_figures):
                    st.write(f"   {i+1}. {fig['name']} (confidence: {fig['confidence']:.1f}%)")
                    
                    # Multiple matching strategies
                    if (fig['name'] == fig_name or 
                        fig_name in fig['name'] or 
                        fig['name'] in fig_name):
                        target_figure = fig
                        st.write(f"‚úÖ Match found: {fig['name']}")
                        break
                
                if not target_figure:
                    st.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y figure '{fig_name}' trong danh s√°ch")
                    # Fallback: l·∫•y figure ƒë·∫ßu ti√™n n·∫øu c√≥
                    if extracted_figures:
                        target_figure = extracted_figures[0]
                        st.write(f"üîÑ Fallback: s·ª≠ d·ª•ng {target_figure['name']}")
            
            if target_figure:
                st.write(f"üéØ Ch√®n figure: {target_figure['name']}")
                
                # Ch·ªâ th√™m heading n·∫øu kh√¥ng ph·∫£i clean mode
                if not clean_mode:
                    heading = doc.add_heading(f"{caption_prefix}: {target_figure['name']}", level=4)
                    heading.alignment = 1
                
                # Decode v√† ch√®n ·∫£nh
                try:
                    img_data = base64.b64decode(target_figure['base64'])
                    img_pil = Image.open(io.BytesIO(img_data))
                    
                    # Convert to RGB if needed
                    if img_pil.mode in ('RGBA', 'LA', 'P'):
                        img_pil = img_pil.convert('RGB')
                    
                    # L∆∞u temporary file
                    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp_file:
                        img_pil.save(tmp_file.name, 'PNG')
                        
                        # T√≠nh k√≠ch th∆∞·ªõc ph√π h·ª£p
                        try:
                            page_width = doc.sections[0].page_width - doc.sections[0].left_margin - doc.sections[0].right_margin
                            img_width = min(page_width * 0.8, Inches(6))
                        except:
                            img_width = Inches(5)  # Fallback width
                        
                        # Th√™m ·∫£nh v√†o document
                        para = doc.add_paragraph()
                        para.alignment = 1
                        run = para.add_run()
                        run.add_picture(tmp_file.name, width=img_width)
                        
                        # Cleanup
                        os.unlink(tmp_file.name)
                    
                    # Ch·ªâ th√™m caption n·∫øu kh√¥ng ph·∫£i clean mode
                    if not clean_mode:
                        caption_para = doc.add_paragraph()
                        caption_para.alignment = 1
                        caption_run = caption_para.add_run(
                            f"Confidence: {target_figure['confidence']:.1f}% | "
                            f"Method: {target_figure['method']} | "
                            f"Aspect: {target_figure['aspect_ratio']:.2f}"
                        )
                        caption_run.font.size = Pt(9)
                        caption_run.font.color.rgb = RGBColor(128, 128, 128)
                        caption_run.italic = True
                    
                    st.success(f"‚úÖ ƒê√£ ch√®n ·∫£nh {target_figure['name']} th√†nh c√¥ng!")
                    
                except Exception as img_error:
                    st.error(f"‚ùå L·ªói ch√®n ·∫£nh: {str(img_error)}")
                    # N·∫øu kh√¥ng th·ªÉ ch√®n ·∫£nh, th√™m placeholder
                    para = doc.add_paragraph(f"[Kh√¥ng th·ªÉ hi·ªÉn th·ªã {target_figure['name']}: {str(img_error)}]")
                    para.alignment = 1
            else:
                st.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y figure n√†o ph√π h·ª£p")
                # N·∫øu kh√¥ng t√¨m th·∫•y figure
                para = doc.add_paragraph(f"[{caption_prefix}: {fig_name} - Kh√¥ng t√¨m th·∫•y]")
                para.alignment = 1
                
        except Exception as e:
            st.error(f"‚ùå L·ªói ch√®n figure: {str(e)}")
            st.write(f"Debug info: tag_line='{tag_line}', figures={len(extracted_figures) if extracted_figures else 0}")
    
    @staticmethod
    def _add_figures_appendix(doc, extracted_figures):
        """
        Th√™m ph·ª• l·ª•c v·ªõi th√¥ng tin figures
        """
        try:
            doc.add_page_break()
            doc.add_heading('Ph·ª• l·ª•c: Th√¥ng tin chi ti·∫øt v·ªÅ h√¨nh ·∫£nh', level=1)
            
            # T·∫°o b·∫£ng th·ªëng k√™
            table = doc.add_table(rows=1, cols=6)
            table.style = 'Table Grid'
            
            # Header
            header_cells = table.rows[0].cells
            headers = ['T√™n', 'Lo·∫°i', 'Confidence', 'Method', 'Aspect', 'Area']
            for i, header in enumerate(headers):
                header_cells[i].text = header
                # Bold header
                for paragraph in header_cells[i].paragraphs:
                    for run in paragraph.runs:
                        run.font.bold = True
            
            # D·ªØ li·ªáu
            for fig in extracted_figures:
                row_cells = table.add_row().cells
                row_cells[0].text = fig['name']
                row_cells[1].text = 'B·∫£ng' if fig['is_table'] else 'H√¨nh'
                row_cells[2].text = f"{fig['confidence']:.1f}%"
                row_cells[3].text = fig['method']
                row_cells[4].text = f"{fig['aspect_ratio']:.2f}"
                row_cells[5].text = f"{fig['area_ratio']:.3f}"
                
        except Exception as e:
            st.warning(f"‚ö†Ô∏è L·ªói t·∫°o appendix: {str(e)}")
    
    @staticmethod
    def _add_original_images(doc, images):
        """
        Th√™m ·∫£nh g·ªëc v√†o document
        """
        try:
            doc.add_page_break()
            doc.add_heading('Ph·ª• l·ª•c: H√¨nh ·∫£nh g·ªëc', level=1)
            
            for i, img in enumerate(images):
                doc.add_heading(f'H√¨nh g·ªëc {i+1}', level=2)
                
                # Convert image
                if img.mode in ('RGBA', 'LA', 'P'):
                    img = img.convert('RGB')
                
                # Save temporary
                with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp_file:
                    img.save(tmp_file.name, 'PNG')
                    
                    try:
                        # Add to document
                        page_width = doc.sections[0].page_width - doc.sections[0].left_margin - doc.sections[0].right_margin
                        img_width = min(page_width * 0.9, Inches(7))
                        
                        para = doc.add_paragraph()
                        para.alignment = 1
                        run = para.add_run()
                        run.add_picture(tmp_file.name, width=img_width)
                        
                    except Exception:
                        doc.add_paragraph(f"[H√¨nh g·ªëc {i+1} - Kh√¥ng th·ªÉ hi·ªÉn th·ªã]")
                    finally:
                        os.unlink(tmp_file.name)
                        
        except Exception as e:
            st.warning(f"‚ö†Ô∏è L·ªói th√™m ·∫£nh g·ªëc: {str(e)}")

def display_beautiful_figures(figures, debug_img=None):
    """
    Hi·ªÉn th·ªã figures m·ªôt c√°ch ƒë·∫πp m·∫Øt
    """
    if not figures:
        st.markdown('<div class="status-warning">‚ö†Ô∏è Kh√¥ng c√≥ figures n√†o ƒë∆∞·ª£c t√°ch ra</div>', unsafe_allow_html=True)
        return
    
    # Hi·ªÉn th·ªã debug image n·∫øu c√≥
    if debug_img:
        st.markdown("### üîç Debug Visualization")
        st.image(debug_img, caption="Enhanced extraction results", use_column_width=True)
    
    # Hi·ªÉn th·ªã figures
    st.markdown("### üì∏ Figures ƒë√£ t√°ch")
    
    # T·∫°o grid layout
    cols_per_row = 3
    for i in range(0, len(figures), cols_per_row):
        cols = st.columns(cols_per_row)
        for j in range(cols_per_row):
            if i + j < len(figures):
                fig = figures[i + j]
                with cols[j]:
                    # Hi·ªÉn th·ªã ·∫£nh
                    img_data = base64.b64decode(fig['base64'])
                    img_pil = Image.open(io.BytesIO(img_data))
                    
                    st.markdown('<div class="figure-preview">', unsafe_allow_html=True)
                    st.image(img_pil, use_column_width=True)
                    
                    # Th√¥ng tin chi ti·∫øt
                    confidence_color = "üü¢" if fig['confidence'] > 70 else "üü°" if fig['confidence'] > 50 else "üî¥"
                    type_icon = "üìä" if fig['is_table'] else "üñºÔ∏è"
                    
                    st.markdown(f"""
                    <div class="figure-info">
                        <strong>{type_icon} {fig['name']}</strong><br>
                        {confidence_color} Confidence: {fig['confidence']:.1f}%<br>
                        üìè Aspect: {fig['aspect_ratio']:.2f}<br>
                        üìê Area: {fig['area_ratio']:.3f}<br>
                        ‚öôÔ∏è Method: {fig['method']}
                    </div>
                    """, unsafe_allow_html=True)
                    st.markdown('</div>', unsafe_allow_html=True)

def validate_api_key(api_key: str) -> bool:
    if not api_key or len(api_key) < 20:
        return False
    return re.match(r'^[A-Za-z0-9_-]+$', api_key) is not None

def format_file_size(size_bytes: int) -> str:
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"

def check_dependencies():
    """
    Ki·ªÉm tra c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt
    """
    dependencies = {
        'python-docx': 'pip install python-docx',
        'PyMuPDF': 'pip install PyMuPDF',
        'opencv-python': 'pip install opencv-python',
        'scikit-image': 'pip install scikit-image',
        'scipy': 'pip install scipy'
    }
    
    missing = []
    
    if not DOCX_AVAILABLE:
        missing.append('python-docx')
    
    try:
        import fitz
    except ImportError:
        missing.append('PyMuPDF')
    
    if not CV2_AVAILABLE:
        missing.extend(['opencv-python', 'scikit-image', 'scipy'])
    
    return missing, dependencies

def main():
    st.markdown('<h1 class="main-header">üìù Enhanced PDF/LaTeX Converter - Content-Based Filter</h1>', unsafe_allow_html=True)
    
    # Ki·ªÉm tra dependencies
    missing_deps, dep_commands = check_dependencies()
    if missing_deps:
        st.error("‚ùå Thi·∫øu th∆∞ vi·ªán c·∫ßn thi·∫øt:")
        for dep in missing_deps:
            st.code(dep_commands[dep], language="bash")
        st.stop()
    
    # Hero section
    st.markdown("""
    <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 2rem; border-radius: 15px; margin-bottom: 2rem; text-align: center;">
        <h2 style="margin: 0;">üß† CONTENT-BASED FILTER - T·ª∞ ƒê·ªòNG ƒê·∫æM S·ªê ·∫¢NH</h2>
        <p style="margin: 1rem 0; font-size: 1.1rem;">‚úÖ Ph√¢n t√≠ch n·ªôi dung ‚Ä¢ ‚úÖ ƒê·∫øm ·∫£nh th·ª±c t·∫ø ‚Ä¢ ‚úÖ L·ªçc ch·∫•t l∆∞·ª£ng ‚Ä¢ ‚úÖ Word s·∫°ch s·∫Ω</p>
        <div style="display: flex; justify-content: space-around; margin-top: 1.5rem;">
            <div style="text-align: center;">
                <div style="font-size: 2rem; margin-bottom: 0.5rem;">üß†</div>
                <div><strong>Content Analysis</strong></div>
                <div style="font-size: 0.9rem; opacity: 0.8;">AI ph√¢n t√≠ch ‚Ä¢ ƒê·∫øm th·ª±c t·∫ø</div>
            </div>
            <div style="text-align: center;">
                <div style="font-size: 2rem; margin-bottom: 0.5rem;">üéØ</div>
                <div><strong>Precision Filter</strong></div>
                <div style="font-size: 0.9rem; opacity: 0.8;">L·ªçc ch·∫•t l∆∞·ª£ng ‚Ä¢ Kh√¥ng th·ª´a</div>
            </div>
            <div style="text-align: center;">
                <div style="font-size: 2rem; margin-bottom: 0.5rem;">üìÑ</div>
                <div><strong>Clean Output</strong></div>
                <div style="font-size: 0.9rem; opacity: 0.8;">S·∫°ch s·∫Ω ‚Ä¢ Ch√≠nh x√°c</div>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è C√†i ƒë·∫∑t")
        
        # API key
        api_key = st.text_input(
            "Gemini API Key", 
            type="password", 
            help="Nh·∫≠p API key t·ª´ Google AI Studio",
            placeholder="Paste your API key here..."
        )
        
        if api_key:
            if validate_api_key(api_key):
                st.success("‚úÖ API key h·ª£p l·ªá")
            else:
                st.error("‚ùå API key kh√¥ng h·ª£p l·ªá")
        
        st.markdown("---")
        
        # C√†i ƒë·∫∑t t√°ch ·∫£nh
        if CV2_AVAILABLE:
            st.markdown("### üîç T√°ch ·∫£nh SI√äU C·∫¢I TI·∫æN")
            enable_extraction = st.checkbox("B·∫≠t t√°ch ·∫£nh th√¥ng minh", value=True)
            
            if enable_extraction:
                st.markdown("#### üéõÔ∏è T√πy ch·ªânh n√¢ng cao")
                
                # Content-Based Filter
                st.markdown("**üß† Content-Based Filter (M·ªöI):**")
                enable_content_filter = st.checkbox("B·∫≠t l·ªçc theo n·ªôi dung th·ª±c t·∫ø", value=True, key="content_filter")
                if enable_content_filter:
                    st.markdown("""
                    <div style="background: #e8f5e8; padding: 0.5rem; border-radius: 5px; margin: 5px 0;">
                    <small>
                    ‚úÖ Ph√¢n t√≠ch n·ªôi dung ƒë·ªÉ ƒë·∫øm s·ªë ·∫£nh minh h·ªça th·ª±c t·∫ø<br>
                    ‚úÖ L·ªçc b·ªè text regions, noise, artifacts<br>
                    ‚úÖ Ch·ªâ gi·ªØ l·∫°i figures ch·∫•t l∆∞·ª£ng cao<br>
                    ‚úÖ T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh s·ªë l∆∞·ª£ng ph√π h·ª£p
                    </small>
                    </div>
                    """, unsafe_allow_html=True)
                
                # Quick presets
                st.markdown("**‚ö° Quick Presets:**")
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("üî• T√°ch nhi·ªÅu", key="preset_many"):
                        st.session_state.preset = "many"
                with col2:
                    if st.button("üéØ Ch·∫•t l∆∞·ª£ng", key="preset_quality"):
                        st.session_state.preset = "quality"
                
                # Detailed settings
                with st.expander("üîß C√†i ƒë·∫∑t chi ti·∫øt"):
                    min_area = st.slider("Di·ªán t√≠ch t·ªëi thi·ªÉu (%)", 0.01, 1.0, 0.08, 0.01) / 100
                    min_size = st.slider("K√≠ch th∆∞·ªõc t·ªëi thi·ªÉu (px)", 15, 100, 25, 5)
                    max_figures = st.slider("S·ªë ·∫£nh t·ªëi ƒëa", 5, 50, 30, 5)
                    confidence_threshold = st.slider("Ng∆∞·ª°ng confidence", 10, 80, 20, 5)
                    smart_padding = st.slider("Smart padding", 15, 60, 30, 5)
                    
                    st.markdown("**Edge Detection:**")
                    canny_low = st.slider("Canny low", 10, 100, 30, 5)
                    canny_high = st.slider("Canny high", 50, 200, 80, 10)
                    
                    st.markdown("**Content Filter Settings:**")
                    if enable_content_filter:
                        visual_complexity_threshold = st.slider("Visual Complexity Threshold", 0.1, 1.0, 0.4, 0.1)
                        text_ratio_threshold = st.slider("Text Ratio Threshold", 0.1, 0.8, 0.3, 0.1)
                        diagram_threshold = st.slider("Diagram Detection Threshold", 0.1, 1.0, 0.5, 0.1)
                    
                    show_debug = st.checkbox("Hi·ªÉn th·ªã debug visualization", value=True)
                    detailed_info = st.checkbox("Th√¥ng tin chi ti·∫øt", value=True)
        else:
            enable_extraction = False
            enable_content_filter = False
            st.error("‚ùå OpenCV kh√¥ng kh·∫£ d·ª•ng!")
            st.code("pip install opencv-python", language="bash")
            
            # Set default values for variables
            min_area = 0.0008
            min_size = 25
            max_figures = 30
            confidence_threshold = 20
            smart_padding = 30
            canny_low = 30
            canny_high = 80
            show_debug = True
            detailed_info = True
        
        st.markdown("---")
        
        # Th√¥ng tin chi ti·∫øt
        st.markdown("""
        ### üéØ **C·∫£i ti·∫øn ch√≠nh:**
        
        **üß† Content-Based Filter (M·ªöI):**
        - ‚úÖ Ph√¢n t√≠ch n·ªôi dung th·ª±c t·∫ø trong ·∫£nh
        - ‚úÖ ∆Ø·ªõc t√≠nh s·ªë l∆∞·ª£ng ·∫£nh minh h·ªça th·ª±c t·∫ø  
        - ‚úÖ L·ªçc b·ªè text regions, noise, artifacts
        - ‚úÖ Ch·ªâ gi·ªØ l·∫°i figures ch·∫•t l∆∞·ª£ng cao
        - ‚úÖ T·ª± ƒë·ªông ƒëi·ªÅu ch·ªânh s·ªë l∆∞·ª£ng ph√π h·ª£p
        
        **üìÑ Clean Word Export:**
        - ‚úÖ B·ªè ti√™u ƒë·ªÅ metadata
        - ‚úÖ B·ªè th√¥ng tin th·ªùi gian, figures count
        - ‚úÖ B·ªè appendix th·ªëng k√™
        - ‚úÖ Ch·ªâ n·ªôi dung ch√≠nh + figures
        - ‚úÖ Dual mode: Clean vs Full
        
        **üîç T√°ch ·∫£nh SI√äU C·∫¢I TI·∫æN:**
        - ‚úÖ 4 ph∆∞∆°ng ph√°p song song
        - ‚úÖ Threshold c·ª±c th·∫•p (t√°ch ƒë∆∞·ª£c h·∫ßu h·∫øt ·∫£nh)
        - ‚úÖ Smart merging & filtering
        - ‚úÖ Debug visualization ƒë·∫πp
        - ‚úÖ Multi-method confidence scoring
        
        **üéØ Figure Insertion Improved:**
        - ‚úÖ Debug mode real-time
        - ‚úÖ Better tag parsing
        - ‚úÖ Fallback matching strategies
        - ‚úÖ Test functions for debugging
        
        ### üöÄ **C√°ch ho·∫°t ƒë·ªông Content Filter:**
        1. **Ph√¢n t√≠ch Layout**: ∆Ø·ªõc t√≠nh s·ªë figures th·ª±c t·∫ø
        2. **Content Analysis**: ƒê√°nh gi√° t·ª´ng candidate
        3. **Visual Complexity**: T√≠nh ƒë·ªô ph·ª©c t·∫°p h√¨nh ·∫£nh
        4. **Text Density**: L·ªçc b·ªè v√πng ch·ªß y·∫øu l√† text
        5. **Diagram Detection**: Ph√°t hi·ªán bi·ªÉu ƒë·ªì, s∆° ƒë·ªì
        6. **Quality Assessment**: ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng figure
        7. **Smart Limiting**: Gi·ªõi h·∫°n theo s·ªë l∆∞·ª£ng ∆∞·ªõc t√≠nh
        
        ### üîß **H∆∞·ªõng d·∫´n:**
        - **Content Filter ON**: T√°ch ƒë√∫ng s·ªë l∆∞·ª£ng th·ª±c t·∫ø
        - **Content Filter OFF**: T√°ch nhi·ªÅu nh∆∞ tr∆∞·ªõc
        - **Preset "T√°ch nhi·ªÅu"**: Relaxed content filter
        - **Preset "Ch·∫•t l∆∞·ª£ng"**: Strict content filter
        - **Debug**: Xem real-time analysis
        - **Test**: Th·ª≠ nghi·ªám tr∆∞·ªõc khi d√πng
        """)
    
    if not api_key:
        st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p Gemini API Key ·ªü sidebar ƒë·ªÉ b·∫Øt ƒë·∫ßu!")
        return
    
    if not validate_api_key(api_key):
        st.error("‚ùå API key kh√¥ng h·ª£p l·ªá. Vui l√≤ng ki·ªÉm tra l·∫°i!")
        return
    
    # Kh·ªüi t·∫°o
    try:
        gemini_api = GeminiAPI(api_key)
        if enable_extraction and CV2_AVAILABLE:
            image_extractor = SuperEnhancedImageExtractor()
            
            # Apply content filter settings
            if enable_content_filter:
                image_extractor.enable_content_filter = True
                if 'visual_complexity_threshold' in locals():
                    image_extractor.content_filter.min_visual_complexity = visual_complexity_threshold
                if 'text_ratio_threshold' in locals():
                    image_extractor.content_filter.text_to_image_ratio_threshold = text_ratio_threshold
                if 'diagram_threshold' in locals():
                    image_extractor.content_filter.diagram_detection_threshold = diagram_threshold
            else:
                image_extractor.enable_content_filter = False
            
            # Apply presets
            if st.session_state.get('preset') == "many":
                image_extractor.min_area_ratio = 0.0005
                image_extractor.min_area_abs = 200
                image_extractor.min_width = 20
                image_extractor.min_height = 20
                image_extractor.confidence_threshold = 15
                image_extractor.max_figures = 50
                # Relaxed content filter for "many" preset
                if enable_content_filter:
                    image_extractor.content_filter.min_visual_complexity = 0.2
                    image_extractor.content_filter.text_to_image_ratio_threshold = 0.5
            elif st.session_state.get('preset') == "quality":
                image_extractor.min_area_ratio = 0.002
                image_extractor.min_area_abs = 800
                image_extractor.min_width = 40
                image_extractor.min_height = 40
                image_extractor.confidence_threshold = 40
                image_extractor.max_figures = 15
                # Strict content filter for "quality" preset
                if enable_content_filter:
                    image_extractor.content_filter.min_visual_complexity = 0.6
                    image_extractor.content_filter.text_to_image_ratio_threshold = 0.2
            else:
                # Custom settings
                image_extractor.min_area_ratio = min_area
                image_extractor.min_area_abs = min_size * min_size
                image_extractor.min_width = min_size
                image_extractor.min_height = min_size
                image_extractor.confidence_threshold = confidence_threshold
                image_extractor.max_figures = max_figures
                image_extractor.smart_padding = smart_padding
                image_extractor.canny_low = canny_low
                image_extractor.canny_high = canny_high
        else:
            image_extractor = None
                
    except Exception as e:
        st.error(f"‚ùå L·ªói kh·ªüi t·∫°o: {str(e)}")
        return
    
    # Tabs
    tab1, tab2, tab3 = st.tabs(["üìÑ PDF to LaTeX", "üñºÔ∏è Image to LaTeX", "üîç Debug Info"])
    
    # Tab PDF
    with tab1:
        st.header("üìÑ Chuy·ªÉn ƒë·ªïi PDF sang LaTeX")
        
        uploaded_pdf = st.file_uploader("Ch·ªçn file PDF", type=['pdf'])
        
        if uploaded_pdf:
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.subheader("üìã Preview PDF")
                
                # Metrics
                col_a, col_b = st.columns(2)
                with col_a:
                    st.markdown(f'<div class="metric-card">üìÅ {uploaded_pdf.name}</div>', unsafe_allow_html=True)
                with col_b:
                    st.markdown(f'<div class="metric-card">üìè {format_file_size(uploaded_pdf.size)}</div>', unsafe_allow_html=True)
                
                with st.spinner("üîÑ ƒêang x·ª≠ l√Ω PDF..."):
                    try:
                        pdf_images = PDFProcessor.extract_images_and_text(uploaded_pdf)
                        st.markdown(f'<div class="status-success">‚úÖ ƒê√£ tr√≠ch xu·∫•t {len(pdf_images)} trang</div>', unsafe_allow_html=True)
                        
                        # Preview m·ªôt s·ªë trang
                        for i, (img, page_num) in enumerate(pdf_images[:2]):
                            st.markdown(f"**üìÑ Trang {page_num}:**")
                            st.image(img, use_column_width=True)
                        
                        if len(pdf_images) > 2:
                            st.info(f"... v√† {len(pdf_images) - 2} trang kh√°c")
                    
                    except Exception as e:
                        st.error(f"‚ùå L·ªói x·ª≠ l√Ω PDF: {str(e)}")
                        pdf_images = []
            
            with col2:
                st.subheader("‚ö° Chuy·ªÉn ƒë·ªïi sang LaTeX")
                
                if st.button("üöÄ B·∫Øt ƒë·∫ßu chuy·ªÉn ƒë·ªïi PDF", type="primary", key="convert_pdf"):
                    if pdf_images:
                        st.markdown('<div class="processing-container">', unsafe_allow_html=True)
                        
                        all_latex_content = []
                        all_extracted_figures = []
                        all_debug_images = []
                        
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        for i, (img, page_num) in enumerate(pdf_images):
                            status_text.markdown(f"üîÑ **ƒêang x·ª≠ l√Ω trang {page_num}/{len(pdf_images)}...**")
                            
                            img_buffer = io.BytesIO()
                            img.save(img_buffer, format='PNG')
                            img_bytes = img_buffer.getvalue()
                            
                            # T√°ch ·∫£nh SI√äU C·∫¢I TI·∫æN
                            extracted_figures = []
                            debug_img = None
                            
                            if enable_extraction and CV2_AVAILABLE and image_extractor:
                                try:
                                    with st.spinner(f"üîç ƒêang t√°ch ·∫£nh trang {page_num}..."):
                                        figures, h, w = image_extractor.extract_figures_and_tables(img_bytes)
                                        extracted_figures = figures
                                        all_extracted_figures.extend(figures)
                                        
                                        if show_debug and figures:
                                            debug_img = image_extractor.create_beautiful_debug_visualization(img_bytes, figures)
                                            all_debug_images.append((debug_img, page_num, figures))
                                        
                                        # Hi·ªÉn th·ªã k·∫øt qu·∫£ t√°ch ·∫£nh
                                        if figures:
                                            if enable_content_filter:
                                                st.markdown(f'<div class="status-success">üß† Trang {page_num}: T√°ch ƒë∆∞·ª£c {len(figures)} figures (content-filtered)</div>', unsafe_allow_html=True)
                                            else:
                                                st.markdown(f'<div class="status-success">üéØ Trang {page_num}: T√°ch ƒë∆∞·ª£c {len(figures)} figures</div>', unsafe_allow_html=True)
                                            
                                            if detailed_info:
                                                for fig in figures:
                                                    method_icon = {"edge": "üîç", "contour": "üìê", "grid": "üìä", "blob": "üîµ"}
                                                    conf_color = "üü¢" if fig['confidence'] > 70 else "üü°" if fig['confidence'] > 40 else "üî¥"
                                                    content_info = f" | {fig.get('content_type', 'unknown')}" if enable_content_filter else ""
                                                    st.markdown(f"   {method_icon.get(fig['method'], '‚öôÔ∏è')} {conf_color} **{fig['name']}**: {fig['confidence']:.1f}% ({fig['method']}{content_info})")
                                        else:
                                            st.markdown(f'<div class="status-warning">‚ö†Ô∏è Trang {page_num}: Kh√¥ng t√°ch ƒë∆∞·ª£c figures</div>', unsafe_allow_html=True)
                                    
                                except Exception as e:
                                    st.error(f"‚ùå L·ªói t√°ch ·∫£nh trang {page_num}: {str(e)}")
                            
                            # Prompt ƒë√£ c·∫£i ti·∫øn
                            prompt_text = """
Chuy·ªÉn ƒë·ªïi TO√ÄN B·ªò n·ªôi dung trong ·∫£nh th√†nh vƒÉn b·∫£n v·ªõi format LaTeX ${...}$.

üéØ Y√äU C·∫¶U ƒê·ªäNH D·∫†NG:

1. **C√¢u h·ªèi tr·∫Øc nghi·ªám:**
```
C√¢u X: [n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß]
A) [ƒë√°p √°n A ho√†n ch·ªânh]
B) [ƒë√°p √°n B ho√†n ch·ªânh]
C) [ƒë√°p √°n C ho√†n ch·ªânh]  
D) [ƒë√°p √°n D ho√†n ch·ªânh]
```

2. **C√¢u h·ªèi ƒë√∫ng sai:**
```
C√¢u X: [n·ªôi dung c√¢u h·ªèi]
a) [kh·∫≥ng ƒë·ªãnh a ƒë·∫ßy ƒë·ªß]
b) [kh·∫≥ng ƒë·ªãnh b ƒë·∫ßy ƒë·ªß]
c) [kh·∫≥ng ƒë·ªãnh c ƒë·∫ßy ƒë·ªß]
d) [kh·∫≥ng ƒë·ªãnh d ƒë·∫ßy ƒë·ªß]
```

3. **C√¥ng th·ª©c to√°n h·ªçc - LU√îN d√πng ${...}$:**
- H√¨nh h·ªçc: ${ABCD.A'B'C'D'}$, ${\\overrightarrow{AB}}$
- Ph∆∞∆°ng tr√¨nh: ${x^2 + y^2 = z^2}$, ${\\frac{a+b}{c-d}}$
- T√≠ch ph√¢n: ${\\int_{0}^{1} x^2 dx}$, ${\\lim_{x \\to 0} \\frac{\\sin x}{x}}$
- Ma tr·∫≠n: ${\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}}$

‚ö†Ô∏è TUY·ªÜT ƒê·ªêI:
- LU√îN d√πng ${...}$ cho M·ªåI c√¥ng th·ª©c, k√Ω hi·ªáu to√°n h·ªçc
- KH√îNG d√πng ```latex```, $...$, \\(...\\), \\[...\\]
- S·ª≠ d·ª•ng A), B), C), D) cho tr·∫Øc nghi·ªám
- S·ª≠ d·ª•ng a), b), c), d) cho ƒë√∫ng sai
- Bao g·ªìm T·∫§T C·∫¢ vƒÉn b·∫£n t·ª´ ·∫£nh
- Gi·ªØ nguy√™n th·ª© t·ª± v√† c·∫•u tr√∫c
"""
                            
                            # G·ªçi API
                            try:
                                with st.spinner(f"ü§ñ ƒêang chuy·ªÉn ƒë·ªïi LaTeX trang {page_num}..."):
                                    latex_result = gemini_api.convert_to_latex(img_bytes, "image/png", prompt_text)
                                    
                                    if latex_result:
                                        # Ch√®n figures v√†o ƒë√∫ng v·ªã tr√≠
                                        if enable_extraction and extracted_figures and CV2_AVAILABLE and image_extractor:
                                            latex_result = image_extractor.insert_figures_into_text_precisely(
                                                latex_result, extracted_figures, h, w
                                            )
                                        
                                        all_latex_content.append(f"<!-- üìÑ Trang {page_num} -->\n{latex_result}\n")
                                        st.success(f"‚úÖ Ho√†n th√†nh trang {page_num}")
                                    else:
                                        st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ x·ª≠ l√Ω trang {page_num}")
                                        
                            except Exception as e:
                                st.error(f"‚ùå L·ªói API trang {page_num}: {str(e)}")
                            
                            progress_bar.progress((i + 1) / len(pdf_images))
                        
                        status_text.markdown("üéâ **Ho√†n th√†nh chuy·ªÉn ƒë·ªïi!**")
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                        # Hi·ªÉn th·ªã k·∫øt qu·∫£
                        combined_latex = "\n".join(all_latex_content)
                        
                        st.markdown("### üìù K·∫øt qu·∫£ LaTeX")
                        st.markdown('<div class="latex-output">', unsafe_allow_html=True)
                        st.code(combined_latex, language="latex")
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                        # Debug: hi·ªÉn th·ªã c√°c tags ƒë√£ ch√®n
                        if enable_extraction and all_extracted_figures:
                            st.markdown("### üîç Debug: Tags ƒë√£ ch√®n")
                            latex_lines = combined_latex.split('\n')
                            figure_tags = [line for line in latex_lines if line.startswith('[') and ('H√åNH:' in line or 'B·∫¢NG:' in line)]
                            
                            if figure_tags:
                                st.write(f"üìä T√¨m th·∫•y {len(figure_tags)} tags:")
                                for i, tag in enumerate(figure_tags):
                                    st.write(f"   {i+1}. {tag}")
                            else:
                                st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y tags n√†o trong LaTeX content")
                        
                        # Th·ªëng k√™
                        if enable_extraction and CV2_AVAILABLE and all_extracted_figures:
                            st.markdown("### üìä Th·ªëng k√™ t√°ch ·∫£nh")
                            
                            col_1, col_2, col_3, col_4 = st.columns(4)
                            with col_1:
                                st.metric("üîç T·ªïng figures", len(all_extracted_figures))
                            with col_2:
                                tables = sum(1 for f in all_extracted_figures if f['is_table'])
                                st.metric("üìä B·∫£ng", tables)
                            with col_3:
                                figures_count = len(all_extracted_figures) - tables
                                st.metric("üñºÔ∏è H√¨nh", figures_count)
                            with col_4:
                                avg_conf = sum(f['confidence'] for f in all_extracted_figures) / len(all_extracted_figures)
                                st.metric("üéØ Avg Confidence", f"{avg_conf:.1f}%")
                            
                            # Hi·ªÉn th·ªã th√¥ng tin content filter n·∫øu c√≥
                            if enable_content_filter:
                                st.markdown("### üß† Content Filter Analysis")
                                
                                content_types = {}
                                for fig in all_extracted_figures:
                                    content_type = fig.get('content_type', 'unknown')
                                    content_types[content_type] = content_types.get(content_type, 0) + 1
                                
                                if content_types:
                                    col_a, col_b, col_c, col_d = st.columns(4)
                                    type_items = list(content_types.items())
                                    
                                    for i, (content_type, count) in enumerate(type_items[:4]):
                                        with [col_a, col_b, col_c, col_d][i]:
                                            icon = {"diagram": "üìä", "chart": "üìà", "image": "üñºÔ∏è", "table": "üìã", "mixed": "üîÑ"}.get(content_type, "‚ùì")
                                            st.metric(f"{icon} {content_type.title()}", count)
                                
                                # Hi·ªÉn th·ªã quality metrics
                                if any('content_score' in fig for fig in all_extracted_figures):
                                    avg_content_score = sum(fig.get('content_score', 0) for fig in all_extracted_figures) / len(all_extracted_figures)
                                    avg_visual_complexity = sum(fig.get('visual_complexity', 0) for fig in all_extracted_figures) / len(all_extracted_figures)
                                    
                                    col_x, col_y = st.columns(2)
                                    with col_x:
                                        st.metric("üéØ Avg Content Score", f"{avg_content_score:.2f}")
                                    with col_y:
                                        st.metric("üé® Avg Visual Complexity", f"{avg_visual_complexity:.2f}")
                            
                            # Hi·ªÉn th·ªã figures ƒë·∫πp
                            for debug_img, page_num, figures in all_debug_images:
                                with st.expander(f"üìÑ Trang {page_num} - {len(figures)} figures"):
                                    display_beautiful_figures(figures, debug_img)
                        
                        # L∆∞u v√†o session
                        st.session_state.pdf_latex_content = combined_latex
                        st.session_state.pdf_images = [img for img, _ in pdf_images]
                        st.session_state.pdf_extracted_figures = all_extracted_figures if enable_extraction else None
                
                # Download buttons
                if 'pdf_latex_content' in st.session_state:
                    st.markdown("---")
                    st.markdown("### üì• T·∫£i xu·ªëng")
                    
                    col_x, col_y = st.columns(2)
                    with col_x:
                        st.download_button(
                            label="üìù T·∫£i LaTeX (.tex)",
                            data=st.session_state.pdf_latex_content,
                            file_name=uploaded_pdf.name.replace('.pdf', '.tex'),
                            mime="text/plain",
                            type="primary"
                        )
                    
                    with col_y:
                        if DOCX_AVAILABLE:
                            # T√πy ch·ªçn Word export
                            st.markdown("**üìÑ T√πy ch·ªçn Word Export:**")
                            word_clean_mode = st.checkbox("Clean Mode (b·ªè metadata, appendix)", value=True, key="word_clean")
                            
                            if st.button("üìÑ T·∫°o Word", key="create_word"):
                                with st.spinner("üîÑ ƒêang t·∫°o Word v·ªõi LaTeX..."):
                                    try:
                                        # T·∫°o Word document th·ª±c s·ª±
                                        extracted_figs = st.session_state.get('pdf_extracted_figures')
                                        original_imgs = st.session_state.get('pdf_images')
                                        
                                        # Debug info tr∆∞·ªõc khi t·∫°o Word
                                        if extracted_figs:
                                            st.info(f"üìä S·∫Ω ch√®n {len(extracted_figs)} figures v√†o Word")
                                            for i, fig in enumerate(extracted_figs):
                                                st.write(f"   {i+1}. {fig['name']} ({fig['confidence']:.1f}%)")
                                        
                                        if word_clean_mode:
                                            word_buffer = EnhancedWordExporter.create_word_document(
                                                st.session_state.pdf_latex_content,
                                                extracted_figures=extracted_figs,
                                                images=None  # Kh√¥ng th√™m ·∫£nh g·ªëc trong clean mode
                                            )
                                            filename = uploaded_pdf.name.replace('.pdf', '_clean.docx')
                                            success_msg = "‚úÖ Word document (Clean) ƒë√£ t·∫°o th√†nh c√¥ng!"
                                        else:
                                            word_buffer = EnhancedWordExporter.create_word_document_full(
                                                st.session_state.pdf_latex_content,
                                                extracted_figures=extracted_figs,
                                                images=original_imgs
                                            )
                                            filename = uploaded_pdf.name.replace('.pdf', '_full.docx')
                                            success_msg = "‚úÖ Word document (Full) ƒë√£ t·∫°o th√†nh c√¥ng!"
                                        
                                        st.download_button(
                                            label="üìÑ T·∫£i Word (.docx)",
                                            data=word_buffer.getvalue(),
                                            file_name=filename,
                                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                                            key="download_word"
                                        )
                                        
                                        st.success(success_msg)
                                        
                                        # H∆∞·ªõng d·∫´n ki·ªÉm tra
                                        if word_clean_mode:
                                            st.markdown("""
                                            ### üìù Clean Mode Features:
                                            - ‚úÖ **Kh√¥ng c√≥** ti√™u ƒë·ªÅ metadata 
                                            - ‚úÖ **Kh√¥ng c√≥** th√¥ng tin th·ªùi gian t·∫°o
                                            - ‚úÖ **Kh√¥ng c√≥** appendix v·ªõi b·∫£ng th·ªëng k√™
                                            - ‚úÖ **Kh√¥ng c√≥** figure headings v√† captions
                                            - ‚úÖ **Ch·ªâ c√≥** n·ªôi dung ch√≠nh + figures embedded
                                            
                                            ### üîç So s√°nh v·ªõi ·∫£nh b·∫°n g·ª≠i:
                                            - ‚ùå "T√†i li·ªáu LaTeX ƒë√£ chuy·ªÉn ƒë·ªïi" ‚Üí ‚úÖ **ƒê√£ b·ªè**
                                            - ‚ùå "ƒê∆∞·ª£c t·∫°o b·ªüi Enhanced..." ‚Üí ‚úÖ **ƒê√£ b·ªè**
                                            - ‚ùå "Figures: 3" ‚Üí ‚úÖ **ƒê√£ b·ªè**
                                            - ‚ùå "Ph·ª• l·ª•c: Th√¥ng tin chi ti·∫øt..." ‚Üí ‚úÖ **ƒê√£ b·ªè**
                                            - ‚ùå Caption "Confidence: 70.0%..." ‚Üí ‚úÖ **ƒê√£ b·ªè**
                                            """)
                                        else:
                                            st.markdown("""
                                            ### üìä Full Mode Features:
                                            - ‚úÖ C√≥ ti√™u ƒë·ªÅ v√† metadata
                                            - ‚úÖ C√≥ th√¥ng tin th·ªùi gian t·∫°o
                                            - ‚úÖ C√≥ appendix v·ªõi th√¥ng tin figures
                                            - ‚úÖ C√≥ figure headings v√† captions
                                            - ‚úÖ C√≥ ·∫£nh g·ªëc n·∫øu c·∫ßn
                                            """)
                                        
                                        # Th√™m th√¥ng tin v·ªÅ n·ªôi dung
                                        if extracted_figs:
                                            st.info(f"üìä ƒê√£ bao g·ªìm {len(extracted_figs)} figures ƒë∆∞·ª£c t√°ch")
                                        if not word_clean_mode and original_imgs:
                                            st.info(f"üì∏ ƒê√£ bao g·ªìm {len(original_imgs)} ·∫£nh g·ªëc")
                                            
                                    except Exception as e:
                                        st.error(f"‚ùå L·ªói t·∫°o Word: {str(e)}")
                                        st.error("üí° Th·ª≠: pip install python-docx")
                                        st.error("üîß Ho·∫∑c d√πng 'Test Figure Insertion' ƒë·ªÉ debug")
                        else:
                            st.error("‚ùå C·∫ßn c√†i ƒë·∫∑t python-docx")
                            st.code("pip install python-docx", language="bash")
    
    # Tab Image (similar structure)
    with tab2:
        st.header("üñºÔ∏è Chuy·ªÉn ƒë·ªïi ·∫¢nh sang LaTeX")
        
        uploaded_images = st.file_uploader(
            "Ch·ªçn ·∫£nh (c√≥ th·ªÉ ch·ªçn nhi·ªÅu)",
            type=['png', 'jpg', 'jpeg', 'bmp', 'tiff'],
            accept_multiple_files=True
        )
        
        if uploaded_images:
            st.info("üñºÔ∏è X·ª≠ l√Ω t∆∞∆°ng t·ª± nh∆∞ PDF tab...")
            # Implementation similar to PDF tab
    
    # Tab Debug
    with tab3:
        st.header("üîç Debug Information")
        
        # Dependencies status
        st.markdown("### üì¶ Dependencies Status")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Core Libraries:**")
            st.markdown(f"‚úÖ Streamlit: {st.__version__}")
            st.markdown(f"‚úÖ Requests: Available")
            st.markdown(f"‚úÖ PIL: Available")
            st.markdown(f"‚úÖ Base64: Available")
            
        with col2:
            st.markdown("**Optional Libraries:**")
            st.markdown(f"{'‚úÖ' if DOCX_AVAILABLE else '‚ùå'} python-docx: {'Available' if DOCX_AVAILABLE else 'Missing'}")
            
            try:
                import fitz
                st.markdown(f"‚úÖ PyMuPDF: Available")
            except ImportError:
                st.markdown(f"‚ùå PyMuPDF: Missing")
            
            st.markdown(f"{'‚úÖ' if CV2_AVAILABLE else '‚ùå'} OpenCV: {'Available' if CV2_AVAILABLE else 'Missing'}")
        
        if not DOCX_AVAILABLE:
            st.error("‚ùå python-docx not available - Word export disabled")
            st.code("pip install python-docx", language="bash")
        
        if CV2_AVAILABLE:
            st.markdown("""
            ### ‚úÖ OpenCV Status: Available
            
            **Installed modules:**
            - cv2 (OpenCV)
            - numpy
            - scipy
            - skimage
            
            **Extraction methods:**
            1. üîç Edge detection
            2. üìê Contour analysis  
            3. üìä Grid detection
            4. üîµ Blob detection
            """)
        else:
            st.markdown("""
            ### ‚ùå OpenCV Status: Not Available
            
            **ƒê·ªÉ s·ª≠ d·ª•ng t√°ch ·∫£nh, c·∫ßn c√†i ƒë·∫∑t:**
            ```bash
            pip install opencv-python
            pip install scikit-image
            pip install scipy
            ```
            """)
        
        # Display current settings
        if enable_extraction and CV2_AVAILABLE and image_extractor:
            st.markdown("### ‚öôÔ∏è Current Settings")
            
            settings_data = {
                "min_area_ratio": image_extractor.min_area_ratio,
                "min_area_abs": image_extractor.min_area_abs,
                "min_width": image_extractor.min_width,
                "min_height": image_extractor.min_height,
                "max_figures": image_extractor.max_figures,
                "confidence_threshold": image_extractor.confidence_threshold,
                "smart_padding": image_extractor.smart_padding,
                "canny_low": image_extractor.canny_low,
                "canny_high": image_extractor.canny_high,
                "content_filter_enabled": image_extractor.enable_content_filter
            }
            
            if image_extractor.enable_content_filter:
                settings_data.update({
                    "content_filter_visual_threshold": image_extractor.content_filter.min_visual_complexity,
                    "content_filter_text_threshold": image_extractor.content_filter.text_to_image_ratio_threshold,
                    "content_filter_diagram_threshold": image_extractor.content_filter.diagram_detection_threshold
                })
            
            st.json(settings_data)
        
        # Test functions
        st.markdown("### üß™ Test Functions")
        
        col_test1, col_test2 = st.columns(2)
        
        with col_test1:
            test_mode = st.radio("Test Mode", ["Clean", "Full"], index=0, key="test_mode_radio")
            if st.button("Test Word Export", key="test_word"):
                if DOCX_AVAILABLE:
                    try:
                        test_content = "Test LaTeX: ${x^2 + y^2 = z^2}$"
                        if test_mode == "Clean":
                            test_buffer = EnhancedWordExporter.create_word_document(test_content)
                            filename = "test_clean.docx"
                            st.success("‚úÖ Clean mode test passed - Kh√¥ng metadata")
                        else:
                            test_buffer = EnhancedWordExporter.create_word_document_full(test_content)
                            filename = "test_full.docx"
                            st.success("‚úÖ Full mode test passed - C√≥ metadata")
                        
                        st.download_button(
                            f"üìÑ Download Test Word ({test_mode})",
                            data=test_buffer.getvalue(),
                            file_name=filename,
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                        )
                    except Exception as e:
                        st.error(f"‚ùå Word export test failed: {str(e)}")
                else:
                    st.error("‚ùå python-docx not available")
        
        with col_test2:
            test_clean_mode = st.checkbox("Test Clean Mode", value=True, key="test_clean")
            if st.button("Test Figure Insertion", key="test_figure"):
                if DOCX_AVAILABLE:
                    try:
                        # T·∫°o test content v·ªõi figure tags
                        test_content = """
C√¢u 1: Gi·∫£i ph∆∞∆°ng tr√¨nh sau:

[üñºÔ∏è H√åNH: figure-1.jpeg]

ƒê√°p √°n: A) x = 1, B) x = 2

[üìä B·∫¢NG: table-1.jpeg]

K·∫øt qu·∫£ nh∆∞ tr√™n.
"""
                        
                        # T·∫°o mock figures
                        mock_figures = [
                            {
                                'name': 'figure-1.jpeg',
                                'base64': 'iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8/5+hHgAHggJ/PchI7wAAAABJRU5ErkJggg==',
                                'confidence': 70.0,
                                'method': 'test',
                                'aspect_ratio': 1.0,
                                'is_table': False
                            },
                            {
                                'name': 'table-1.jpeg',
                                'base64': 'iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8/5+hHgAHggJ/PchI7wAAAABJRU5ErkJggg==',
                                'confidence': 70.0,
                                'method': 'test',
                                'aspect_ratio': 2.0,
                                'is_table': True
                            }
                        ]
                        
                        if test_clean_mode:
                            test_buffer = EnhancedWordExporter.create_word_document(test_content, extracted_figures=mock_figures)
                            filename = "test_clean_with_figures.docx"
                            st.success("‚úÖ Clean mode test passed - Kh√¥ng c√≥ heading, caption")
                        else:
                            test_buffer = EnhancedWordExporter.create_word_document_full(test_content, extracted_figures=mock_figures)
                            filename = "test_full_with_figures.docx"
                            st.success("‚úÖ Full mode test passed - C√≥ heading, caption, metadata")
                        
                        st.download_button(
                            f"üìÑ Download Test Word ({'Clean' if test_clean_mode else 'Full'})",
                            data=test_buffer.getvalue(),
                            file_name=filename,
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                        )
                        
                    except Exception as e:
                        st.error(f"‚ùå Figure insertion test failed: {str(e)}")
                else:
                    st.error("‚ùå python-docx not available")
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 2rem; border-radius: 15px;'>
        <h3>üéØ CONTENT-BASED FILTER - T·ª∞ ƒê·ªòNG ƒê·∫æM S·ªê ·∫¢NH TH·ª∞C T·∫æ</h3>
        <div style='display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 2rem; margin-top: 1.5rem;'>
            <div style='background: rgba(255,255,255,0.1); padding: 1.5rem; border-radius: 10px;'>
                <h4>üß† Content-Based Filter</h4>
                <p>‚úÖ Ph√¢n t√≠ch n·ªôi dung th·ª±c t·∫ø<br>‚úÖ ∆Ø·ªõc t√≠nh s·ªë ·∫£nh minh h·ªça<br>‚úÖ L·ªçc b·ªè text/noise<br>‚úÖ Ch·ªâ gi·ªØ figures ch·∫•t l∆∞·ª£ng</p>
            </div>
            <div style='background: rgba(255,255,255,0.1); padding: 1.5rem; border-radius: 10px;'>
                <h4>üìÑ Clean Word Export</h4>
                <p>‚úÖ B·ªè metadata ho√†n to√†n<br>‚úÖ Ch·ªâ n·ªôi dung + figures<br>‚úÖ Dual mode support<br>‚úÖ Professional output</p>
            </div>
            <div style='background: rgba(255,255,255,0.1); padding: 1.5rem; border-radius: 10px;'>
                <h4>üîç Smart Extraction</h4>
                <p>‚úÖ 4 ph∆∞∆°ng ph√°p + AI filter<br>‚úÖ Content analysis<br>‚úÖ Quality assessment<br>‚úÖ Precision targeting</p>
            </div>
        </div>
        <div style='margin-top: 2rem; padding: 1.5rem; background: rgba(255,255,255,0.1); border-radius: 10px;'>
            <p style='margin: 0; font-size: 1.1rem;'>
                <strong>üöÄ CONTENT-BASED FILTER WORKFLOW:</strong><br>
                üìä **Analyze Layout** ‚Üí ∆Ø·ªõc t√≠nh s·ªë figures th·ª±c t·∫ø t·ª´ structure<br>
                üîç **Content Analysis** ‚Üí ƒê√°nh gi√° t·ª´ng candidate (visual complexity, text density)<br>
                üéØ **Quality Filter** ‚Üí L·ªçc theo diagram score, figure quality<br>
                üß† **Smart Limiting** ‚Üí Ch·ªâ gi·ªØ ƒë√∫ng s·ªë l∆∞·ª£ng ∆∞·ªõc t√≠nh<br>
                ‚úÖ **Result**: C·∫Øt ƒë√∫ng s·ªë ·∫£nh minh h·ªça th·ª±c t·∫ø, kh√¥ng th·ª´a kh√¥ng thi·∫øu!
            </p>
        </div>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
