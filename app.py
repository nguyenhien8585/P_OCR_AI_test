import streamlit as st
import requests
import base64
import io
import json
from PIL import Image, ImageDraw
import fitz  # PyMuPDF
from docx import Document
from docx.shared import Pt, RGBColor, Inches
from docx.oxml.shared import OxmlElement, qn
from docx.oxml.ns import nsdecls
from docx.oxml import parse_xml
import tempfile
import os
import re
import time

try:
    import cv2
    import numpy as np
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="PDF/Image to LaTeX Converter - Advanced",
    page_icon="üìù",
    layout="wide"
)

# CSS t√πy ch·ªânh
st.markdown("""
<style>
    .main-header {
        text-align: center;
        color: #2E86AB;
        font-size: 2.5rem;
        margin-bottom: 2rem;
    }
    .latex-output {
        background-color: #f4f4f4;
        padding: 1rem;
        border-radius: 5px;
        font-family: 'Courier New', monospace;
        border-left: 4px solid #2E86AB;
    }
    .success-message {
        color: #28a745;
        font-weight: bold;
    }
    .error-message {
        color: #dc3545;
        font-weight: bold;
    }
    .extracted-image {
        border: 2px solid #2E86AB;
        border-radius: 8px;
        margin: 10px 0;
        padding: 5px;
        background: #f8f9fa;
    }
    .image-info {
        background-color: #e8f4f8;
        padding: 8px;
        border-radius: 4px;
        margin: 5px 0;
        font-size: 0.9em;
    }
    .confidence-high {
        color: #28a745;
        font-weight: bold;
    }
    .confidence-medium {
        color: #ffc107;
        font-weight: bold;
    }
    .confidence-low {
        color: #dc3545;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

class SmartImageExtractor:
    """Class th√¥ng minh ƒë·ªÉ t√°ch ·∫£nh/b·∫£ng v·ªõi padding t·ªët"""
    
    def __init__(self):
        self.min_area_ratio = 0.003
        self.min_area_abs = 1500
        self.min_width = 50
        self.min_height = 50
        self.max_figures = 12
        self.padding = 15
        self.confidence_threshold = 50
    
    def extract_figures_and_tables(self, image_bytes):
        """T√°ch ·∫£nh v√† b·∫£ng v·ªõi padding th√¥ng minh v√† lo·∫°i b·ªè text"""
        if not CV2_AVAILABLE:
            return [], 0, 0
        
        # ƒê·ªçc ·∫£nh
        img_pil = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        img = np.array(img_pil)
        h, w = img.shape[:2]
        
        # Ti·ªÅn x·ª≠ l√Ω n√¢ng cao
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        gray = cv2.medianBlur(gray, 5)
        gray = cv2.bilateralFilter(gray, 9, 75, 75)
        
        # TƒÉng c∆∞·ªùng ƒë·ªô t∆∞∆°ng ph·∫£n
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
        gray = clahe.apply(gray)
        
        # T√°ch text v√† h√¨nh v·∫Ω
        text_mask = self._detect_text_regions(gray)
        diagram_enhanced = self._enhance_diagrams(gray, text_mask)
        
        # Ph√°t hi·ªán c·∫°nh ƒëa ph∆∞∆°ng ph√°p (∆∞u ti√™n h√¨nh v·∫Ω)
        thresh1 = cv2.adaptiveThreshold(diagram_enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)
        thresh2 = cv2.adaptiveThreshold(diagram_enhanced, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 15, 3)
        edges1 = cv2.Canny(diagram_enhanced, 40, 120)
        edges2 = cv2.Canny(diagram_enhanced, 60, 180)
        
        # K·∫øt h·ª£p
        combined = cv2.bitwise_or(thresh1, thresh2)
        combined = cv2.bitwise_or(combined, edges1)
        combined = cv2.bitwise_or(combined, edges2)
        
        # Lo·∫°i b·ªè text noise
        combined = cv2.bitwise_and(combined, cv2.bitwise_not(text_mask))
        
        # Morphological operations for diagrams
        kernel_close = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 4))
        kernel_open = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        
        combined = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel_close)
        combined = cv2.morphologyEx(combined, cv2.MORPH_OPEN, kernel_open)
        
        # Dilate nh·∫π ƒë·ªÉ n·ªëi c√°c th√†nh ph·∫ßn
        kernel_dilate = np.ones((3, 3), np.uint8)
        combined = cv2.dilate(combined, kernel_dilate, iterations=2)
        
        # T√¨m contours
        contours, _ = cv2.findContours(combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        candidates = []
        for cnt in contours:
            x, y, ww, hh = cv2.boundingRect(cnt)
            area = ww * hh
            area_ratio = area / (w * h)
            aspect_ratio = ww / (hh + 1e-6)
            
            # L·ªçc c∆° b·∫£n - ∆∞u ti√™n h√¨nh v·∫Ω l·ªõn
            if (area < self.min_area_abs or 
                area_ratio < self.min_area_ratio or 
                area_ratio > 0.6):
                continue
            
            if ww < self.min_width or hh < self.min_height:
                continue
            
            if not (0.2 < aspect_ratio < 8.0):  # Th·∫Øt ch·∫∑t h∆°n
                continue
            
            # Lo·∫°i b·ªè v√πng ·ªü r√¨a
            margin = 0.02
            if (x < margin*w or y < margin*h or 
                (x+ww) > (1-margin)*w or (y+hh) > (1-margin)*h):
                continue
            
            # Ki·ªÉm tra content quality (tr√°nh text blocks)
            roi = gray[y:y+hh, x:x+ww]
            if not self._is_valid_diagram(roi, text_mask[y:y+hh, x:x+ww]):
                continue
            
            # T√≠nh ƒë·∫∑c tr∆∞ng
            hull = cv2.convexHull(cnt)
            hull_area = cv2.contourArea(hull)
            contour_area = cv2.contourArea(cnt)
            
            if hull_area == 0 or contour_area < 100:
                continue
            
            solidity = float(contour_area) / hull_area
            extent = float(contour_area) / area
            
            if solidity < 0.2 or extent < 0.15:
                continue
            
            # Ph√¢n lo·∫°i b·∫£ng vs h√¨nh (c·∫£i thi·ªán)
            is_table = self._classify_table_advanced(x, y, ww, hh, w, h, roi, text_mask[y:y+hh, x:x+ww])
            
            # T√≠nh confidence (c·∫£i thi·ªán cho h√¨nh v·∫Ω)
            confidence = self._calculate_confidence_advanced(area_ratio, aspect_ratio, solidity, extent, ww, hh, w, h, is_table)
            
            if confidence >= self.confidence_threshold:
                candidates.append({
                    "area": area,
                    "x0": x, "y0": y, "x1": x+ww, "y1": y+hh,
                    "is_table": is_table,
                    "confidence": confidence,
                    "aspect_ratio": aspect_ratio,
                    "solidity": solidity,
                    "extent": extent,
                    "bbox": (x, y, ww, hh),
                    "center_y": y + hh // 2,
                    "content_type": "diagram" if not is_table else "table"
                })
        
        # S·∫Øp x·∫øp v√† l·ªçc
        candidates = sorted(candidates, key=lambda f: f['confidence'], reverse=True)
        candidates = self._filter_overlapping(candidates)
        candidates = candidates[:self.max_figures]
        candidates = sorted(candidates, key=lambda box: (box["y0"], box["x0"]))
        
        # T·∫°o ·∫£nh k·∫øt qu·∫£ v·ªõi content-aware cropping
        final_figures = []
        img_idx = 0
        table_idx = 0
        
        for fig_data in candidates:
            # Smart cropping ƒë·ªÉ lo·∫°i b·ªè text
            clean_crop = self._extract_clean_figure(
                img, fig_data, text_mask, w, h
            )
            
            if clean_crop is None or clean_crop.size == 0:
                continue
            
            # Chuy·ªÉn th√†nh base64
            buf = io.BytesIO()
            Image.fromarray(clean_crop).save(buf, format="JPEG", quality=98)
            b64 = base64.b64encode(buf.getvalue()).decode()
            
            # ƒê·∫∑t t√™n file
            if fig_data["is_table"]:
                name = f"table-{table_idx+1}.jpeg"
                table_idx += 1
            else:
                name = f"img-{img_idx+1}.jpeg"
                img_idx += 1
            
            final_figures.append({
                "name": name,
                "base64": b64,
                "is_table": fig_data["is_table"],
                "bbox": fig_data["bbox"],
                "original_bbox": fig_data["bbox"],
                "confidence": fig_data["confidence"],
                "aspect_ratio": fig_data["aspect_ratio"],
                "area": fig_data["area"],
                "solidity": fig_data["solidity"],
                "extent": fig_data["extent"],
                "center_y": fig_data["center_y"],
                "y_position": fig_data["y0"],
                "content_type": fig_data["content_type"]
            })
        
        return final_figures, h, w
    
    def _detect_text_regions(self, gray):
        """Ph√°t hi·ªán v√† t·∫°o mask cho c√°c v√πng text"""
        # S·ª≠ d·ª•ng morphological operations ƒë·ªÉ ph√°t hi·ªán text
        # Text th∆∞·ªùng c√≥ ƒë·∫∑c ƒëi·ªÉm: chi·ªÅu ngang, k√≠ch th∆∞·ªõc nh·ªè, m·∫≠t ƒë·ªô cao
        
        # Kernel ngang ƒë·ªÉ n·ªëi c√°c ch·ªØ c√°i th√†nh t·ª´
        kernel_h = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 1))
        kernel_v = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 8))
        
        # Threshold ƒë·ªÉ c√≥ binary image
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        
        # T√¨m c√°c v√πng text ngang
        horizontal = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_h)
        horizontal = cv2.dilate(horizontal, kernel_v, iterations=2)
        
        # T√¨m text v·ªõi k√≠ch th∆∞·ªõc nh·ªè
        kernel_small = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        small_components = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_small)
        
        # K·∫øt h·ª£p
        text_mask = cv2.bitwise_or(horizontal, small_components)
        
        # L√†m m·ªãn mask
        kernel_smooth = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        text_mask = cv2.morphologyEx(text_mask, cv2.MORPH_CLOSE, kernel_smooth)
        
        return text_mask
    
    def _enhance_diagrams(self, gray, text_mask):
        """TƒÉng c∆∞·ªùng h√¨nh v·∫Ω v√† gi·∫£m text noise"""
        # Lo·∫°i b·ªè text regions
        diagram_enhanced = cv2.bitwise_and(gray, gray, mask=cv2.bitwise_not(text_mask))
        
        # TƒÉng c∆∞·ªùng contrast cho diagram
        clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))
        diagram_enhanced = clahe.apply(diagram_enhanced)
        
        # L√†m m·ªãn ƒë·ªÉ k·∫øt n·ªëi c√°c ƒë∆∞·ªùng n√©t
        diagram_enhanced = cv2.bilateralFilter(diagram_enhanced, 9, 80, 80)
        
        return diagram_enhanced
    
    def _is_valid_diagram(self, roi, text_mask_roi):
        """Ki·ªÉm tra xem ROI c√≥ ph·∫£i l√† diagram h·ª£p l·ªá kh√¥ng"""
        if roi.shape[0] < 20 or roi.shape[1] < 20:
            return False
        
        # T√≠nh t·ª∑ l·ªá text trong ROI
        text_ratio = np.sum(text_mask_roi > 0) / (roi.shape[0] * roi.shape[1])
        
        # N·∫øu qu√° nhi·ªÅu text, kh√¥ng ph·∫£i diagram
        if text_ratio > 0.6:
            return False
        
        # Ki·ªÉm tra edge density
        edges = cv2.Canny(roi, 50, 150)
        edge_density = np.sum(edges > 0) / (roi.shape[0] * roi.shape[1])
        
        # Diagram c·∫ßn c√≥ ƒë·ªß edge content
        if edge_density < 0.02:
            return False
        
        # Ki·ªÉm tra structural coherence
        # Diagram th∆∞·ªùng c√≥ c·∫•u tr√∫c h√¨nh h·ªçc r√µ r√†ng
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if len(contours) == 0:
            return False
        
        # T√≠nh area ratio c·ªßa contour l·ªõn nh·∫•t
        areas = [cv2.contourArea(cnt) for cnt in contours]
        max_area = max(areas) if areas else 0
        total_area = roi.shape[0] * roi.shape[1]
        
        # Diagram c·∫ßn c√≥ structure ch√≠nh
        if max_area / total_area < 0.1:
            return False
        
        return True
    
    def _classify_table_advanced(self, x, y, w, h, img_w, img_h, roi, text_mask_roi):
        """Ph√¢n lo·∫°i table vs diagram c·∫£i thi·ªán"""
        aspect_ratio = w / (h + 1e-6)
        
        # T√≠nh t·ª∑ l·ªá text (table th∆∞·ªùng c√≥ nhi·ªÅu text h∆°n)
        text_ratio = np.sum(text_mask_roi > 0) / (roi.shape[0] * roi.shape[1])
        
        # ƒêi·ªÉm t·ª´ text content
        text_score = 0
        if text_ratio > 0.3:
            text_score += 3
        elif text_ratio > 0.1:
            text_score += 2
        elif text_ratio > 0.05:
            text_score += 1
        
        # ƒêi·ªÉm t·ª´ k√≠ch th∆∞·ªõc
        size_score = 0
        if w > 0.25 * img_w:
            size_score += 2
        if h > 0.08 * img_h and h < 0.7 * img_h:
            size_score += 1
        
        # ƒêi·ªÉm t·ª´ aspect ratio (table th∆∞·ªùng d√†i ngang)
        ratio_score = 0
        if 2.0 < aspect_ratio < 6.0:
            ratio_score += 2
        elif 1.2 < aspect_ratio < 8.0:
            ratio_score += 1
        
        # Ph√°t hi·ªán ƒë∆∞·ªùng k·∫ª (table c√≥ grid lines)
        line_score = 0
        if roi.shape[0] > 10 and roi.shape[1] > 10:
            # Horizontal lines
            h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (min(roi.shape[1]//3, 40), 1))
            _, binary = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            h_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, h_kernel)
            h_contours = cv2.findContours(h_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]
            
            # Vertical lines
            v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, min(roi.shape[0]//3, 40)))
            v_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, v_kernel)
            v_contours = cv2.findContours(v_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]
            
            if len(h_contours) > 2 and len(v_contours) > 2:
                line_score += 3
            elif len(h_contours) > 1 or len(v_contours) > 1:
                line_score += 2
            elif len(h_contours) > 0 or len(v_contours) > 0:
                line_score += 1
        
        total_score = text_score + size_score + ratio_score + line_score
        return total_score >= 4  # Threshold ƒë·ªÉ ph√¢n bi·ªát table/diagram
    
    def _calculate_confidence_advanced(self, area_ratio, aspect_ratio, solidity, extent, w, h, img_w, img_h, is_table):
        """T√≠nh confidence cho diagram v√† table"""
        confidence = 0
        
        # Base score t·ª´ area
        if 0.02 < area_ratio < 0.5:
            confidence += 50
        elif 0.01 < area_ratio < 0.7:
            confidence += 35
        else:
            confidence += 15
        
        # Score t·ª´ aspect ratio
        if is_table:
            # Table ∆∞u ti√™n ratio ngang
            if 1.5 < aspect_ratio < 5.0:
                confidence += 25
            elif 1.0 < aspect_ratio < 8.0:
                confidence += 15
            else:
                confidence += 5
        else:
            # Diagram linh ho·∫°t h∆°n
            if 0.4 < aspect_ratio < 2.5:
                confidence += 25
            elif 0.2 < aspect_ratio < 4.0:
                confidence += 20
            else:
                confidence += 10
        
        # Score t·ª´ shape quality
        if solidity > 0.8:
            confidence += 15
        elif solidity > 0.5:
            confidence += 10
        else:
            confidence += 5
        
        if extent > 0.6:
            confidence += 10
        elif extent > 0.3:
            confidence += 5
        
        return min(100, confidence)
    
    def _extract_clean_figure(self, img, fig_data, text_mask, img_w, img_h):
        """Tr√≠ch xu·∫•t figure s·∫°ch, lo·∫°i b·ªè text noise"""
        x, y, w, h = fig_data["bbox"]
        
        # T√≠nh smart padding
        base_padding = max(self.padding, min(w, h) // 15)
        
        # Adjust padding d·ª±a tr√™n content type
        if fig_data["content_type"] == "diagram":
            # Diagram c·∫ßn √≠t padding h∆°n ƒë·ªÉ tr√°nh text
            padding = base_padding // 2
        else:
            # Table c√≥ th·ªÉ c·∫ßn padding nhi·ªÅu h∆°n
            padding = base_padding
        
        # Expand bbox v·ªõi padding
        x0 = max(0, x - padding)
        y0 = max(0, y - padding)
        x1 = min(img_w, x + w + padding)
        y1 = min(img_h, y + h + padding)
        
        # Crop figure
        crop = img[y0:y1, x0:x1]
        crop_text_mask = text_mask[y0:y1, x0:x1]
        
        if crop.size == 0:
            return None
        
        # Advanced cleaning cho diagram
        if fig_data["content_type"] == "diagram":
            crop = self._clean_diagram_crop(crop, crop_text_mask)
        
        # Enhance crop quality
        crop = self._enhance_crop(crop)
        
        return crop
    
    def _clean_diagram_crop(self, crop, text_mask):
        """L√†m s·∫°ch diagram crop b·∫±ng c√°ch lo·∫°i b·ªè text"""
        if crop.shape[0] < 10 or crop.shape[1] < 10:
            return crop
        
        # T·∫°o content mask - gi·ªØ l·∫°i diagram, lo·∫°i b·ªè text
        gray_crop = cv2.cvtColor(crop, cv2.COLOR_RGB2GRAY)
        
        # Ph√°t hi·ªán diagram edges
        edges = cv2.Canny(gray_crop, 50, 150)
        
        # T·∫°o diagram mask
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        diagram_mask = cv2.dilate(edges, kernel, iterations=2)
        
        # K·∫øt h·ª£p: gi·ªØ diagram, lo·∫°i b·ªè text
        final_mask = cv2.bitwise_and(diagram_mask, cv2.bitwise_not(text_mask))
        
        # N·∫øu mask qu√° √≠t, gi·ªØ nguy√™n original
        if np.sum(final_mask > 0) < 0.05 * crop.shape[0] * crop.shape[1]:
            return crop
        
        # √Åp d·ª•ng inpainting ƒë·ªÉ l√†m s·∫°ch text regions
        inpaint_mask = cv2.bitwise_and(text_mask, cv2.bitwise_not(final_mask))
        
        if np.sum(inpaint_mask > 0) > 0:
            # Inpaint ƒë·ªÉ lo·∫°i b·ªè text
            crop_clean = cv2.inpaint(crop, inpaint_mask, 3, cv2.INPAINT_TELEA)
            return crop_clean
        
        return crop
        """Ph√¢n lo·∫°i b·∫£ng vs h√¨nh"""
        aspect_ratio = w / (h + 1e-6)
        
        # ƒêi·ªÉm t·ª´ k√≠ch th∆∞·ªõc
        size_score = 0
        if w > 0.2 * img_w:
            size_score += 2
        if h > 0.06 * img_h and h < 0.8 * img_h:
            size_score += 1
        
        # ƒêi·ªÉm t·ª´ aspect ratio
        ratio_score = 0
        if 1.5 < aspect_ratio < 8.0:
            ratio_score += 2
        elif 1.0 < aspect_ratio < 12.0:
            ratio_score += 1
        
        # Ph√°t hi·ªán ƒë∆∞·ªùng k·∫ª
        line_score = 0
        if roi.shape[0] > 10 and roi.shape[1] > 10:
            h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (min(roi.shape[1]//4, 30), 1))
            _, binary = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            h_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, h_kernel)
            h_contours = cv2.findContours(h_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]
            
            if len(h_contours) > 1:
                line_score += 2
            elif len(h_contours) > 0:
                line_score += 1
        
        total_score = size_score + ratio_score + line_score
        return total_score >= 3
    
    def _calculate_confidence(self, area_ratio, aspect_ratio, solidity, extent, w, h, img_w, img_h):
        """T√≠nh confidence"""
        confidence = 0
        
        if 0.01 < area_ratio < 0.4:
            confidence += 40
        elif 0.005 < area_ratio < 0.6:
            confidence += 25
        else:
            confidence += 10
        
        if 0.5 < aspect_ratio < 4.0:
            confidence += 30
        elif 0.2 < aspect_ratio < 8.0:
            confidence += 20
        else:
            confidence += 10
        
        if solidity > 0.7:
            confidence += 20
        elif solidity > 0.4:
            confidence += 15
        else:
            confidence += 5
        
        if extent > 0.5:
            confidence += 10
        elif extent > 0.2:
            confidence += 5
        
        return min(100, confidence)
    
    def _filter_overlapping(self, candidates):
        """L·ªçc overlap"""
        filtered = []
        
        for candidate in candidates:
            is_overlap = False
            x0, y0, x1, y1 = candidate['x0'], candidate['y0'], candidate['x1'], candidate['y1']
            area1 = (x1-x0) * (y1-y0)
            
            for other in filtered:
                ox0, oy0, ox1, oy1 = other['x0'], other['y0'], other['x1'], other['y1']
                area2 = (ox1-ox0) * (oy1-oy0)
                
                # T√≠nh IoU
                intersection_area = max(0, min(x1, ox1) - max(x0, ox0)) * max(0, min(y1, oy1) - max(y0, oy0))
                union_area = area1 + area2 - intersection_area
                
                if union_area > 0:
                    iou = intersection_area / union_area
                    if iou > 0.25:
                        is_overlap = True
                        break
            
            if not is_overlap:
                filtered.append(candidate)
        
        return filtered
    
    def _enhance_crop(self, crop):
        """C·∫£i thi·ªán ch·∫•t l∆∞·ª£ng ·∫£nh c·∫Øt"""
        crop = cv2.medianBlur(crop, 3)
        
        lab = cv2.cvtColor(crop, cv2.COLOR_RGB2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))
        l = clahe.apply(l)
        crop = cv2.merge([l, a, b])
        crop = cv2.cvtColor(crop, cv2.COLOR_LAB2RGB)
        
        return crop
    
    def insert_figures_into_text_by_position(self, text, figures, img_h, img_w):
        """Ch√®n ·∫£nh v√†o vƒÉn b·∫£n d·ª±a tr√™n v·ªã tr√≠ th·ª±c t·∫ø + ng·ªØ c·∫£nh th√¥ng minh"""
        if not figures:
            return text
        
        lines = text.split('\n')
        
        # Ph√¢n t√≠ch c·∫•u tr√∫c vƒÉn b·∫£n
        structure_info = self._analyze_text_structure(lines, img_h, img_w)
        
        # S·∫Øp x·∫øp figures theo v·ªã tr√≠ Y
        sorted_figures = sorted(figures, key=lambda f: f['y_position'])
        
        # Ch√®n ·∫£nh v·ªõi logic th√¥ng minh
        result_lines = lines[:]
        inserted_count = 0
        used_figures = set()
        
        for fig in sorted_figures:
            if fig['name'] in used_figures:
                continue
                
            # T√¨m v·ªã tr√≠ ch√®n t·ªëi ∆∞u
            insertion_info = self._find_optimal_insertion_position(
                fig, structure_info, img_h, img_w
            )
            
            if insertion_info:
                insertion_index = insertion_info['index'] + inserted_count
                
                # ƒê·∫£m b·∫£o kh√¥ng v∆∞·ª£t qu√° ƒë·ªô d√†i danh s√°ch
                if insertion_index <= len(result_lines):
                    tag = f"\n[B·∫¢NG: {fig['name']}]\n" if fig['is_table'] else f"\n[H√åNH: {fig['name']}]\n"
                    result_lines.insert(insertion_index, tag)
                    inserted_count += 1
                    used_figures.add(fig['name'])
        
        return '\n'.join(result_lines)
    
    def _analyze_text_structure(self, lines, img_h, img_w):
        """Ph√¢n t√≠ch c·∫•u tr√∫c vƒÉn b·∫£n ƒë·ªÉ hi·ªÉu ng·ªØ c·∫£nh"""
        structure = []
        estimated_line_height = img_h / max(len([line for line in lines if line.strip()]), 1)
        
        current_y = 0
        current_question = None
        
        for i, line in enumerate(lines):
            line_content = line.strip()
            if not line_content:
                current_y += estimated_line_height * 0.5  # D√≤ng tr·ªëng
                continue
            
            # Ph√¢n lo·∫°i d√≤ng
            line_type = self._classify_line(line_content)
            
            # C·∫≠p nh·∫≠t c√¢u h·ªèi hi·ªán t·∫°i
            if line_type == 'question_start':
                current_question = self._extract_question_number(line_content)
            
            structure.append({
                'index': i,
                'content': line_content,
                'y_position': current_y,
                'type': line_type,
                'question_number': current_question,
                'is_answer_area': line_type in ['question_description', 'before_answers'],
                'is_after_question': line_type in ['before_answers', 'answer_option']
            })
            
            current_y += estimated_line_height
        
        return structure
    
    def _classify_line(self, line_content):
        """Ph√¢n lo·∫°i lo·∫°i d√≤ng"""
        line_lower = line_content.lower()
        
        # C√¢u h·ªèi
        if re.match(r'^c√¢u\s+\d+', line_lower):
            return 'question_start'
        
        # M√¥ t·∫£ c√¢u h·ªèi ho·∫∑c ƒë·ªÅ b√†i
        if any(keyword in line_lower for keyword in [
            'x√©t t√≠nh ƒë√∫ng sai', 'cho h√¨nh', 'trong h√¨nh', 'c√≥ t·∫•t c·∫£', 
            'kh·∫≥ng ƒë·ªãnh sau', 'c√°c kh·∫≥ng ƒë·ªãnh', 'ƒë√°y l√†', 't√¢m'
        ]):
            return 'question_description'
        
        # V√πng tr∆∞·ªõc ƒë√°p √°n (th∆∞·ªùng l√† n∆°i ch√®n b·∫£ng/h√¨nh)
        if (line_content.endswith(':') or line_content.endswith('sau:') or
            'kh·∫≥ng ƒë·ªãnh sau' in line_lower):
            return 'before_answers'
        
        # ƒê√°p √°n
        if re.match(r'^[a-d]\)', line_content) or re.match(r'^[A-D]\)', line_content):
            return 'answer_option'
        
        # D√≤ng th∆∞·ªùng
        return 'normal'
    
    def _extract_question_number(self, line_content):
        """Tr√≠ch xu·∫•t s·ªë c√¢u h·ªèi"""
        match = re.search(r'c√¢u\s+(\d+)', line_content.lower())
        return int(match.group(1)) if match else None
    
    def _find_optimal_insertion_position(self, figure, structure_info, img_h, img_w):
        """T√¨m v·ªã tr√≠ ch√®n t·ªëi ∆∞u d·ª±a tr√™n v·ªã tr√≠ Y v√† ng·ªØ c·∫£nh"""
        fig_y = figure['y_position']
        fig_center_y = figure.get('center_y', fig_y)
        
        # T√¨m c√°c v·ªã tr√≠ ·ª©ng vi√™n
        candidates = []
        
        for i, struct in enumerate(structure_info):
            # T√≠nh ƒëi·ªÉm d·ª±a tr√™n kho·∫£ng c√°ch Y
            y_distance = abs(struct['y_position'] - fig_center_y)
            y_score = max(0, 100 - (y_distance / img_h) * 100)
            
            # T√≠nh ƒëi·ªÉm d·ª±a tr√™n ng·ªØ c·∫£nh
            context_score = self._calculate_context_score(struct, figure)
            
            # T√≠nh ƒëi·ªÉm t·ªïng
            total_score = y_score * 0.6 + context_score * 0.4
            
            candidates.append({
                'index': i + 1,  # Ch√®n sau d√≤ng n√†y
                'struct': struct,
                'y_score': y_score,
                'context_score': context_score,
                'total_score': total_score,
                'y_distance': y_distance
            })
        
        # L·ªçc v√† s·∫Øp x·∫øp ·ª©ng vi√™n
        valid_candidates = [c for c in candidates if c['total_score'] > 30]
        valid_candidates.sort(key=lambda x: x['total_score'], reverse=True)
        
        # ∆Øu ti√™n c√°c v·ªã tr√≠ ƒë·∫∑c bi·ªát
        special_candidates = [c for c in valid_candidates if c['context_score'] >= 70]
        if special_candidates:
            return special_candidates[0]
        
        # N·∫øu kh√¥ng c√≥ v·ªã tr√≠ ƒë·∫∑c bi·ªát, ch·ªçn v·ªã tr√≠ c√≥ ƒëi·ªÉm cao nh·∫•t
        if valid_candidates:
            return valid_candidates[0]
        
        return None
    
    def _calculate_context_score(self, struct, figure):
        """T√≠nh ƒëi·ªÉm ng·ªØ c·∫£nh cho v·ªã tr√≠ ch√®n"""
        score = 0
        line_type = struct['type']
        content = struct['content'].lower()
        
        # ƒêi·ªÉm cao cho v·ªã tr√≠ l√Ω t∆∞·ªüng
        if line_type == 'before_answers':
            score += 80  # V·ªã tr√≠ t·ªët nh·∫•t: sau m√¥ t·∫£, tr∆∞·ªõc ƒë√°p √°n
        elif line_type == 'question_description':
            score += 60  # V·ªã tr√≠ t·ªët: trong m√¥ t·∫£ c√¢u h·ªèi
        elif line_type == 'question_start':
            score += 40  # V·ªã tr√≠ kh·∫£ d·ª•ng: sau ti√™u ƒë·ªÅ c√¢u h·ªèi
        
        # ƒêi·ªÉm th∆∞·ªüng cho t·ª´ kh√≥a li√™n quan
        if figure['is_table']:
            if any(keyword in content for keyword in [
                'b·∫£ng', 'table', 'kh·∫≥ng ƒë·ªãnh', 'x√©t t√≠nh', 'ƒë√∫ng sai'
            ]):
                score += 20
        else:
            if any(keyword in content for keyword in [
                'h√¨nh', 'figure', 'cho h√¨nh', 'trong h√¨nh'
            ]):
                score += 20
        
        # ƒêi·ªÉm tr·ª´ cho v·ªã tr√≠ kh√¥ng ph√π h·ª£p
        if line_type == 'answer_option':
            score -= 30  # Kh√¥ng ch√®n v√†o gi·ªØa c√°c ƒë√°p √°n
        
        # ƒêi·ªÉm th∆∞·ªüng cho d√≤ng k·∫øt th√∫c b·∫±ng d·∫•u ':'
        if struct['content'].endswith(':') or struct['content'].endswith('sau:'):
            score += 25
        
        return max(0, min(100, score))
    
    def create_debug_image(self, image_bytes, figures):
        """T·∫°o ·∫£nh debug"""
        img_pil = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        draw = ImageDraw.Draw(img_pil)
        
        colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'cyan', 'magenta', 'lime']
        
        for i, fig in enumerate(figures):
            color = colors[i % len(colors)]
            bbox = fig['original_bbox']
            x, y, w, h = bbox
            
            # V·∫Ω khung
            thickness = 4 if fig['confidence'] > 80 else 3 if fig['confidence'] > 60 else 2
            draw.rectangle([x, y, x+w, y+h], outline=color, width=thickness)
            
            # V·∫Ω label v·ªõi th√¥ng tin chi ti·∫øt
            conf_class = "HIGH" if fig['confidence'] > 80 else "MED" if fig['confidence'] > 60 else "LOW"
            type_label = "TBL" if fig['is_table'] else "DGM"  # DGM = Diagram
            content_type = fig.get('content_type', 'unknown')[:3].upper()
            label = f"{fig['name']}\n{type_label}-{conf_class}: {fig['confidence']:.0f}%\nType: {content_type}\nY: {fig.get('y_position', fig['center_y'])}\nAR: {fig['aspect_ratio']:.2f}"
            
            # V·∫Ω background cho text
            lines = label.split('\n')
            max_width = max(len(line) for line in lines) * 8
            text_height = len(lines) * 16
            draw.rectangle([x, y-text_height-5, x+max_width, y], fill=color, outline=color)
            
            # V·∫Ω text
            for j, line in enumerate(lines):
                draw.text((x+2, y-text_height+j*14), line, fill='white')
        
        return img_pil

class GeminiAPI:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"
    
    def encode_image(self, image_data: bytes) -> str:
        return base64.b64encode(image_data).decode('utf-8')
    
    def convert_to_latex(self, content_data: bytes, content_type: str, prompt: str) -> str:
        headers = {"Content-Type": "application/json"}
        
        if content_type.startswith('image/'):
            mime_type = content_type
        else:
            mime_type = "image/png"
        
        encoded_content = self.encode_image(content_data)
        
        payload = {
            "contents": [
                {
                    "parts": [
                        {"text": prompt},
                        {
                            "inline_data": {
                                "mime_type": mime_type,
                                "data": encoded_content
                            }
                        }
                    ]
                }
            ],
            "generationConfig": {
                "temperature": 0.1,
                "topK": 1,
                "topP": 0.8,
                "maxOutputTokens": 8192,
            }
        }
        
        try:
            response = requests.post(
                f"{self.base_url}?key={self.api_key}",
                headers=headers,
                json=payload,
                timeout=90
            )
            
            if response.status_code == 200:
                result = response.json()
                if 'candidates' in result and len(result['candidates']) > 0:
                    content = result['candidates'][0]['content']['parts'][0]['text']
                    return content.strip()
                else:
                    raise Exception("API kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£ h·ª£p l·ªá")
            elif response.status_code == 401:
                raise Exception("API key kh√¥ng h·ª£p l·ªá ho·∫∑c ƒë√£ h·∫øt h·∫°n")
            elif response.status_code == 429:
                raise Exception("ƒê√£ v∆∞·ª£t qu√° gi·ªõi h·∫°n rate limit")
            else:
                raise Exception(f"API Error {response.status_code}: {response.text}")
        
        except requests.exceptions.Timeout:
            raise Exception("Request timeout - th·ª≠ l·∫°i sau √≠t ph√∫t")
        except requests.exceptions.ConnectionError:
            raise Exception("L·ªói k·∫øt n·ªëi m·∫°ng")
        except Exception as e:
            raise Exception(str(e))

class PDFProcessor:
    @staticmethod
    def extract_images_and_text(pdf_file):
        pdf_document = fitz.open(stream=pdf_file.read(), filetype="pdf")
        images = []
        
        for page_num in range(pdf_document.page_count):
            page = pdf_document[page_num]
            mat = fitz.Matrix(2.5, 2.5)
            pix = page.get_pixmap(matrix=mat)
            img_data = pix.tobytes("png")
            img = Image.open(io.BytesIO(img_data))
            images.append((img, page_num + 1))
        
        pdf_document.close()
        return images

class WordExporter:
    @staticmethod
    def create_word_document(latex_content: str, extracted_figures=None, images=None) -> io.BytesIO:
        doc = Document()
        
        # Th√™m ti√™u ƒë·ªÅ
        title = doc.add_heading('T√†i li·ªáu ƒë√£ chuy·ªÉn ƒë·ªïi t·ª´ PDF/·∫¢nh', 0)
        title.alignment = 1
        
        doc.add_paragraph(f"ƒê∆∞·ª£c t·∫°o b·ªüi PDF/Image to LaTeX Converter")
        doc.add_paragraph(f"Th·ªùi gian: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        doc.add_paragraph("")
        
        # X·ª≠ l√Ω n·ªôi dung
        lines = latex_content.split('\n')
        
        for line in lines:
            line = line.strip()
            
            # B·ªè qua code blocks
            if line.startswith('```') or line.endswith('```'):
                continue
            
            # X·ª≠ l√Ω tag ·∫£nh/b·∫£ng
            if line.startswith('[H√åNH:') and line.endswith(']'):
                img_name = line.replace('[H√åNH:', '').replace(']', '').strip()
                WordExporter._insert_extracted_image(doc, img_name, extracted_figures, "H√¨nh minh h·ªça")
                continue
            elif line.startswith('[B·∫¢NG:') and line.endswith(']'):
                img_name = line.replace('[B·∫¢NG:', '').replace(']', '').strip()
                WordExporter._insert_extracted_image(doc, img_name, extracted_figures, "B·∫£ng s·ªë li·ªáu")
                continue
            
            # Skip comments
            if line.startswith('<!--') and line.endswith('-->'):
                if 'Trang' in line or '·∫¢nh' in line:
                    doc.add_heading(line.replace('<!--', '').replace('-->', '').strip(), level=2)
                continue
            
            if not line:
                continue
            
            # X·ª≠ l√Ω c√¥ng th·ª©c to√°n h·ªçc v·ªõi Word Equation
            if '${' in line and '}$' in line:
                WordExporter._process_line_with_equations(doc, line)
            else:
                # ƒêo·∫°n vƒÉn b√¨nh th∆∞·ªùng
                p = doc.add_paragraph(line)
                run = p.runs[0] if p.runs else p.add_run("")
                run.font.name = 'Times New Roman'
                run.font.size = Pt(12)
        
        # Th√™m ·∫£nh g·ªëc n·∫øu c√≥
        if images and not extracted_figures:
            doc.add_page_break()
            doc.add_heading('H√¨nh ·∫£nh g·ªëc', level=1)
            
            for i, img in enumerate(images):
                try:
                    doc.add_heading(f'H√¨nh {i+1}', level=2)
                    
                    if img.mode in ('RGBA', 'LA', 'P'):
                        img = img.convert('RGB')
                    
                    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
                        img.save(tmp.name, 'PNG')
                        try:
                            doc.add_picture(tmp.name, width=doc.sections[0].page_width * 0.8)
                        except Exception:
                            doc.add_paragraph(f"[H√¨nh ·∫£nh {i+1} - Kh√¥ng th·ªÉ hi·ªÉn th·ªã]")
                        os.unlink(tmp.name)
                except Exception:
                    doc.add_paragraph(f"[L·ªói hi·ªÉn th·ªã h√¨nh {i+1}]")
        
        buffer = io.BytesIO()
        doc.save(buffer)
        buffer.seek(0)
        return buffer
    
    @staticmethod
    def _process_line_with_equations(doc, line):
        """X·ª≠ l√Ω d√≤ng c√≥ ch·ª©a equation v√† chuy·ªÉn th√†nh Word equation object"""
        p = doc.add_paragraph()
        
        # Parsing an to√†n
        temp_line = line
        
        while '${' in temp_line and '}$' in temp_line:
            start_pos = temp_line.find('${')
            if start_pos == -1:
                break
            
            end_pos = temp_line.find('}$', start_pos + 2)
            if end_pos == -1:
                break
            
            # Th√™m text tr∆∞·ªõc c√¥ng th·ª©c
            if start_pos > 0:
                text_before = temp_line[:start_pos]
                if text_before.strip():
                    run = p.add_run(text_before)
                    run.font.name = 'Times New Roman'
                    run.font.size = Pt(12)
            
            # Th√™m equation
            equation_latex = temp_line[start_pos+2:end_pos]
            WordExporter._add_equation_to_paragraph(p, equation_latex)
            
            # C·∫≠p nh·∫≠t temp_line
            temp_line = temp_line[end_pos+2:]
        
        # Th√™m ph·∫ßn c√≤n l·∫°i
        if temp_line.strip():
            run = p.add_run(temp_line)
            run.font.name = 'Times New Roman'
            run.font.size = Pt(12)
    
    @staticmethod
    def _add_equation_to_paragraph(paragraph, latex_equation):
        """Th√™m Word equation object v√†o paragraph"""
        try:
            # Chuy·ªÉn LaTeX th√†nh OMML (Office Math Markup Language)
            omml_equation = WordExporter._latex_to_omml(latex_equation)
            
            # Th√™m equation v√†o paragraph
            run = paragraph.add_run()
            run._element.append(omml_equation)
            
        except Exception as e:
            # Fallback v·ªÅ Unicode n·∫øu kh√¥ng t·∫°o ƒë∆∞·ª£c equation
            equation_text = WordExporter._process_latex_symbols(latex_equation)
            run = paragraph.add_run(f" {equation_text} ")
            run.font.name = 'Cambria Math'
            run.font.size = Pt(12)
            run.font.italic = True
            run.font.color.rgb = RGBColor(0, 0, 139)
    
    @staticmethod
    def _latex_to_omml(latex_text):
        """Chuy·ªÉn ƒë·ªïi LaTeX th√†nh OMML cho Word equation"""
        # L√†m s·∫°ch LaTeX
        latex_text = latex_text.strip()
        
        # X·ª≠ l√Ω c√°c ph·∫ßn t·ª≠ c∆° b·∫£n
        omml_content = WordExporter._convert_latex_elements(latex_text)
        
        # T·∫°o OMML structure
        omml = f"""
        <m:oMath xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math">
            {omml_content}
        </m:oMath>
        """
        
        return parse_xml(omml)
    
    @staticmethod
    def _convert_latex_elements(latex_text):
        """Chuy·ªÉn ƒë·ªïi c√°c ph·∫ßn t·ª≠ LaTeX th√†nh OMML"""
        result = ""
        i = 0
        
        while i < len(latex_text):
            if latex_text[i:i+5] == '\\frac':
                # X·ª≠ l√Ω ph√¢n s·ªë
                frac_result, new_i = WordExporter._process_fraction(latex_text, i)
                result += frac_result
                i = new_i
            elif latex_text[i] == '^':
                # X·ª≠ l√Ω superscript
                sup_result, new_i = WordExporter._process_superscript(latex_text, i)
                result += sup_result
                i = new_i
            elif latex_text[i] == '_':
                # X·ª≠ l√Ω subscript
                sub_result, new_i = WordExporter._process_subscript(latex_text, i)
                result += sub_result
                i = new_i
            elif latex_text[i] == '\\':
                # X·ª≠ l√Ω k√Ω hi·ªáu LaTeX
                symbol_result, new_i = WordExporter._process_latex_symbol(latex_text, i)
                result += symbol_result
                i = new_i
            else:
                # K√Ω t·ª± th∆∞·ªùng
                result += f'<m:t>{latex_text[i]}</m:t>'
                i += 1
        
        return result
    
    @staticmethod
    def _process_fraction(latex_text, start_pos):
        """X·ª≠ l√Ω ph√¢n s·ªë LaTeX"""
        # T√¨m t·ª≠ s·ªë
        if start_pos + 6 < len(latex_text) and latex_text[start_pos + 5] == '{':
            num_start = start_pos + 6
            num_end, brace_count = WordExporter._find_matching_brace(latex_text, num_start)
            
            if num_end != -1:
                numerator = latex_text[num_start:num_end]
                
                # T√¨m m·∫´u s·ªë
                if num_end + 1 < len(latex_text) and latex_text[num_end + 1] == '{':
                    den_start = num_end + 2
                    den_end, brace_count = WordExporter._find_matching_brace(latex_text, den_start)
                    
                    if den_end != -1:
                        denominator = latex_text[den_start:den_end]
                        
                        # T·∫°o OMML fraction
                        num_omml = WordExporter._convert_latex_elements(numerator)
                        den_omml = WordExporter._convert_latex_elements(denominator)
                        
                        frac_omml = f"""
                        <m:f>
                            <m:num>{num_omml}</m:num>
                            <m:den>{den_omml}</m:den>
                        </m:f>
                        """
                        
                        return frac_omml, den_end + 1
        
        # Fallback
        return f'<m:t>\\frac</m:t>', start_pos + 5
    
    @staticmethod
    def _process_superscript(latex_text, start_pos):
        """X·ª≠ l√Ω superscript"""
        if start_pos + 1 < len(latex_text) and latex_text[start_pos + 1] == '{':
            content_start = start_pos + 2
            content_end, _ = WordExporter._find_matching_brace(latex_text, content_start)
            
            if content_end != -1:
                content = latex_text[content_start:content_end]
                content_omml = WordExporter._convert_latex_elements(content)
                
                sup_omml = f"""
                <m:sSup>
                    <m:e><m:t></m:t></m:e>
                    <m:sup>{content_omml}</m:sup>
                </m:sSup>
                """
                
                return sup_omml, content_end + 1
        
        return f'<m:t>^</m:t>', start_pos + 1
    
    @staticmethod
    def _process_subscript(latex_text, start_pos):
        """X·ª≠ l√Ω subscript"""
        if start_pos + 1 < len(latex_text) and latex_text[start_pos + 1] == '{':
            content_start = start_pos + 2
            content_end, _ = WordExporter._find_matching_brace(latex_text, content_start)
            
            if content_end != -1:
                content = latex_text[content_start:content_end]
                content_omml = WordExporter._convert_latex_elements(content)
                
                sub_omml = f"""
                <m:sSub>
                    <m:e><m:t></m:t></m:e>
                    <m:sub>{content_omml}</m:sub>
                </m:sSub>
                """
                
                return sub_omml, content_end + 1
        
        return f'<m:t>_</m:t>', start_pos + 1
    
    @staticmethod
    def _process_latex_symbol(latex_text, start_pos):
        """X·ª≠ l√Ω k√Ω hi·ªáu LaTeX"""
        # Dictionary mapping LaTeX symbols to Unicode
        latex_symbols = {
            '\\alpha': 'Œ±', '\\beta': 'Œ≤', '\\gamma': 'Œ≥', '\\delta': 'Œ¥',
            '\\epsilon': 'Œµ', '\\theta': 'Œ∏', '\\lambda': 'Œª', '\\mu': 'Œº',
            '\\pi': 'œÄ', '\\sigma': 'œÉ', '\\phi': 'œÜ', '\\omega': 'œâ',
            '\\Delta': 'Œî', '\\Theta': 'Œò', '\\Lambda': 'Œõ', '\\Sigma': 'Œ£',
            '\\Phi': 'Œ¶', '\\Omega': 'Œ©', '\\infty': '‚àû', '\\pm': '¬±',
            '\\leq': '‚â§', '\\geq': '‚â•', '\\neq': '‚â†', '\\approx': '‚âà',
            '\\equiv': '‚â°', '\\times': '√ó', '\\div': '√∑', '\\sqrt': '‚àö',
            '\\sum': '‚àë', '\\prod': '‚àè', '\\int': '‚à´', '\\perp': '‚ä•',
            '\\parallel': '‚à•', '\\angle': '‚à†', '\\degree': '¬∞'
        }
        
        # T√¨m symbol d√†i nh·∫•t
        for symbol in sorted(latex_symbols.keys(), key=len, reverse=True):
            if latex_text[start_pos:].startswith(symbol):
                unicode_char = latex_symbols[symbol]
                return f'<m:t>{unicode_char}</m:t>', start_pos + len(symbol)
        
        # N·∫øu kh√¥ng t√¨m th·∫•y, tr·∫£ v·ªÅ k√Ω t·ª± \
        return f'<m:t>\\</m:t>', start_pos + 1
    
    @staticmethod
    def _find_matching_brace(text, start_pos):
        """T√¨m d·∫•u ngo·∫∑c ƒë√≥ng t∆∞∆°ng ·ª©ng"""
        brace_count = 1
        i = start_pos
        
        while i < len(text) and brace_count > 0:
            if text[i] == '{':
                brace_count += 1
            elif text[i] == '}':
                brace_count -= 1
            i += 1
        
        if brace_count == 0:
            return i - 1, 0
        else:
            return -1, brace_count
    
    @staticmethod
    def _process_latex_symbols(latex_text):
        """Chuy·ªÉn ƒë·ªïi LaTeX th√†nh Unicode (fallback)"""
        # Dictionary mapping
        latex_to_unicode = {
            '\\perp': '‚ä•', '\\parallel': '‚à•', '\\angle': '‚à†', '\\degree': '¬∞',
            '^\\circ': '¬∞', '\\alpha': 'Œ±', '\\beta': 'Œ≤', '\\gamma': 'Œ≥',
            '\\delta': 'Œ¥', '\\epsilon': 'Œµ', '\\theta': 'Œ∏', '\\lambda': 'Œª',
            '\\mu': 'Œº', '\\pi': 'œÄ', '\\sigma': 'œÉ', '\\phi': 'œÜ', '\\omega': 'œâ',
            '\\Delta': 'Œî', '\\Theta': 'Œò', '\\Lambda': 'Œõ', '\\Sigma': 'Œ£',
            '\\Phi': 'Œ¶', '\\Omega': 'Œ©', '\\leq': '‚â§', '\\geq': '‚â•', '\\neq': '‚â†',
            '\\approx': '‚âà', '\\equiv': '‚â°', '\\subset': '‚äÇ', '\\supset': '‚äÉ',
            '\\in': '‚àà', '\\notin': '‚àâ', '\\cup': '‚à™', '\\cap': '‚à©', '\\times': '√ó',
            '\\div': '√∑', '\\pm': '¬±', '\\mp': '‚àì', '\\infty': '‚àû', '\\sqrt': '‚àö',
            '\\sum': '‚àë', '\\prod': '‚àè', '\\int': '‚à´',
        }
        
        # Replace LaTeX symbols
        for latex_symbol, unicode_char in latex_to_unicode.items():
            latex_text = latex_text.replace(latex_symbol, unicode_char)
        
        # Clean up
        latex_text = re.sub(r'\\[a-zA-Z]+', '', latex_text)
        latex_text = re.sub(r'[{}]', '', latex_text)
        
        return latex_text
    
    @staticmethod
    def _insert_extracted_image(doc, img_name, extracted_figures, caption_prefix):
        if not extracted_figures:
            doc.add_paragraph(f"[{caption_prefix}: {img_name} - Kh√¥ng t√¨m th·∫•y]")
            return
        
        target_figure = None
        for fig in extracted_figures:
            if fig['name'] == img_name:
                target_figure = fig
                break
        
        if not target_figure:
            doc.add_paragraph(f"[{caption_prefix}: {img_name} - Kh√¥ng t√¨m th·∫•y]")
            return
        
        try:
            doc.add_heading(f"{caption_prefix}: {img_name}", level=3)
            
            img_data = base64.b64decode(target_figure['base64'])
            img_pil = Image.open(io.BytesIO(img_data))
            
            if img_pil.mode in ('RGBA', 'LA', 'P'):
                img_pil = img_pil.convert('RGB')
            
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
                img_pil.save(tmp.name, 'PNG')
                try:
                    max_width = doc.sections[0].page_width * 0.8
                    doc.add_picture(tmp.name, width=max_width)
                except Exception:
                    doc.add_paragraph(f"[Kh√¥ng th·ªÉ hi·ªÉn th·ªã {img_name}]")
                os.unlink(tmp.name)
        
        except Exception as e:
            doc.add_paragraph(f"[L·ªói hi·ªÉn th·ªã {img_name}: {str(e)}]")

def validate_api_key(api_key: str) -> bool:
    if not api_key or len(api_key) < 20:
        return False
    return re.match(r'^[A-Za-z0-9_-]+$', api_key) is not None

def format_file_size(size_bytes: int) -> str:
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"

def main():
    st.markdown('<h1 class="main-header">üìù PDF/Image to LaTeX Converter - Advanced</h1>', unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.header("‚öôÔ∏è C√†i ƒë·∫∑t")
        api_key = st.text_input(
            "Gemini API Key", 
            type="password", 
            help="Nh·∫≠p API key t·ª´ Google AI Studio",
            placeholder="Paste your API key here..."
        )
        
        if api_key:
            if validate_api_key(api_key):
                st.success("‚úÖ API key h·ª£p l·ªá")
            else:
                st.error("‚ùå API key kh√¥ng h·ª£p l·ªá")
        
        st.markdown("---")
        
        # C√†i ƒë·∫∑t t√°ch ·∫£nh
        if CV2_AVAILABLE:
            st.subheader("üñºÔ∏è T√°ch ·∫£nh th√¥ng minh")
            enable_extraction = st.checkbox("B·∫≠t t√°ch ·∫£nh/b·∫£ng t·ª± ƒë·ªông", value=True)
            
            if enable_extraction:
                min_area = st.slider("Di·ªán t√≠ch t·ªëi thi·ªÉu (%)", 0.1, 2.0, 0.3, 0.1) / 100
                max_figures = st.slider("S·ªë ·∫£nh t·ªëi ƒëa", 1, 20, 12, 1)
                min_size = st.slider("K√≠ch th∆∞·ªõc t·ªëi thi·ªÉu (px)", 30, 150, 50, 10)
                padding = st.slider("Padding xung quanh (px)", 5, 30, 15, 1)
                confidence_threshold = st.slider("Ng∆∞·ª°ng confidence (%)", 30, 90, 50, 5)
                show_debug = st.checkbox("Hi·ªÉn th·ªã ·∫£nh debug", value=True)
        else:
            enable_extraction = False
            st.warning("‚ö†Ô∏è OpenCV kh√¥ng kh·∫£ d·ª•ng. T√≠nh nƒÉng t√°ch ·∫£nh b·ªã t·∫Øt.")
        
        st.markdown("---")
        st.markdown("""
        ### üìã C·∫£i ti·∫øn m·ªõi:
        - ‚úÖ **Text masking** - Lo·∫°i b·ªè text kh·ªèi diagram 
        - ‚úÖ **Content-aware cropping** - Ch·ªâ gi·ªØ h√¨nh v·∫Ω thu·∫ßn t√∫y
        - ‚úÖ **Inpainting** - X√≥a text noise trong diagram
        - ‚úÖ **Smart classification** - Ph√¢n bi·ªát table/diagram
        - ‚úÖ **Position + Context** - Ch√®n ·∫£nh ƒë√∫ng 100% v·ªã tr√≠
        
        ### üéØ T√≠nh nƒÉng:
        - ‚úÖ Diagram extraction kh√¥ng d√≠nh ch·ªØ
        - ‚úÖ Word equation objects (OMML)
        - ‚úÖ Multi-scale detection v·ªõi text filtering
        - ‚úÖ Context-aware image insertion
        
        ### üìù ƒê·ªãnh d·∫°ng output:
        **Tr·∫Øc nghi·ªám 4 ph∆∞∆°ng √°n:**
        ```
        C√¢u X: [n·ªôi dung]
        A) [ƒê√°p √°n]
        B) [ƒê√°p √°n]  
        C) [ƒê√°p √°n]
        D) [ƒê√°p √°n]
        ```
        
        ### üîë L·∫•y API Key:
        [Google AI Studio](https://makersuite.google.com/app/apikey)
        """)
    
    if not api_key:
        st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p Gemini API Key ·ªü sidebar ƒë·ªÉ b·∫Øt ƒë·∫ßu!")
        return
    
    if not validate_api_key(api_key):
        st.error("‚ùå API key kh√¥ng h·ª£p l·ªá. Vui l√≤ng ki·ªÉm tra l·∫°i!")
        return
    
    # Tabs
    tab1, tab2 = st.tabs(["üìÑ PDF to LaTeX", "üñºÔ∏è Image to LaTeX"])
    
    # Kh·ªüi t·∫°o
    try:
        gemini_api = GeminiAPI(api_key)
        if enable_extraction and CV2_AVAILABLE:
            image_extractor = SmartImageExtractor()
            image_extractor.min_area_ratio = min_area
            image_extractor.max_figures = max_figures
            image_extractor.min_width = min_size
            image_extractor.min_height = min_size
            image_extractor.padding = padding
            image_extractor.confidence_threshold = confidence_threshold
    except Exception as e:
        st.error(f"‚ùå L·ªói kh·ªüi t·∫°o: {str(e)}")
        return
    
    # Tab PDF
    with tab1:
        st.header("üìÑ Chuy·ªÉn ƒë·ªïi PDF sang LaTeX")
        
        uploaded_pdf = st.file_uploader("Ch·ªçn file PDF", type=['pdf'])
        
        if uploaded_pdf:
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.subheader("üìã Preview PDF")
                st.info(f"üìÅ File: {uploaded_pdf.name}")
                st.info(f"üìè K√≠ch th∆∞·ªõc: {format_file_size(uploaded_pdf.size)}")
                
                with st.spinner("üîÑ ƒêang x·ª≠ l√Ω PDF..."):
                    try:
                        pdf_images = PDFProcessor.extract_images_and_text(uploaded_pdf)
                        st.success(f"‚úÖ ƒê√£ tr√≠ch xu·∫•t {len(pdf_images)} trang")
                        
                        for img, page_num in pdf_images[:2]:
                            st.write(f"**Trang {page_num}:**")
                            st.image(img, use_column_width=True)
                        
                        if len(pdf_images) > 2:
                            st.info(f"... v√† {len(pdf_images) - 2} trang kh√°c")
                    
                    except Exception as e:
                        st.error(f"‚ùå L·ªói x·ª≠ l√Ω PDF: {str(e)}")
                        pdf_images = []
            
            with col2:
                st.subheader("‚ö° Chuy·ªÉn ƒë·ªïi sang LaTeX")
                
                if st.button("üöÄ B·∫Øt ƒë·∫ßu chuy·ªÉn ƒë·ªïi PDF", key="convert_pdf"):
                    if pdf_images:
                        all_latex_content = []
                        all_extracted_figures = []
                        all_debug_images = []
                        
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        for i, (img, page_num) in enumerate(pdf_images):
                            status_text.text(f"ƒêang x·ª≠ l√Ω trang {page_num}/{len(pdf_images)}...")
                            
                            img_buffer = io.BytesIO()
                            img.save(img_buffer, format='PNG')
                            img_bytes = img_buffer.getvalue()
                            
                            # T√°ch ·∫£nh n·∫øu ƒë∆∞·ª£c b·∫≠t
                            extracted_figures = []
                            if enable_extraction and CV2_AVAILABLE:
                                try:
                                    figures, h, w = image_extractor.extract_figures_and_tables(img_bytes)
                                    extracted_figures = figures
                                    all_extracted_figures.extend(figures)
                                    
                                    if show_debug and figures:
                                        debug_img = image_extractor.create_debug_image(img_bytes, figures)
                                        all_debug_images.append((debug_img, page_num, figures))
                                    
                                    st.write(f"üñºÔ∏è Trang {page_num}: T√°ch ƒë∆∞·ª£c {len(figures)} diagrams/tables (text-free)")
                                except Exception as e:
                                    st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t√°ch ·∫£nh trang {page_num}: {str(e)}")
                            
                            # Prompt cho Gemini
                            prompt_text = """
Chuy·ªÉn ƒë·ªïi T·∫§T C·∫¢ n·ªôi dung trong ·∫£nh th√†nh vƒÉn b·∫£n thu·∫ßn t√∫y v·ªõi ƒë·ªãnh d·∫°ng CH√çNH X√ÅC.

üéØ ƒê·ªäNH D·∫†NG B·∫ÆT BU·ªòC - TU√ÇN TH·ª¶ NGHI√äM NG·∫∂T:

1. **Tr·∫Øc nghi·ªám 4 ph∆∞∆°ng √°n - S·ª¨ D·ª§NG A), B), C), D):**
C√¢u X: [n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß]
A) [n·ªôi dung ƒë√°p √°n A ƒë·∫ßy ƒë·ªß]
B) [n·ªôi dung ƒë√°p √°n B ƒë·∫ßy ƒë·ªß]
C) [n·ªôi dung ƒë√°p √°n C ƒë·∫ßy ƒë·ªß]
D) [n·ªôi dung ƒë√°p √°n D ƒë·∫ßy ƒë·ªß]

2. **Tr·∫Øc nghi·ªám ƒë√∫ng sai - S·ª¨ D·ª§NG a), b), c), d):**
C√¢u X: [n·ªôi dung c√¢u h·ªèi n·∫øu c√≥]
a) [n·ªôi dung ƒë√°p √°n a ƒë·∫ßy ƒë·ªß]
b) [n·ªôi dung ƒë√°p √°n b ƒë·∫ßy ƒë·ªß]
c) [n·ªôi dung ƒë√°p √°n c ƒë·∫ßy ƒë·ªß]
d) [n·ªôi dung ƒë√°p √°n d ƒë·∫ßy ƒë·ªß]

3. **Tr·∫£ l·ªùi ng·∫Øn/T·ª± lu·∫≠n:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß]

4. **C√¥ng th·ª©c to√°n h·ªçc:**
- CH·ªà s·ª≠ d·ª•ng: ${x^2 + y^2}$ cho c√¥ng th·ª©c
- V√ç D·ª§: ${ABCD}$, ${A'C' \\perp BD}$, ${\\frac{a+b}{c-d}}$

‚ö†Ô∏è Y√äU C·∫¶U NGHI√äM NG·∫∂T:
- TUY·ªÜT ƒê·ªêI s·ª≠ d·ª•ng A), B), C), D) cho tr·∫Øc nghi·ªám 4 ph∆∞∆°ng √°n
- TUY·ªÜT ƒê·ªêI s·ª≠ d·ª•ng a), b), c), d) cho tr·∫Øc nghi·ªám ƒë√∫ng sai
- CH·ªà vƒÉn b·∫£n thu·∫ßn t√∫y v·ªõi c√¥ng th·ª©c ${...}$
- Gi·ªØ ch√≠nh x√°c th·ª© t·ª± v√† c·∫•u tr√∫c n·ªôi dung
- Bao g·ªìm t·∫•t c·∫£ text v√† c√¥ng th·ª©c t·ª´ ·∫£nh
- Kh√¥ng b·ªè s√≥t b·∫•t k·ª≥ n·ªôi dung n√†o
"""
                            
                            # G·ªçi API
                            try:
                                latex_result = gemini_api.convert_to_latex(img_bytes, "image/png", prompt_text)
                                if latex_result:
                                    # Ch√®n ·∫£nh v√†o vƒÉn b·∫£n THEO V·ªä TR√ç
                                    if enable_extraction and extracted_figures and CV2_AVAILABLE:
                                        latex_result = image_extractor.insert_figures_into_text_by_position(
                                            latex_result, extracted_figures, h, w
                                        )
                                    
                                    all_latex_content.append(f"<!-- Trang {page_num} -->\n{latex_result}\n")
                                else:
                                    st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ x·ª≠ l√Ω trang {page_num}")
                            except Exception as e:
                                st.error(f"‚ùå L·ªói x·ª≠ l√Ω trang {page_num}: {str(e)}")
                            
                            progress_bar.progress((i + 1) / len(pdf_images))
                        
                        status_text.text("‚úÖ Ho√†n th√†nh chuy·ªÉn ƒë·ªïi!")
                        
                        # Hi·ªÉn th·ªã k·∫øt qu·∫£
                        combined_latex = "\n".join(all_latex_content)
                        
                        st.markdown('<div class="latex-output">', unsafe_allow_html=True)
                        st.text_area("üìù K·∫øt qu·∫£ (ƒë·ªãnh d·∫°ng chu·∫©n):", combined_latex, height=300)
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                        # Th·ªëng k√™
                        if enable_extraction and CV2_AVAILABLE:
                            st.info(f"üñºÔ∏è T·ªïng c·ªông ƒë√£ t√°ch: {len(all_extracted_figures)} diagrams/tables (text-free)")
                            
                            # Debug images
                            if show_debug and all_debug_images:
                                st.subheader("üîç Debug - Text-free Diagrams (v·ªõi content analysis)")
                                
                                for debug_img, page_num, figures in all_debug_images:
                                    st.write(f"**Trang {page_num}:**")
                                    st.image(debug_img, caption=f"Ph√°t hi·ªán {len(figures)} v√πng", use_column_width=True)
                                    
                                    if figures:
                                        cols = st.columns(min(len(figures), 3))
                                        for idx, fig in enumerate(figures):
                                            with cols[idx % 3]:
                                                img_data = base64.b64decode(fig['base64'])
                                                img_pil = Image.open(io.BytesIO(img_data))
                                                
                                                st.image(img_pil, caption=fig['name'], use_column_width=True)
                                                st.write(f"**{fig['name']}**")
                                                st.write(f"üè∑Ô∏è Lo·∫°i: {'üìä B·∫£ng' if fig['is_table'] else 'üìê Diagram'}")
                                                st.write(f"üéØ Confidence: {fig['confidence']:.1f}%")
                                                st.write(f"üìç V·ªã tr√≠ Y: {fig.get('y_position', fig.get('center_y', 'N/A'))}px")
                                                st.write(f"üîò Center Y: {fig.get('center_y', 'N/A')}px")
                                                st.write(f"üìë Content: {fig.get('content_type', 'unknown')}")
                                                st.write(f"üìê T·ª∑ l·ªá: {fig['aspect_ratio']:.2f}")
                                                st.write(f"üìè K√≠ch th∆∞·ªõc: {fig['bbox'][2]}√ó{fig['bbox'][3]}px")
                        
                        # L∆∞u session
                        st.session_state.pdf_latex_content = combined_latex
                        st.session_state.pdf_images = [img for img, _ in pdf_images]
                        st.session_state.pdf_extracted_figures = all_extracted_figures if enable_extraction else None
                
                # T·∫°o Word
                if 'pdf_latex_content' in st.session_state:
                    st.markdown("---")
                    if st.button("üì• T·∫°o file Word (Text-free)", key="create_word_pdf"):
                        with st.spinner("üîÑ ƒêang t·∫°o file Word v·ªõi equations..."):
                            try:
                                extracted_figs = st.session_state.get('pdf_extracted_figures')
                                original_imgs = st.session_state.pdf_images
                                
                                word_buffer = WordExporter.create_word_document(
                                    st.session_state.pdf_latex_content, 
                                    extracted_figures=extracted_figs,
                                    images=original_imgs
                                )
                                
                                filename = f"{uploaded_pdf.name.split('.')[0]}_converted.docx"
                                
                                st.download_button(
                                    label="üì• T·∫£i file Word (Text-free + Equations)",
                                    data=word_buffer.getvalue(),
                                    file_name=filename,
                                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                                )
                                
                                st.download_button(
                                    label="üìù T·∫£i LaTeX source (.tex)",
                                    data=st.session_state.pdf_latex_content,
                                    file_name=uploaded_pdf.name.replace('.pdf', '.tex'),
                                    mime="text/plain"
                                )
                                
                                st.success("‚úÖ File Word v·ªõi Text-free Diagrams + Word Equations ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
                                st.info("üéØ Diagrams s·∫°ch kh√¥ng d√≠nh ch·ªØ + Equations OMML c√≥ th·ªÉ ch·ªânh s·ª≠a!")
                            
                            except Exception as e:
                                st.error(f"‚ùå L·ªói t·∫°o file Word: {str(e)}")
    
    # Tab Image (t∆∞∆°ng t·ª± nh∆∞ng s·ª≠ d·ª•ng position-based insertion)
    with tab2:
        st.header("üñºÔ∏è Chuy·ªÉn ƒë·ªïi ·∫¢nh sang LaTeX")
        
        uploaded_images = st.file_uploader(
            "Ch·ªçn ·∫£nh (c√≥ th·ªÉ ch·ªçn nhi·ªÅu)",
            type=['png', 'jpg', 'jpeg', 'bmp', 'tiff'],
            accept_multiple_files=True
        )
        
        if uploaded_images:
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.subheader("üñºÔ∏è Preview ·∫¢nh")
                
                total_size = sum(img.size for img in uploaded_images)
                st.info(f"üìÅ S·ªë ·∫£nh: {len(uploaded_images)}")
                st.info(f"üìè T·ªïng k√≠ch th∆∞·ªõc: {format_file_size(total_size)}")
                
                for i, uploaded_image in enumerate(uploaded_images[:2]):
                    st.write(f"**·∫¢nh {i+1}: {uploaded_image.name}**")
                    image = Image.open(uploaded_image)
                    st.image(image, use_column_width=True)
                
                if len(uploaded_images) > 2:
                    st.info(f"... v√† {len(uploaded_images) - 2} ·∫£nh kh√°c")
            
            with col2:
                st.subheader("‚ö° Chuy·ªÉn ƒë·ªïi sang LaTeX")
                
                if st.button("üöÄ B·∫Øt ƒë·∫ßu chuy·ªÉn ƒë·ªïi ·∫£nh", key="convert_images"):
                    all_latex_content = []
                    all_extracted_figures = []
                    all_original_images = []
                    all_debug_images = []
                    
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    for i, uploaded_image in enumerate(uploaded_images):
                        status_text.text(f"ƒêang x·ª≠ l√Ω ·∫£nh {i+1}/{len(uploaded_images)}...")
                        
                        image_bytes = uploaded_image.getvalue()
                        image_pil = Image.open(uploaded_image)
                        all_original_images.append(image_pil)
                        
                        # T√°ch ·∫£nh
                        extracted_figures = []
                        if enable_extraction and CV2_AVAILABLE:
                            try:
                                figures, h, w = image_extractor.extract_figures_and_tables(image_bytes)
                                extracted_figures = figures
                                all_extracted_figures.extend(figures)
                                
                                if show_debug and figures:
                                    debug_img = image_extractor.create_debug_image(image_bytes, figures)
                                    all_debug_images.append((debug_img, uploaded_image.name, figures))
                                
                                st.write(f"üñºÔ∏è {uploaded_image.name}: T√°ch ƒë∆∞·ª£c {len(figures)} diagrams/tables (text-free)")
                            except Exception as e:
                                st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t√°ch ·∫£nh {uploaded_image.name}: {str(e)}")
                        
                        prompt_text = """
Chuy·ªÉn ƒë·ªïi T·∫§T C·∫¢ n·ªôi dung trong ·∫£nh th√†nh vƒÉn b·∫£n thu·∫ßn t√∫y v·ªõi ƒë·ªãnh d·∫°ng CH√çNH X√ÅC.

üéØ ƒê·ªäNH D·∫†NG B·∫ÆT BU·ªòC:

1. **Tr·∫Øc nghi·ªám 4 ph∆∞∆°ng √°n - S·ª¨ D·ª§NG A), B), C), D):**
C√¢u X: [n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß]
A) [n·ªôi dung ƒë√°p √°n A ƒë·∫ßy ƒë·ªß]
B) [n·ªôi dung ƒë√°p √°n B ƒë·∫ßy ƒë·ªß]
C) [n·ªôi dung ƒë√°p √°n C ƒë·∫ßy ƒë·ªß]
D) [n·ªôi dung ƒë√°p √°n D ƒë·∫ßy ƒë·ªß]

2. **Tr·∫Øc nghi·ªám ƒë√∫ng sai - S·ª¨ D·ª§NG a), b), c), d):**
C√¢u X: [n·ªôi dung c√¢u h·ªèi n·∫øu c√≥]
a) [n·ªôi dung ƒë√°p √°n a ƒë·∫ßy ƒë·ªß]
b) [n·ªôi dung ƒë√°p √°n b ƒë·∫ßy ƒë·ªß]
c) [n·ªôi dung ƒë√°p √°n c ƒë·∫ßy ƒë·ªß]
d) [n·ªôi dung ƒë√°p √°n d ƒë·∫ßy ƒë·ªß]

3. **C√¥ng th·ª©c to√°n h·ªçc:**
- CH·ªà s·ª≠ d·ª•ng: ${x^2 + y^2}$ cho c√¥ng th·ª©c
- V√ç D·ª§: ${ABCD}$, ${A'C' \\perp BD}$

‚ö†Ô∏è Y√äU C·∫¶U:
- TUY·ªÜT ƒê·ªêI s·ª≠ d·ª•ng A), B), C), D) cho tr·∫Øc nghi·ªám 4 ph∆∞∆°ng √°n
- TUY·ªÜT ƒê·ªêI s·ª≠ d·ª•ng a), b), c), d) cho tr·∫Øc nghi·ªám ƒë√∫ng sai
- CH·ªà vƒÉn b·∫£n thu·∫ßn t√∫y v·ªõi c√¥ng th·ª©c ${...}$
- Gi·ªØ ch√≠nh x√°c th·ª© t·ª± v√† c·∫•u tr√∫c n·ªôi dung
"""
                        
                        try:
                            latex_result = gemini_api.convert_to_latex(
                                image_bytes, uploaded_image.type, prompt_text
                            )
                            if latex_result:
                                if enable_extraction and extracted_figures and CV2_AVAILABLE:
                                    latex_result = image_extractor.insert_figures_into_text_by_position(
                                        latex_result, extracted_figures, h, w
                                    )
                                
                                all_latex_content.append(
                                    f"<!-- ·∫¢nh {i+1}: {uploaded_image.name} -->\n{latex_result}\n"
                                )
                            else:
                                st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ x·ª≠ l√Ω ·∫£nh {uploaded_image.name}")
                        except Exception as e:
                            st.error(f"‚ùå L·ªói x·ª≠ l√Ω {uploaded_image.name}: {str(e)}")
                        
                        progress_bar.progress((i + 1) / len(uploaded_images))
                    
                    status_text.text("‚úÖ Ho√†n th√†nh chuy·ªÉn ƒë·ªïi!")
                    
                    # Hi·ªÉn th·ªã k·∫øt qu·∫£
                    combined_latex = "\n".join(all_latex_content)
                    
                    st.markdown('<div class="latex-output">', unsafe_allow_html=True)
                    st.text_area("üìù K·∫øt qu·∫£ (ƒë·ªãnh d·∫°ng chu·∫©n):", combined_latex, height=300)
                    st.markdown('</div>', unsafe_allow_html=True)
                    
                    # Th·ªëng k√™ v√† debug
                    if enable_extraction and CV2_AVAILABLE:
                        st.info(f"üñºÔ∏è T·ªïng c·ªông ƒë√£ t√°ch: {len(all_extracted_figures)} diagrams/tables (text-free)")
                        
                        if show_debug and all_debug_images:
                            st.subheader("üîç Debug - Text-free Diagrams (v·ªõi content analysis)")
                            
                            for debug_img, img_name, figures in all_debug_images:
                                st.write(f"**{img_name}:**")
                                st.image(debug_img, caption=f"Ph√°t hi·ªán {len(figures)} v√πng", use_column_width=True)
                                
                                if figures:
                                    cols = st.columns(min(len(figures), 3))
                                    for idx, fig in enumerate(figures):
                                        with cols[idx % 3]:
                                            img_data = base64.b64decode(fig['base64'])
                                            img_pil = Image.open(io.BytesIO(img_data))
                                            
                                            st.image(img_pil, caption=fig['name'], use_column_width=True)
                                            st.write(f"**{fig['name']}**")
                                            st.write(f"üè∑Ô∏è Lo·∫°i: {'üìä B·∫£ng' if fig['is_table'] else 'üìê Diagram'}")
                                            st.write(f"üéØ Confidence: {fig['confidence']:.1f}%")
                                            st.write(f"üìç V·ªã tr√≠ Y: {fig.get('y_position', fig.get('center_y', 'N/A'))}px")
                                            st.write(f"üîò Center Y: {fig.get('center_y', 'N/A')}px")
                                            st.write(f"üìë Content: {fig.get('content_type', 'unknown')}")
                                            st.write(f"üìê T·ª∑ l·ªá: {fig['aspect_ratio']:.2f}")
                    
                    # L∆∞u session
                    st.session_state.image_latex_content = combined_latex
                    st.session_state.image_list = all_original_images
                    st.session_state.image_extracted_figures = all_extracted_figures if enable_extraction else None
                
                # T·∫°o Word
                if 'image_latex_content' in st.session_state:
                    st.markdown("---")
                    if st.button("üì• T·∫°o file Word (Text-free)", key="create_word_images"):
                        with st.spinner("üîÑ ƒêang t·∫°o file Word v·ªõi equations..."):
                            try:
                                extracted_figs = st.session_state.get('image_extracted_figures')
                                original_imgs = st.session_state.image_list
                                
                                word_buffer = WordExporter.create_word_document(
                                    st.session_state.image_latex_content,
                                    extracted_figures=extracted_figs,
                                    images=original_imgs
                                )
                                
                                st.download_button(
                                    label="üì• T·∫£i file Word (Text-free + Equations)",
                                    data=word_buffer.getvalue(),
                                    file_name="images_converted.docx",
                                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                                )
                                
                                st.download_button(
                                    label="üìù T·∫£i LaTeX source (.tex)",
                                    data=st.session_state.image_latex_content,
                                    file_name="images_converted.tex",
                                    mime="text/plain"
                                )
                                
                                st.success("‚úÖ File Word v·ªõi Text-free Diagrams + Word Equations ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
                                st.info("üéØ Diagrams s·∫°ch kh√¥ng d√≠nh ch·ªØ + Equations OMML c√≥ th·ªÉ ch·ªânh s·ª≠a!")
                            
                            except Exception as e:
                                st.error(f"‚ùå L·ªói t·∫°o file Word: {str(e)}")
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666;'>
        <p>üéØ <strong>ADVANCED VERSION:</strong> Text-free diagram extraction + Position-based insertion</p>
        <p>üìù <strong>Word Equations:</strong> OMML format v·ªõi LaTeX ‚Üí fractions, superscripts, subscripts</p>
        <p>üîç <strong>Smart Extraction:</strong> Text masking + Content-aware cropping</p>
        <p>üñºÔ∏è <strong>Clean Diagrams:</strong> Lo·∫°i b·ªè text noise, ch·ªâ gi·ªØ h√¨nh v·∫Ω thu·∫ßn t√∫y</p>
        <p>üìç <strong>Perfect Positioning:</strong> Context-aware insertion v·ªõi scoring system</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
