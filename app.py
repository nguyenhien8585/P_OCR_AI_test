import streamlit as st
import requests
import base64
import io
import json
from PIL import Image, ImageDraw, ImageFont
import fitz  # PyMuPDF
from docx import Document
import tempfile
import os
import re
import time
import cv2
import numpy as np

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="PDF/Image to LaTeX Converter - Ultra Enhanced",
    page_icon="üìù",
    layout="wide"
)

# CSS t√πy ch·ªânh
st.markdown("""
<style>
    .main-header {
        text-align: center;
        color: #2E86AB;
        font-size: 2.5rem;
        margin-bottom: 2rem;
    }
    .latex-output {
        background-color: #f4f4f4;
        padding: 1rem;
        border-radius: 5px;
        font-family: 'Courier New', monospace;
        border-left: 4px solid #2E86AB;
    }
    .success-message {
        color: #28a745;
        font-weight: bold;
    }
    .error-message {
        color: #dc3545;
        font-weight: bold;
    }
    .extracted-image {
        border: 2px solid #2E86AB;
        border-radius: 8px;
        margin: 10px 0;
        padding: 5px;
        background: #f8f9fa;
    }
    .image-info {
        background-color: #e8f4f8;
        padding: 8px;
        border-radius: 4px;
        margin: 5px 0;
        font-size: 0.9em;
    }
    .confidence-high { color: #28a745; font-weight: bold; }
    .confidence-medium { color: #ffc107; font-weight: bold; }
    .confidence-low { color: #dc3545; font-weight: bold; }
</style>
""", unsafe_allow_html=True)

class UltraImageExtractor:
    """
    Class si√™u n√¢ng cao ƒë·ªÉ t√°ch ·∫£nh/b·∫£ng v·ªõi ƒë·ªô ch√≠nh x√°c c·ª±c cao
    """
    
    def __init__(self):
        self.min_area_ratio = 0.003    # Di·ªán t√≠ch t·ªëi thi·ªÉu (% c·ªßa ·∫£nh g·ªëc)
        self.min_area_abs = 1000       # Di·ªán t√≠ch t·ªëi thi·ªÉu (pixel)
        self.min_width = 40            # Chi·ªÅu r·ªông t·ªëi thi·ªÉu
        self.min_height = 40           # Chi·ªÅu cao t·ªëi thi·ªÉu
        self.max_figures = 12          # S·ªë l∆∞·ª£ng ·∫£nh t·ªëi ƒëa
        self.padding = 8               # Padding xung quanh ·∫£nh c·∫Øt
        self.confidence_threshold = 50 # Ng∆∞·ª°ng confidence t·ªëi thi·ªÉu
    
    def extract_figures_and_tables(self, image_bytes):
        """T√°ch ·∫£nh v√† b·∫£ng v·ªõi thu·∫≠t to√°n si√™u ch√≠nh x√°c"""
        # 1. ƒê·ªçc v√† ti·ªÅn x·ª≠ l√Ω ·∫£nh
        img_pil = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        img = np.array(img_pil)
        h, w = img.shape[:2]
        
        # 2. Ti·ªÅn x·ª≠ l√Ω ·∫£nh ƒëa c·∫•p ƒë·ªô
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        
        # Kh·ª≠ nhi·ªÖu m·∫°nh
        gray = cv2.medianBlur(gray, 5)
        gray = cv2.bilateralFilter(gray, 9, 75, 75)
        
        # TƒÉng c∆∞·ªùng ƒë·ªô t∆∞∆°ng ph·∫£n adaptive
        clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))
        gray = clahe.apply(gray)
        
        # 3. Ph√°t hi·ªán c·∫°nh ƒëa ph∆∞∆°ng ph√°p
        # Ph∆∞∆°ng ph√°p 1: Adaptive threshold v·ªõi nhi·ªÅu k√≠ch th∆∞·ªõc kernel
        thresh1 = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)
        thresh2 = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 15, 3)
        
        # Ph∆∞∆°ng ph√°p 2: Canny v·ªõi multiple scales
        edges1 = cv2.Canny(gray, 30, 100, apertureSize=3)
        edges2 = cv2.Canny(gray, 50, 150, apertureSize=3)
        edges3 = cv2.Canny(gray, 80, 200, apertureSize=5)
        
        # Ph∆∞∆°ng ph√°p 3: Gradient-based detection
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        gradient = np.sqrt(sobelx**2 + sobely**2)
        gradient = np.uint8(gradient / gradient.max() * 255)
        _, gradient_thresh = cv2.threshold(gradient, 50, 255, cv2.THRESH_BINARY)
        
        # 4. K·∫øt h·ª£p t·∫•t c·∫£ ph∆∞∆°ng ph√°p
        combined = cv2.bitwise_or(thresh1, thresh2)
        combined = cv2.bitwise_or(combined, edges1)
        combined = cv2.bitwise_or(combined, edges2) 
        combined = cv2.bitwise_or(combined, edges3)
        combined = cv2.bitwise_or(combined, gradient_thresh)
        
        # 5. Morphological operations ƒë·ªÉ l√†m s·∫°ch
        kernel_close = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        kernel_open = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        
        combined = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel_close)
        combined = cv2.morphologyEx(combined, cv2.MORPH_OPEN, kernel_open)
        
        # Dilate nh·∫π ƒë·ªÉ k·∫øt n·ªëi c√°c th√†nh ph·∫ßn
        kernel_dilate = np.ones((2, 2), np.uint8)
        combined = cv2.dilate(combined, kernel_dilate, iterations=1)
        
        # 6. T√¨m contours v·ªõi hierarchy
        contours, hierarchy = cv2.findContours(combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # 7. L·ªçc v√† ph√¢n t√≠ch contours v·ªõi nhi·ªÅu ti√™u ch√≠
        candidates = []
        
        for i, cnt in enumerate(contours):
            # T√≠nh to√°n bounding box
            x, y, ww, hh = cv2.boundingRect(cnt)
            area = ww * hh
            area_ratio = area / (w * h)
            aspect_ratio = ww / (hh + 1e-6)
            
            # L·ªçc k√≠ch th∆∞·ªõc c∆° b·∫£n
            if (area < self.min_area_abs or 
                area_ratio < self.min_area_ratio or 
                area_ratio > 0.8):
                continue
            
            if ww < self.min_width or hh < self.min_height:
                continue
            
            # L·ªçc aspect ratio h·ª£p l√Ω
            if not (0.05 < aspect_ratio < 20.0):
                continue
            
            # Lo·∫°i b·ªè v√πng ·ªü r√¨a ·∫£nh
            margin = 0.01
            if (x < margin*w or y < margin*h or 
                (x+ww) > (1-margin)*w or (y+hh) > (1-margin)*h):
                continue
            
            # T√≠nh c√°c ƒë·∫∑c tr∆∞ng h√¨nh h·ªçc n√¢ng cao
            hull = cv2.convexHull(cnt)
            hull_area = cv2.contourArea(hull)
            contour_area = cv2.contourArea(cnt)
            
            if hull_area == 0 or contour_area < 100:
                continue
            
            # T√≠nh to√°n c√°c metrics ch·∫•t l∆∞·ª£ng
            solidity = float(contour_area) / hull_area
            extent = float(contour_area) / area
            
            # T√≠nh chu vi v√† circularity
            perimeter = cv2.arcLength(cnt, True)
            if perimeter == 0:
                continue
            circularity = 4 * np.pi * contour_area / (perimeter ** 2)
            
            # L·ªçc c√°c shape qu√° ph·ª©c t·∫°p ho·∫∑c qu√° ƒë∆°n gi·∫£n
            if solidity < 0.2 or extent < 0.15:
                continue
            
            # T√≠nh moments ƒë·ªÉ ki·ªÉm tra shape regularity
            moments = cv2.moments(cnt)
            if moments['m00'] == 0:
                continue
            
            # Ph√¢n t√≠ch n·ªôi dung v√πng ƒë·ªÉ ph√¢n lo·∫°i
            roi = gray[y:y+hh, x:x+ww]
            content_analysis = self._analyze_region_content(roi)
            
            # Ph√¢n lo·∫°i b·∫£ng vs h√¨nh
            is_table = self._advanced_table_classification(x, y, ww, hh, w, h, cnt, roi, content_analysis)
            
            # T√≠nh ƒëi·ªÉm confidence n√¢ng cao
            confidence = self._calculate_advanced_confidence(
                area_ratio, aspect_ratio, solidity, extent, circularity,
                ww, hh, w, h, content_analysis, contour_area
            )
            
            # Ch·ªâ gi·ªØ l·∫°i nh·ªØng v√πng c√≥ confidence cao
            if confidence < self.confidence_threshold:
                continue
            
            candidates.append({
                "area": area,
                "x0": x, "y0": y, "x1": x+ww, "y1": y+hh,
                "width": ww, "height": hh,
                "is_table": is_table,
                "confidence": confidence,
                "aspect_ratio": aspect_ratio,
                "solidity": solidity,
                "extent": extent,
                "circularity": circularity,
                "content_analysis": content_analysis,
                "bbox": (x, y, ww, hh),
                "contour": cnt
            })
        
        # 8. S·∫Øp x·∫øp v√† l·ªçc overlapping v·ªõi thu·∫≠t to√°n NMS
        candidates = sorted(candidates, key=lambda f: f['confidence'], reverse=True)
        candidates = self._non_maximum_suppression(candidates, iou_threshold=0.3)
        candidates = candidates[:self.max_figures]
        
        # 9. S·∫Øp x·∫øp theo v·ªã tr√≠ ƒë·ªçc (top-to-bottom, left-to-right)
        candidates = sorted(candidates, key=lambda box: (box["y0"] + box["height"]//2, box["x0"]))
        
        # 10. T·∫°o ·∫£nh k·∫øt qu·∫£ v·ªõi quality cao
        final_figures = []
        img_idx = 0
        table_idx = 0
        
        for fig_data in candidates:
            # C·∫Øt ·∫£nh v·ªõi padding th√¥ng minh
            x0 = max(0, fig_data["x0"] - self.padding)
            y0 = max(0, fig_data["y0"] - self.padding)
            x1 = min(w, fig_data["x1"] + self.padding)
            y1 = min(h, fig_data["y1"] + self.padding)
            
            crop = img[y0:y1, x0:x1]
            
            if crop.size == 0:
                continue
            
            # Post-process ·∫£nh c·∫Øt
            crop = self._enhance_cropped_image(crop)
            
            # Chuy·ªÉn th√†nh base64 v·ªõi quality cao
            buf = io.BytesIO()
            Image.fromarray(crop).save(buf, format="JPEG", quality=98, optimize=True)
            b64 = base64.b64encode(buf.getvalue()).decode()
            
            # ƒê·∫∑t t√™n file th√¥ng minh
            if fig_data["is_table"]:
                name = f"table-{table_idx+1}.jpeg"
                table_idx += 1
            else:
                name = f"img-{img_idx+1}.jpeg"
                img_idx += 1
            
            final_figures.append({
                "name": name,
                "base64": b64,
                "is_table": fig_data["is_table"],
                "bbox": (x0, y0, x1-x0, y1-y0),
                "original_bbox": fig_data["bbox"],
                "confidence": fig_data["confidence"],
                "aspect_ratio": fig_data["aspect_ratio"],
                "area": fig_data["area"],
                "solidity": fig_data["solidity"],
                "content_analysis": fig_data["content_analysis"]
            })
        
        return final_figures, h, w
    
    def _analyze_region_content(self, roi):
        """Ph√¢n t√≠ch n·ªôi dung v√πng ƒë·ªÉ h·ªó tr·ª£ ph√¢n lo·∫°i"""
        if roi.shape[0] < 10 or roi.shape[1] < 10:
            return {"has_text": False, "has_lines": 0, "density": 0, "uniformity": 0}
        
        # Ph√°t hi·ªán text regions (v√πng c√≥ nhi·ªÅu pixel ƒëen nh·ªè)
        kernel_text = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 1))
        _, binary = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        text_regions = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_text)
        has_text = np.sum(text_regions) > roi.shape[0] * roi.shape[1] * 0.05
        
        # Ph√°t hi·ªán ƒë∆∞·ªùng k·∫ª ngang v√† d·ªçc
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (min(roi.shape[1]//3, 40), 1))
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, min(roi.shape[0]//3, 40)))
        
        horizontal_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, horizontal_kernel)
        vertical_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, vertical_kernel)
        
        h_lines = len(cv2.findContours(horizontal_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0])
        v_lines = len(cv2.findContours(vertical_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0])
        
        # T√≠nh m·∫≠t ƒë·ªô pixel
        density = np.sum(binary) / (roi.shape[0] * roi.shape[1] * 255)
        
        # T√≠nh ƒë·ªô ƒë·ªìng ƒë·ªÅu (uniformity)
        hist = cv2.calcHist([roi], [0], None, [256], [0, 256])
        uniformity = np.sum((hist / hist.sum()) ** 2)
        
        return {
            "has_text": has_text,
            "has_lines": h_lines + v_lines,
            "h_lines": h_lines,
            "v_lines": v_lines,
            "density": density,
            "uniformity": uniformity
        }
    
    def _advanced_table_classification(self, x, y, w, h, img_w, img_h, contour, roi, content_analysis):
        """Ph√¢n lo·∫°i b·∫£ng vs h√¨nh ·∫£nh v·ªõi thu·∫≠t to√°n n√¢ng cao"""
        aspect_ratio = w / (h + 1e-6)
        
        # ƒêi·ªÉm t·ª´ k√≠ch th∆∞·ªõc v√† t·ª∑ l·ªá
        size_score = 0
        if w > 0.25 * img_w:  # B·∫£ng th∆∞·ªùng r·ªông
            size_score += 3
        if h > 0.08 * img_h and h < 0.7 * img_h:  # Chi·ªÅu cao v·ª´a ph·∫£i
            size_score += 2
        if 1.5 < aspect_ratio < 10.0:  # T·ª∑ l·ªá ph√π h·ª£p cho b·∫£ng
            size_score += 3
        
        # ƒêi·ªÉm t·ª´ ph√¢n t√≠ch n·ªôi dung
        content_score = 0
        if content_analysis["has_lines"] > 2:  # C√≥ ƒë∆∞·ªùng k·∫ª
            content_score += 4
        if content_analysis["h_lines"] > 1:  # C√≥ ƒë∆∞·ªùng k·∫ª ngang
            content_score += 3
        if content_analysis["v_lines"] > 0:  # C√≥ ƒë∆∞·ªùng k·∫ª d·ªçc
            content_score += 2
        if content_analysis["has_text"]:  # C√≥ text
            content_score += 2
        if 0.1 < content_analysis["density"] < 0.4:  # M·∫≠t ƒë·ªô v·ª´a ph·∫£i
            content_score += 2
        
        # ƒêi·ªÉm t·ª´ v·ªã tr√≠ (b·∫£ng th∆∞·ªùng ·ªü gi·ªØa)
        position_score = 0
        center_x_ratio = (x + w/2) / img_w
        if 0.1 < center_x_ratio < 0.9:
            position_score += 1
        
        total_score = size_score + content_score + position_score
        
        # Ng∆∞·ª°ng ph√¢n lo·∫°i ƒë·ªông d·ª±a tr√™n confidence
        threshold = 6 if content_analysis["has_lines"] > 3 else 8
        
        return total_score >= threshold
    
    def _calculate_advanced_confidence(self, area_ratio, aspect_ratio, solidity, extent, 
                                     circularity, w, h, img_w, img_h, content_analysis, contour_area):
        """T√≠nh confidence score n√¢ng cao"""
        confidence = 0
        
        # ƒêi·ªÉm t·ª´ k√≠ch th∆∞·ªõc (30 ƒëi·ªÉm)
        if 0.005 < area_ratio < 0.6:
            if 0.02 < area_ratio < 0.3:
                confidence += 30
            elif 0.01 < area_ratio < 0.5:
                confidence += 20
            else:
                confidence += 10
        
        # ƒêi·ªÉm t·ª´ aspect ratio (25 ƒëi·ªÉm)
        if 0.3 < aspect_ratio < 5.0:
            confidence += 25
        elif 0.1 < aspect_ratio < 10.0:
            confidence += 15
        elif 0.05 < aspect_ratio < 20.0:
            confidence += 5
        
        # ƒêi·ªÉm t·ª´ solidity (20 ƒëi·ªÉm)
        if solidity > 0.85:
            confidence += 20
        elif solidity > 0.7:
            confidence += 15
        elif solidity > 0.5:
            confidence += 10
        elif solidity > 0.3:
            confidence += 5
        
        # ƒêi·ªÉm t·ª´ extent (15 ƒëi·ªÉm)
        if extent > 0.7:
            confidence += 15
        elif extent > 0.5:
            confidence += 10
        elif extent > 0.3:
            confidence += 5
        
        # ƒêi·ªÉm t·ª´ n·ªôi dung (10 ƒëi·ªÉm)
        if content_analysis["has_text"] or content_analysis["has_lines"] > 1:
            confidence += 10
        elif content_analysis["density"] > 0.05:
            confidence += 5
        
        # ƒêi·ªÉm t·ª´ k√≠ch th∆∞·ªõc tuy·ªát ƒë·ªëi
        if contour_area > 5000:
            confidence += 10
        elif contour_area > 2000:
            confidence += 5
        
        # Ph·∫°t cho shape qu√° tr√≤n (c√≥ th·ªÉ l√† noise)
        if circularity > 0.8 and area_ratio < 0.01:
            confidence -= 20
        
        # Ph·∫°t cho v√πng qu√° nh·ªè ho·∫∑c qu√° l·ªõn
        if area_ratio > 0.7 or area_ratio < 0.002:
            confidence -= 15
        
        return max(0, confidence)
    
    def _non_maximum_suppression(self, candidates, iou_threshold=0.3):
        """Non-Maximum Suppression ƒë·ªÉ lo·∫°i b·ªè overlapping boxes"""
        if not candidates:
            return []
        
        # S·∫Øp x·∫øp theo confidence
        candidates = sorted(candidates, key=lambda x: x['confidence'], reverse=True)
        
        keep = []
        while candidates:
            # L·∫•y candidate c√≥ confidence cao nh·∫•t
            current = candidates.pop(0)
            keep.append(current)
            
            # Lo·∫°i b·ªè c√°c candidates overlap qu√° nhi·ªÅu
            remaining = []
            for candidate in candidates:
                iou = self._calculate_iou(current, candidate)
                if iou < iou_threshold:
                    remaining.append(candidate)
            
            candidates = remaining
        
        return keep
    
    def _calculate_iou(self, box1, box2):
        """T√≠nh Intersection over Union"""
        x1_1, y1_1, x2_1, y2_1 = box1['x0'], box1['y0'], box1['x1'], box1['y1']
        x1_2, y1_2, x2_2, y2_2 = box2['x0'], box2['y0'], box2['x1'], box2['y1']
        
        # T√≠nh intersection
        x_left = max(x1_1, x1_2)
        y_top = max(y1_1, y1_2)
        x_right = min(x2_1, x2_2)
        y_bottom = min(y2_1, y2_2)
        
        if x_right <= x_left or y_bottom <= y_top:
            return 0.0
        
        intersection = (x_right - x_left) * (y_bottom - y_top)
        
        # T√≠nh union
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0
    
    def _enhance_cropped_image(self, crop):
        """C·∫£i thi·ªán ch·∫•t l∆∞·ª£ng ·∫£nh c·∫Øt"""
        # Kh·ª≠ nhi·ªÖu nh·∫π
        crop = cv2.medianBlur(crop, 3)
        
        # TƒÉng c∆∞·ªùng ƒë·ªô t∆∞∆°ng ph·∫£n
        lab = cv2.cvtColor(crop, cv2.COLOR_RGB2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))
        l = clahe.apply(l)
        crop = cv2.merge([l, a, b])
        crop = cv2.cvtColor(crop, cv2.COLOR_LAB2RGB)
        
        return crop
    
    def create_debug_image(self, image_bytes, figures):
        """T·∫°o ·∫£nh debug v·ªõi th√¥ng tin chi ti·∫øt"""
        img_pil = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        draw = ImageDraw.Draw(img_pil)
        
        colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'cyan', 'magenta', 'lime']
        
        for i, fig in enumerate(figures):
            color = colors[i % len(colors)]
            bbox = fig['original_bbox']
            x, y, w, h = bbox
            
            # V·∫Ω khung v·ªõi ƒë·ªô d√†y t√πy theo confidence
            thickness = 4 if fig['confidence'] > 80 else 3 if fig['confidence'] > 60 else 2
            draw.rectangle([x, y, x+w, y+h], outline=color, width=thickness)
            
            # V·∫Ω label v·ªõi th√¥ng tin chi ti·∫øt
            conf_class = "HIGH" if fig['confidence'] > 80 else "MED" if fig['confidence'] > 60 else "LOW"
            label = f"{fig['name']}\n{conf_class}: {fig['confidence']:.0f}%\nAR: {fig['aspect_ratio']:.2f}"
            
            # V·∫Ω background cho text
            lines = label.split('\n')
            max_width = max(len(line) for line in lines) * 7
            text_height = len(lines) * 15
            draw.rectangle([x, y-text_height-5, x+max_width, y], fill=color, outline=color)
            
            # V·∫Ω text
            for j, line in enumerate(lines):
                draw.text((x+2, y-text_height+j*12), line, fill='white')
        
        return img_pil
    
    def insert_figures_into_text(self, text, figures, img_h, img_w):
        """Ch√®n ·∫£nh/b·∫£ng v√†o vƒÉn b·∫£n v·ªõi logic c·∫£i thi·ªán"""
        lines = self._preprocess_text_lines(text)
        
        figures_sorted = sorted(
            [fig for fig in figures if fig.get('bbox')],
            key=lambda f: (f['bbox'][1], f['bbox'][0])
        )
        
        processed_lines = []
        used_figures = set()
        fig_idx = 0
        
        for i, line in enumerate(lines):
            processed_lines.append(line)
            
            inserted = self._try_insert_figure(
                line, figures_sorted, used_figures, 
                processed_lines, fig_idx
            )
            
            if isinstance(inserted, int):
                fig_idx = inserted
        
        # Ch√®n c√°c ·∫£nh c√≤n l·∫°i
        processed_lines = self._insert_remaining_figures(
            processed_lines, figures_sorted, used_figures, fig_idx
        )
        
        return '\n'.join(processed_lines)
    
    def _preprocess_text_lines(self, text):
        """Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n"""
        lines = []
        current_line = ""
        
        for line in text.split('\n'):
            stripped = line.strip()
            if stripped:
                if current_line:
                    current_line += " " + stripped
                else:
                    current_line = stripped
            else:
                if current_line:
                    lines.append(current_line)
                    current_line = ""
                if lines:
                    lines.append('')
        
        if current_line:
            lines.append(current_line)
        
        return lines
    
    def _try_insert_figure(self, line, figures_sorted, used_figures, processed_lines, fig_idx):
        """Th·ª≠ ch√®n ·∫£nh/b·∫£ng d·ª±a tr√™n t·ª´ kh√≥a"""
        lower_line = line.lower()
        
        # T·ª´ kh√≥a cho b·∫£ng (m·ªü r·ªông)
        table_keywords = [
            "b·∫£ng", "b·∫£ng gi√° tr·ªã", "b·∫£ng bi·∫øn thi√™n", "b·∫£ng t·∫ßn s·ªë", 
            "b·∫£ng s·ªë li·ªáu", "table", "cho b·∫£ng", "theo b·∫£ng", "b·∫£ng sau",
            "quan s√°t b·∫£ng", "t·ª´ b·∫£ng", "d·ª±a v√†o b·∫£ng", "b·∫£ng tr√™n",
            "trong b·∫£ng", "b·∫£ng d∆∞·ªõi", "xem b·∫£ng"
        ]
        
        # T·ª´ kh√≥a cho h√¨nh
        image_keywords = [
            "h√¨nh v·∫Ω", "h√¨nh b√™n", "(h√¨nh", "xem h√¨nh", "ƒë·ªì th·ªã", 
            "bi·ªÉu ƒë·ªì", "minh h·ªça", "h√¨nh", "figure", "chart", "graph",
            "cho h√¨nh", "theo h√¨nh", "h√¨nh sau", "quan s√°t h√¨nh",
            "t·ª´ h√¨nh", "d·ª±a v√†o h√¨nh", "s∆° ƒë·ªì", "h√¨nh tr√™n",
            "trong h√¨nh", "h√¨nh d∆∞·ªõi"
        ]
        
        # Ki·ªÉm tra b·∫£ng tr∆∞·ªõc
        if any(keyword in lower_line for keyword in table_keywords):
            for j in range(fig_idx, len(figures_sorted)):
                fig = figures_sorted[j]
                if fig['is_table'] and fig['name'] not in used_figures:
                    tag = f"\n[B·∫¢NG: {fig['name']}]\n"
                    processed_lines.append(tag)
                    used_figures.add(fig['name'])
                    return j + 1
        
        # Ki·ªÉm tra h√¨nh ·∫£nh
        elif any(keyword in lower_line for keyword in image_keywords):
            for j in range(fig_idx, len(figures_sorted)):
                fig = figures_sorted[j]
                if not fig['is_table'] and fig['name'] not in used_figures:
                    tag = f"\n[H√åNH: {fig['name']}]\n"
                    processed_lines.append(tag)
                    used_figures.add(fig['name'])
                    return j + 1
        
        return fig_idx
    
    def _insert_remaining_figures(self, processed_lines, figures_sorted, used_figures, fig_idx):
        """Ch√®n c√°c ·∫£nh c√≤n l·∫°i"""
        question_patterns = [
            r"^(C√¢u|Question|Problem)\s*\d+",
            r"^\d+[\.\)]\s*",
            r"^[A-D][\.\)]\s*",
            r"^[a-d][\.\)]\s*"
        ]
        
        for i, line in enumerate(processed_lines):
            is_question = any(re.match(pattern, line.strip()) for pattern in question_patterns)
            
            if is_question and fig_idx < len(figures_sorted):
                next_line = processed_lines[i+1] if i+1 < len(processed_lines) else ""
                has_image = re.match(r"\[(H√åNH|B·∫¢NG):.*\]", next_line.strip())
                
                if not has_image:
                    while (fig_idx < len(figures_sorted) and 
                           figures_sorted[fig_idx]['name'] in used_figures):
                        fig_idx += 1
                    
                    if fig_idx < len(figures_sorted):
                        fig = figures_sorted[fig_idx]
                        tag = (f"\n[B·∫¢NG: {fig['name']}]\n" if fig['is_table'] 
                               else f"\n[H√åNH: {fig['name']}]\n")
                        processed_lines.insert(i+1, tag)
                        used_figures.add(fig['name'])
                        fig_idx += 1
        
        return processed_lines

class GeminiAPI:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"
    
    def encode_image(self, image_data: bytes) -> str:
        """M√£ h√≥a ·∫£nh th√†nh base64"""
        return base64.b64encode(image_data).decode('utf-8')
    
    def convert_to_latex(self, content_data: bytes, content_type: str, prompt: str) -> str:
        """Chuy·ªÉn ƒë·ªïi n·ªôi dung sang LaTeX s·ª≠ d·ª•ng Gemini API"""
        headers = {"Content-Type": "application/json"}
        
        if content_type.startswith('image/'):
            mime_type = content_type
        else:
            mime_type = "image/png"
        
        encoded_content = self.encode_image(content_data)
        
        payload = {
            "contents": [
                {
                    "parts": [
                        {"text": prompt},
                        {
                            "inline_data": {
                                "mime_type": mime_type,
                                "data": encoded_content
                            }
                        }
                    ]
                }
            ],
            "generationConfig": {
                "temperature": 0.1,
                "topK": 1,
                "topP": 0.8,
                "maxOutputTokens": 8192,
            }
        }
        
        try:
            response = requests.post(
                f"{self.base_url}?key={self.api_key}",
                headers=headers,
                json=payload,
                timeout=90
            )
            
            if response.status_code == 200:
                result = response.json()
                if 'candidates' in result and len(result['candidates']) > 0:
                    content = result['candidates'][0]['content']['parts'][0]['text']
                    return content.strip()
                else:
                    raise Exception("API kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£ h·ª£p l·ªá")
            elif response.status_code == 401:
                raise Exception("API key kh√¥ng h·ª£p l·ªá ho·∫∑c ƒë√£ h·∫øt h·∫°n")
            elif response.status_code == 429:
                raise Exception("ƒê√£ v∆∞·ª£t qu√° gi·ªõi h·∫°n rate limit")
            else:
                raise Exception(f"API Error {response.status_code}: {response.text}")
        
        except requests.exceptions.Timeout:
            raise Exception("Request timeout - th·ª≠ l·∫°i sau √≠t ph√∫t")
        except requests.exceptions.ConnectionError:
            raise Exception("L·ªói k·∫øt n·ªëi m·∫°ng")
        except Exception as e:
            raise Exception(str(e))

class PDFProcessor:
    @staticmethod
    def extract_images_and_text(pdf_file):
        """Tr√≠ch xu·∫•t ·∫£nh v√† chuy·ªÉn ƒë·ªïi trang PDF th√†nh ·∫£nh"""
        pdf_document = fitz.open(stream=pdf_file.read(), filetype="pdf")
        images = []
        
        for page_num in range(pdf_document.page_count):
            page = pdf_document[page_num]
            mat = fitz.Matrix(3.0, 3.0)  # TƒÉng ƒë·ªô ph√¢n gi·∫£i l√™n 3x
            pix = page.get_pixmap(matrix=mat)
            img_data = pix.tobytes("png")
            img = Image.open(io.BytesIO(img_data))
            images.append((img, page_num + 1))
        
        pdf_document.close()
        return images

class WordExporter:
    @staticmethod
    def create_word_document(latex_content: str, extracted_figures=None, images=None) -> io.BytesIO:
        """T·∫°o file Word v·ªõi ƒë·ªãnh d·∫°ng LaTeX chu·∫©n"""
        doc = Document()
        
        # Th√™m ti√™u ƒë·ªÅ
        title = doc.add_heading('T√†i li·ªáu ƒë√£ chuy·ªÉn ƒë·ªïi t·ª´ PDF/·∫¢nh', 0)
        title.alignment = 1
        
        # Th√™m th√¥ng tin
        doc.add_paragraph(f"ƒê∆∞·ª£c t·∫°o b·ªüi PDF/Image to LaTeX Converter Ultra")
        doc.add_paragraph(f"Th·ªùi gian: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        doc.add_paragraph("")
        
        # X·ª≠ l√Ω n·ªôi dung LaTeX v·ªõi ƒë·ªãnh d·∫°ng ${......}$
        lines = latex_content.split('\n')
        
        for line in lines:
            line = line.strip()
            
            # B·ªè qua c√°c d√≤ng ```latex n·∫øu c√≥
            if line.startswith('```') or line.endswith('```'):
                continue
            
            # X·ª≠ l√Ω tag ·∫£nh/b·∫£ng ƒë√£ t√°ch
            if line.startswith('[H√åNH:') and line.endswith(']'):
                img_name = line.replace('[H√åNH:', '').replace(']', '').strip()
                WordExporter._insert_extracted_image(doc, img_name, extracted_figures, "H√¨nh minh h·ªça")
                continue
            elif line.startswith('[B·∫¢NG:') and line.endswith(']'):
                img_name = line.replace('[B·∫¢NG:', '').replace(']', '').strip()
                WordExporter._insert_extracted_image(doc, img_name, extracted_figures, "B·∫£ng s·ªë li·ªáu")
                continue
            
            # Skip comments
            if line.startswith('<!--') and line.endswith('-->'):
                if 'Trang' in line or '·∫¢nh' in line:
                    doc.add_heading(line.replace('<!--', '').replace('-->', '').strip(), level=2)
                continue
            
            if not line:
                continue
            
            # X·ª≠ l√Ω c√¥ng th·ª©c LaTeX v·ªõi ƒë·ªãnh d·∫°ng ${......}$
            if '${' in line and '}$'
        
        # Th√™m ·∫£nh g·ªëc n·∫øu c√≥ (fallback)
        if images and not extracted_figures:
            doc.add_page_break()
            doc.add_heading('H√¨nh ·∫£nh g·ªëc', level=1)
            
            for i, img in enumerate(images):
                try:
                    doc.add_heading(f'H√¨nh {i+1}', level=2)
                    
                    if img.mode in ('RGBA', 'LA', 'P'):
                        img = img.convert('RGB')
                    
                    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
                        img.save(tmp.name, 'PNG')
                        try:
                            doc.add_picture(tmp.name, width=doc.sections[0].page_width * 0.8)
                        except Exception:
                            doc.add_paragraph(f"[H√¨nh ·∫£nh {i+1} - Kh√¥ng th·ªÉ hi·ªÉn th·ªã]")
                        os.unlink(tmp.name)
                except Exception:
                    doc.add_paragraph(f"[L·ªói hi·ªÉn th·ªã h√¨nh {i+1}]")
        
        buffer = io.BytesIO()
        doc.save(buffer)
        buffer.seek(0)
        return buffer
    
    @staticmethod
    def _insert_extracted_image(doc, img_name, extracted_figures, caption_prefix):
        """Ch√®n ·∫£nh ƒë√£ t√°ch v√†o Word document"""
        if not extracted_figures:
            doc.add_paragraph(f"[{caption_prefix}: {img_name} - Kh√¥ng t√¨m th·∫•y]")
            return
        
        target_figure = None
        for fig in extracted_figures:
            if fig['name'] == img_name:
                target_figure = fig
                break
        
        if not target_figure:
            doc.add_paragraph(f"[{caption_prefix}: {img_name} - Kh√¥ng t√¨m th·∫•y]")
            return
        
        try:
            doc.add_heading(f"{caption_prefix}: {img_name}", level=3)
            
            img_data = base64.b64decode(target_figure['base64'])
            img_pil = Image.open(io.BytesIO(img_data))
            
            if img_pil.mode in ('RGBA', 'LA', 'P'):
                img_pil = img_pil.convert('RGB')
            
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
                img_pil.save(tmp.name, 'PNG')
                try:
                    max_width = doc.sections[0].page_width * 0.8
                    doc.add_picture(tmp.name, width=max_width)
                except Exception:
                    doc.add_paragraph(f"[Kh√¥ng th·ªÉ hi·ªÉn th·ªã {img_name}]")
                os.unlink(tmp.name)
        
        except Exception as e:
            doc.add_paragraph(f"[L·ªói hi·ªÉn th·ªã {img_name}: {str(e)}]")

def validate_api_key(api_key: str) -> bool:
    """Ki·ªÉm tra t√≠nh h·ª£p l·ªá c·ªßa API key"""
    if not api_key or len(api_key) < 20:
        return False
    return re.match(r'^[A-Za-z0-9_-]+$', api_key) is not None

def format_file_size(size_bytes: int) -> str:
    """Chuy·ªÉn ƒë·ªïi k√≠ch th∆∞·ªõc file sang ƒë·ªãnh d·∫°ng human-readable"""
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"

def main():
    st.markdown('<h1 class="main-header">üìù PDF/Image to LaTeX Converter - Ultra Enhanced</h1>', unsafe_allow_html=True)
    
    # Sidebar cho API key
    with st.sidebar:
        st.header("‚öôÔ∏è C√†i ƒë·∫∑t")
        api_key = st.text_input(
            "Gemini API Key", 
            type="password", 
            help="Nh·∫≠p API key t·ª´ Google AI Studio",
            placeholder="Paste your API key here..."
        )
        
        if api_key:
            if validate_api_key(api_key):
                st.success("‚úÖ API key h·ª£p l·ªá")
            else:
                st.error("‚ùå API key kh√¥ng h·ª£p l·ªá")
        
        st.markdown("---")
        
        # C√†i ƒë·∫∑t t√°ch ·∫£nh si√™u n√¢ng cao
        st.subheader("üñºÔ∏è T√°ch ·∫£nh si√™u ch√≠nh x√°c")
        enable_extraction = st.checkbox("B·∫≠t t√°ch ·∫£nh/b·∫£ng si√™u n√¢ng cao", value=True, 
                                       help="Thu·∫≠t to√°n AI t√°ch ·∫£nh v·ªõi ƒë·ªô ch√≠nh x√°c c·ª±c cao")
        
        if enable_extraction:
            st.write("**C√†i ƒë·∫∑t si√™u n√¢ng cao:**")
            min_area = st.slider("Di·ªán t√≠ch t·ªëi thi·ªÉu (%)", 0.1, 5.0, 0.3, 0.1,
                               help="% di·ªán t√≠ch ·∫£nh g·ªëc") / 100
            max_figures = st.slider("S·ªë ·∫£nh t·ªëi ƒëa", 1, 25, 12, 1)
            min_size = st.slider("K√≠ch th∆∞·ªõc t·ªëi thi·ªÉu (px)", 30, 300, 40, 10)
            padding = st.slider("Padding xung quanh (px)", 0, 30, 8, 1)
            confidence_threshold = st.slider("Ng∆∞·ª°ng confidence (%)", 30, 90, 50, 5)
            
            show_debug = st.checkbox("Hi·ªÉn th·ªã ·∫£nh debug n√¢ng cao", value=True,
                                   help="Hi·ªÉn th·ªã ·∫£nh v·ªõi confidence score v√† ph√¢n t√≠ch chi ti·∫øt")
        
        st.markdown("---")
        st.markdown("""
        ### üìã H∆∞·ªõng d·∫´n:
        1. Nh·∫≠p API key Gemini
        2. Ch·ªçn tab PDF ho·∫∑c ·∫¢nh  
        3. Upload file
        4. Ch·ªù x·ª≠ l√Ω v√† t·∫£i file Word
        
        ### üéØ T√≠nh nƒÉng si√™u n√¢ng cao:
        - ‚úÖ Thu·∫≠t to√°n AI c·∫Øt ·∫£nh v·ªõi NMS
        - ‚úÖ Confidence scoring th√¥ng minh
        - ‚úÖ ƒê·ªãnh d·∫°ng LaTeX chu·∫©n: `${......}$`
        - ‚úÖ Ph√¢n t√≠ch n·ªôi dung v√πng
        - ‚úÖ Multi-scale edge detection
        
        ### üìù ƒê·ªãnh d·∫°ng OUTPUT chu·∫©n:
        **C√¥ng th·ª©c to√°n h·ªçc:** `${x^2 + y^2}import streamlit as st
import requests
import base64
import io
import json
from PIL import Image, ImageDraw, ImageFont
import fitz  # PyMuPDF
from docx import Document
import tempfile
import os
import re
import time
import cv2
import numpy as np

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="PDF/Image to LaTeX Converter - Ultra Enhanced",
    page_icon="üìù",
    layout="wide"
)

# CSS t√πy ch·ªânh
st.markdown("""
<style>
    .main-header {
        text-align: center;
        color: #2E86AB;
        font-size: 2.5rem;
        margin-bottom: 2rem;
    }
    .latex-output {
        background-color: #f4f4f4;
        padding: 1rem;
        border-radius: 5px;
        font-family: 'Courier New', monospace;
        border-left: 4px solid #2E86AB;
    }
    .success-message {
        color: #28a745;
        font-weight: bold;
    }
    .error-message {
        color: #dc3545;
        font-weight: bold;
    }
    .extracted-image {
        border: 2px solid #2E86AB;
        border-radius: 8px;
        margin: 10px 0;
        padding: 5px;
        background: #f8f9fa;
    }
    .image-info {
        background-color: #e8f4f8;
        padding: 8px;
        border-radius: 4px;
        margin: 5px 0;
        font-size: 0.9em;
    }
    .confidence-high { color: #28a745; font-weight: bold; }
    .confidence-medium { color: #ffc107; font-weight: bold; }
    .confidence-low { color: #dc3545; font-weight: bold; }
</style>
""", unsafe_allow_html=True)

class UltraImageExtractor:
    """
    Class si√™u n√¢ng cao ƒë·ªÉ t√°ch ·∫£nh/b·∫£ng v·ªõi ƒë·ªô ch√≠nh x√°c c·ª±c cao
    """
    
    def __init__(self):
        self.min_area_ratio = 0.003    # Di·ªán t√≠ch t·ªëi thi·ªÉu (% c·ªßa ·∫£nh g·ªëc)
        self.min_area_abs = 1000       # Di·ªán t√≠ch t·ªëi thi·ªÉu (pixel)
        self.min_width = 40            # Chi·ªÅu r·ªông t·ªëi thi·ªÉu
        self.min_height = 40           # Chi·ªÅu cao t·ªëi thi·ªÉu
        self.max_figures = 12          # S·ªë l∆∞·ª£ng ·∫£nh t·ªëi ƒëa
        self.padding = 8               # Padding xung quanh ·∫£nh c·∫Øt
        self.confidence_threshold = 50 # Ng∆∞·ª°ng confidence t·ªëi thi·ªÉu
    
    def extract_figures_and_tables(self, image_bytes):
        """T√°ch ·∫£nh v√† b·∫£ng v·ªõi thu·∫≠t to√°n si√™u ch√≠nh x√°c"""
        # 1. ƒê·ªçc v√† ti·ªÅn x·ª≠ l√Ω ·∫£nh
        img_pil = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        img = np.array(img_pil)
        h, w = img.shape[:2]
        
        # 2. Ti·ªÅn x·ª≠ l√Ω ·∫£nh ƒëa c·∫•p ƒë·ªô
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        
        # Kh·ª≠ nhi·ªÖu m·∫°nh
        gray = cv2.medianBlur(gray, 5)
        gray = cv2.bilateralFilter(gray, 9, 75, 75)
        
        # TƒÉng c∆∞·ªùng ƒë·ªô t∆∞∆°ng ph·∫£n adaptive
        clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8, 8))
        gray = clahe.apply(gray)
        
        # 3. Ph√°t hi·ªán c·∫°nh ƒëa ph∆∞∆°ng ph√°p
        # Ph∆∞∆°ng ph√°p 1: Adaptive threshold v·ªõi nhi·ªÅu k√≠ch th∆∞·ªõc kernel
        thresh1 = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)
        thresh2 = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 15, 3)
        
        # Ph∆∞∆°ng ph√°p 2: Canny v·ªõi multiple scales
        edges1 = cv2.Canny(gray, 30, 100, apertureSize=3)
        edges2 = cv2.Canny(gray, 50, 150, apertureSize=3)
        edges3 = cv2.Canny(gray, 80, 200, apertureSize=5)
        
        # Ph∆∞∆°ng ph√°p 3: Gradient-based detection
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        gradient = np.sqrt(sobelx**2 + sobely**2)
        gradient = np.uint8(gradient / gradient.max() * 255)
        _, gradient_thresh = cv2.threshold(gradient, 50, 255, cv2.THRESH_BINARY)
        
        # 4. K·∫øt h·ª£p t·∫•t c·∫£ ph∆∞∆°ng ph√°p
        combined = cv2.bitwise_or(thresh1, thresh2)
        combined = cv2.bitwise_or(combined, edges1)
        combined = cv2.bitwise_or(combined, edges2) 
        combined = cv2.bitwise_or(combined, edges3)
        combined = cv2.bitwise_or(combined, gradient_thresh)
        
        # 5. Morphological operations ƒë·ªÉ l√†m s·∫°ch
        kernel_close = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        kernel_open = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
        
        combined = cv2.morphologyEx(combined, cv2.MORPH_CLOSE, kernel_close)
        combined = cv2.morphologyEx(combined, cv2.MORPH_OPEN, kernel_open)
        
        # Dilate nh·∫π ƒë·ªÉ k·∫øt n·ªëi c√°c th√†nh ph·∫ßn
        kernel_dilate = np.ones((2, 2), np.uint8)
        combined = cv2.dilate(combined, kernel_dilate, iterations=1)
        
        # 6. T√¨m contours v·ªõi hierarchy
        contours, hierarchy = cv2.findContours(combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # 7. L·ªçc v√† ph√¢n t√≠ch contours v·ªõi nhi·ªÅu ti√™u ch√≠
        candidates = []
        
        for i, cnt in enumerate(contours):
            # T√≠nh to√°n bounding box
            x, y, ww, hh = cv2.boundingRect(cnt)
            area = ww * hh
            area_ratio = area / (w * h)
            aspect_ratio = ww / (hh + 1e-6)
            
            # L·ªçc k√≠ch th∆∞·ªõc c∆° b·∫£n
            if (area < self.min_area_abs or 
                area_ratio < self.min_area_ratio or 
                area_ratio > 0.8):
                continue
            
            if ww < self.min_width or hh < self.min_height:
                continue
            
            # L·ªçc aspect ratio h·ª£p l√Ω
            if not (0.05 < aspect_ratio < 20.0):
                continue
            
            # Lo·∫°i b·ªè v√πng ·ªü r√¨a ·∫£nh
            margin = 0.01
            if (x < margin*w or y < margin*h or 
                (x+ww) > (1-margin)*w or (y+hh) > (1-margin)*h):
                continue
            
            # T√≠nh c√°c ƒë·∫∑c tr∆∞ng h√¨nh h·ªçc n√¢ng cao
            hull = cv2.convexHull(cnt)
            hull_area = cv2.contourArea(hull)
            contour_area = cv2.contourArea(cnt)
            
            if hull_area == 0 or contour_area < 100:
                continue
            
            # T√≠nh to√°n c√°c metrics ch·∫•t l∆∞·ª£ng
            solidity = float(contour_area) / hull_area
            extent = float(contour_area) / area
            
            # T√≠nh chu vi v√† circularity
            perimeter = cv2.arcLength(cnt, True)
            if perimeter == 0:
                continue
            circularity = 4 * np.pi * contour_area / (perimeter ** 2)
            
            # L·ªçc c√°c shape qu√° ph·ª©c t·∫°p ho·∫∑c qu√° ƒë∆°n gi·∫£n
            if solidity < 0.2 or extent < 0.15:
                continue
            
            # T√≠nh moments ƒë·ªÉ ki·ªÉm tra shape regularity
            moments = cv2.moments(cnt)
            if moments['m00'] == 0:
                continue
            
            # Ph√¢n t√≠ch n·ªôi dung v√πng ƒë·ªÉ ph√¢n lo·∫°i
            roi = gray[y:y+hh, x:x+ww]
            content_analysis = self._analyze_region_content(roi)
            
            # Ph√¢n lo·∫°i b·∫£ng vs h√¨nh
            is_table = self._advanced_table_classification(x, y, ww, hh, w, h, cnt, roi, content_analysis)
            
            # T√≠nh ƒëi·ªÉm confidence n√¢ng cao
            confidence = self._calculate_advanced_confidence(
                area_ratio, aspect_ratio, solidity, extent, circularity,
                ww, hh, w, h, content_analysis, contour_area
            )
            
            # Ch·ªâ gi·ªØ l·∫°i nh·ªØng v√πng c√≥ confidence cao
            if confidence < self.confidence_threshold:
                continue
            
            candidates.append({
                "area": area,
                "x0": x, "y0": y, "x1": x+ww, "y1": y+hh,
                "width": ww, "height": hh,
                "is_table": is_table,
                "confidence": confidence,
                "aspect_ratio": aspect_ratio,
                "solidity": solidity,
                "extent": extent,
                "circularity": circularity,
                "content_analysis": content_analysis,
                "bbox": (x, y, ww, hh),
                "contour": cnt
            })
        
        # 8. S·∫Øp x·∫øp v√† l·ªçc overlapping v·ªõi thu·∫≠t to√°n NMS
        candidates = sorted(candidates, key=lambda f: f['confidence'], reverse=True)
        candidates = self._non_maximum_suppression(candidates, iou_threshold=0.3)
        candidates = candidates[:self.max_figures]
        
        # 9. S·∫Øp x·∫øp theo v·ªã tr√≠ ƒë·ªçc (top-to-bottom, left-to-right)
        candidates = sorted(candidates, key=lambda box: (box["y0"] + box["height"]//2, box["x0"]))
        
        # 10. T·∫°o ·∫£nh k·∫øt qu·∫£ v·ªõi quality cao
        final_figures = []
        img_idx = 0
        table_idx = 0
        
        for fig_data in candidates:
            # C·∫Øt ·∫£nh v·ªõi padding th√¥ng minh
            x0 = max(0, fig_data["x0"] - self.padding)
            y0 = max(0, fig_data["y0"] - self.padding)
            x1 = min(w, fig_data["x1"] + self.padding)
            y1 = min(h, fig_data["y1"] + self.padding)
            
            crop = img[y0:y1, x0:x1]
            
            if crop.size == 0:
                continue
            
            # Post-process ·∫£nh c·∫Øt
            crop = self._enhance_cropped_image(crop)
            
            # Chuy·ªÉn th√†nh base64 v·ªõi quality cao
            buf = io.BytesIO()
            Image.fromarray(crop).save(buf, format="JPEG", quality=98, optimize=True)
            b64 = base64.b64encode(buf.getvalue()).decode()
            
            # ƒê·∫∑t t√™n file th√¥ng minh
            if fig_data["is_table"]:
                name = f"table-{table_idx+1}.jpeg"
                table_idx += 1
            else:
                name = f"img-{img_idx+1}.jpeg"
                img_idx += 1
            
            final_figures.append({
                "name": name,
                "base64": b64,
                "is_table": fig_data["is_table"],
                "bbox": (x0, y0, x1-x0, y1-y0),
                "original_bbox": fig_data["bbox"],
                "confidence": fig_data["confidence"],
                "aspect_ratio": fig_data["aspect_ratio"],
                "area": fig_data["area"],
                "solidity": fig_data["solidity"],
                "content_analysis": fig_data["content_analysis"]
            })
        
        return final_figures, h, w
    
    def _analyze_region_content(self, roi):
        """Ph√¢n t√≠ch n·ªôi dung v√πng ƒë·ªÉ h·ªó tr·ª£ ph√¢n lo·∫°i"""
        if roi.shape[0] < 10 or roi.shape[1] < 10:
            return {"has_text": False, "has_lines": 0, "density": 0, "uniformity": 0}
        
        # Ph√°t hi·ªán text regions (v√πng c√≥ nhi·ªÅu pixel ƒëen nh·ªè)
        kernel_text = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 1))
        _, binary = cv2.threshold(roi, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        text_regions = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_text)
        has_text = np.sum(text_regions) > roi.shape[0] * roi.shape[1] * 0.05
        
        # Ph√°t hi·ªán ƒë∆∞·ªùng k·∫ª ngang v√† d·ªçc
        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (min(roi.shape[1]//3, 40), 1))
        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, min(roi.shape[0]//3, 40)))
        
        horizontal_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, horizontal_kernel)
        vertical_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, vertical_kernel)
        
        h_lines = len(cv2.findContours(horizontal_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0])
        v_lines = len(cv2.findContours(vertical_lines, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0])
        
        # T√≠nh m·∫≠t ƒë·ªô pixel
        density = np.sum(binary) / (roi.shape[0] * roi.shape[1] * 255)
        
        # T√≠nh ƒë·ªô ƒë·ªìng ƒë·ªÅu (uniformity)
        hist = cv2.calcHist([roi], [0], None, [256], [0, 256])
        uniformity = np.sum((hist / hist.sum()) ** 2)
        
        return {
            "has_text": has_text,
            "has_lines": h_lines + v_lines,
            "h_lines": h_lines,
            "v_lines": v_lines,
            "density": density,
            "uniformity": uniformity
        }
    
    def _advanced_table_classification(self, x, y, w, h, img_w, img_h, contour, roi, content_analysis):
        """Ph√¢n lo·∫°i b·∫£ng vs h√¨nh ·∫£nh v·ªõi thu·∫≠t to√°n n√¢ng cao"""
        aspect_ratio = w / (h + 1e-6)
        
        # ƒêi·ªÉm t·ª´ k√≠ch th∆∞·ªõc v√† t·ª∑ l·ªá
        size_score = 0
        if w > 0.25 * img_w:  # B·∫£ng th∆∞·ªùng r·ªông
            size_score += 3
        if h > 0.08 * img_h and h < 0.7 * img_h:  # Chi·ªÅu cao v·ª´a ph·∫£i
            size_score += 2
        if 1.5 < aspect_ratio < 10.0:  # T·ª∑ l·ªá ph√π h·ª£p cho b·∫£ng
            size_score += 3
        
        # ƒêi·ªÉm t·ª´ ph√¢n t√≠ch n·ªôi dung
        content_score = 0
        if content_analysis["has_lines"] > 2:  # C√≥ ƒë∆∞·ªùng k·∫ª
            content_score += 4
        if content_analysis["h_lines"] > 1:  # C√≥ ƒë∆∞·ªùng k·∫ª ngang
            content_score += 3
        if content_analysis["v_lines"] > 0:  # C√≥ ƒë∆∞·ªùng k·∫ª d·ªçc
            content_score += 2
        if content_analysis["has_text"]:  # C√≥ text
            content_score += 2
        if 0.1 < content_analysis["density"] < 0.4:  # M·∫≠t ƒë·ªô v·ª´a ph·∫£i
            content_score += 2
        
        # ƒêi·ªÉm t·ª´ v·ªã tr√≠ (b·∫£ng th∆∞·ªùng ·ªü gi·ªØa)
        position_score = 0
        center_x_ratio = (x + w/2) / img_w
        if 0.1 < center_x_ratio < 0.9:
            position_score += 1
        
        total_score = size_score + content_score + position_score
        
        # Ng∆∞·ª°ng ph√¢n lo·∫°i ƒë·ªông d·ª±a tr√™n confidence
        threshold = 6 if content_analysis["has_lines"] > 3 else 8
        
        return total_score >= threshold
    
    def _calculate_advanced_confidence(self, area_ratio, aspect_ratio, solidity, extent, 
                                     circularity, w, h, img_w, img_h, content_analysis, contour_area):
        """T√≠nh confidence score n√¢ng cao"""
        confidence = 0
        
        # ƒêi·ªÉm t·ª´ k√≠ch th∆∞·ªõc (30 ƒëi·ªÉm)
        if 0.005 < area_ratio < 0.6:
            if 0.02 < area_ratio < 0.3:
                confidence += 30
            elif 0.01 < area_ratio < 0.5:
                confidence += 20
            else:
                confidence += 10
        
        # ƒêi·ªÉm t·ª´ aspect ratio (25 ƒëi·ªÉm)
        if 0.3 < aspect_ratio < 5.0:
            confidence += 25
        elif 0.1 < aspect_ratio < 10.0:
            confidence += 15
        elif 0.05 < aspect_ratio < 20.0:
            confidence += 5
        
        # ƒêi·ªÉm t·ª´ solidity (20 ƒëi·ªÉm)
        if solidity > 0.85:
            confidence += 20
        elif solidity > 0.7:
            confidence += 15
        elif solidity > 0.5:
            confidence += 10
        elif solidity > 0.3:
            confidence += 5
        
        # ƒêi·ªÉm t·ª´ extent (15 ƒëi·ªÉm)
        if extent > 0.7:
            confidence += 15
        elif extent > 0.5:
            confidence += 10
        elif extent > 0.3:
            confidence += 5
        
        # ƒêi·ªÉm t·ª´ n·ªôi dung (10 ƒëi·ªÉm)
        if content_analysis["has_text"] or content_analysis["has_lines"] > 1:
            confidence += 10
        elif content_analysis["density"] > 0.05:
            confidence += 5
        
        # ƒêi·ªÉm t·ª´ k√≠ch th∆∞·ªõc tuy·ªát ƒë·ªëi
        if contour_area > 5000:
            confidence += 10
        elif contour_area > 2000:
            confidence += 5
        
        # Ph·∫°t cho shape qu√° tr√≤n (c√≥ th·ªÉ l√† noise)
        if circularity > 0.8 and area_ratio < 0.01:
            confidence -= 20
        
        # Ph·∫°t cho v√πng qu√° nh·ªè ho·∫∑c qu√° l·ªõn
        if area_ratio > 0.7 or area_ratio < 0.002:
            confidence -= 15
        
        return max(0, confidence)
    
    def _non_maximum_suppression(self, candidates, iou_threshold=0.3):
        """Non-Maximum Suppression ƒë·ªÉ lo·∫°i b·ªè overlapping boxes"""
        if not candidates:
            return []
        
        # S·∫Øp x·∫øp theo confidence
        candidates = sorted(candidates, key=lambda x: x['confidence'], reverse=True)
        
        keep = []
        while candidates:
            # L·∫•y candidate c√≥ confidence cao nh·∫•t
            current = candidates.pop(0)
            keep.append(current)
            
            # Lo·∫°i b·ªè c√°c candidates overlap qu√° nhi·ªÅu
            remaining = []
            for candidate in candidates:
                iou = self._calculate_iou(current, candidate)
                if iou < iou_threshold:
                    remaining.append(candidate)
            
            candidates = remaining
        
        return keep
    
    def _calculate_iou(self, box1, box2):
        """T√≠nh Intersection over Union"""
        x1_1, y1_1, x2_1, y2_1 = box1['x0'], box1['y0'], box1['x1'], box1['y1']
        x1_2, y1_2, x2_2, y2_2 = box2['x0'], box2['y0'], box2['x1'], box2['y1']
        
        # T√≠nh intersection
        x_left = max(x1_1, x1_2)
        y_top = max(y1_1, y1_2)
        x_right = min(x2_1, x2_2)
        y_bottom = min(y2_1, y2_2)
        
        if x_right <= x_left or y_bottom <= y_top:
            return 0.0
        
        intersection = (x_right - x_left) * (y_bottom - y_top)
        
        # T√≠nh union
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0
    
    def _enhance_cropped_image(self, crop):
        """C·∫£i thi·ªán ch·∫•t l∆∞·ª£ng ·∫£nh c·∫Øt"""
        # Kh·ª≠ nhi·ªÖu nh·∫π
        crop = cv2.medianBlur(crop, 3)
        
        # TƒÉng c∆∞·ªùng ƒë·ªô t∆∞∆°ng ph·∫£n
        lab = cv2.cvtColor(crop, cv2.COLOR_RGB2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))
        l = clahe.apply(l)
        crop = cv2.merge([l, a, b])
        crop = cv2.cvtColor(crop, cv2.COLOR_LAB2RGB)
        
        return crop
    
    def create_debug_image(self, image_bytes, figures):
        """T·∫°o ·∫£nh debug v·ªõi th√¥ng tin chi ti·∫øt"""
        img_pil = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        draw = ImageDraw.Draw(img_pil)
        
        colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'cyan', 'magenta', 'lime']
        
        for i, fig in enumerate(figures):
            color = colors[i % len(colors)]
            bbox = fig['original_bbox']
            x, y, w, h = bbox
            
            # V·∫Ω khung v·ªõi ƒë·ªô d√†y t√πy theo confidence
            thickness = 4 if fig['confidence'] > 80 else 3 if fig['confidence'] > 60 else 2
            draw.rectangle([x, y, x+w, y+h], outline=color, width=thickness)
            
            # V·∫Ω label v·ªõi th√¥ng tin chi ti·∫øt
            conf_class = "HIGH" if fig['confidence'] > 80 else "MED" if fig['confidence'] > 60 else "LOW"
            label = f"{fig['name']}\n{conf_class}: {fig['confidence']:.0f}%\nAR: {fig['aspect_ratio']:.2f}"
            
            # V·∫Ω background cho text
            lines = label.split('\n')
            max_width = max(len(line) for line in lines) * 7
            text_height = len(lines) * 15
            draw.rectangle([x, y-text_height-5, x+max_width, y], fill=color, outline=color)
            
            # V·∫Ω text
            for j, line in enumerate(lines):
                draw.text((x+2, y-text_height+j*12), line, fill='white')
        
        return img_pil
    
    def insert_figures_into_text(self, text, figures, img_h, img_w):
        """Ch√®n ·∫£nh/b·∫£ng v√†o vƒÉn b·∫£n v·ªõi logic c·∫£i thi·ªán"""
        lines = self._preprocess_text_lines(text)
        
        figures_sorted = sorted(
            [fig for fig in figures if fig.get('bbox')],
            key=lambda f: (f['bbox'][1], f['bbox'][0])
        )
        
        processed_lines = []
        used_figures = set()
        fig_idx = 0
        
        for i, line in enumerate(lines):
            processed_lines.append(line)
            
            inserted = self._try_insert_figure(
                line, figures_sorted, used_figures, 
                processed_lines, fig_idx
            )
            
            if isinstance(inserted, int):
                fig_idx = inserted
        
        # Ch√®n c√°c ·∫£nh c√≤n l·∫°i
        processed_lines = self._insert_remaining_figures(
            processed_lines, figures_sorted, used_figures, fig_idx
        )
        
        return '\n'.join(processed_lines)
    
    def _preprocess_text_lines(self, text):
        """Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n"""
        lines = []
        current_line = ""
        
        for line in text.split('\n'):
            stripped = line.strip()
            if stripped:
                if current_line:
                    current_line += " " + stripped
                else:
                    current_line = stripped
            else:
                if current_line:
                    lines.append(current_line)
                    current_line = ""
                if lines:
                    lines.append('')
        
        if current_line:
            lines.append(current_line)
        
        return lines
    
    def _try_insert_figure(self, line, figures_sorted, used_figures, processed_lines, fig_idx):
        """Th·ª≠ ch√®n ·∫£nh/b·∫£ng d·ª±a tr√™n t·ª´ kh√≥a"""
        lower_line = line.lower()
        
        # T·ª´ kh√≥a cho b·∫£ng (m·ªü r·ªông)
        table_keywords = [
            "b·∫£ng", "b·∫£ng gi√° tr·ªã", "b·∫£ng bi·∫øn thi√™n", "b·∫£ng t·∫ßn s·ªë", 
            "b·∫£ng s·ªë li·ªáu", "table", "cho b·∫£ng", "theo b·∫£ng", "b·∫£ng sau",
            "quan s√°t b·∫£ng", "t·ª´ b·∫£ng", "d·ª±a v√†o b·∫£ng", "b·∫£ng tr√™n",
            "trong b·∫£ng", "b·∫£ng d∆∞·ªõi", "xem b·∫£ng"
        ]
        
        # T·ª´ kh√≥a cho h√¨nh
        image_keywords = [
            "h√¨nh v·∫Ω", "h√¨nh b√™n", "(h√¨nh", "xem h√¨nh", "ƒë·ªì th·ªã", 
            "bi·ªÉu ƒë·ªì", "minh h·ªça", "h√¨nh", "figure", "chart", "graph",
            "cho h√¨nh", "theo h√¨nh", "h√¨nh sau", "quan s√°t h√¨nh",
            "t·ª´ h√¨nh", "d·ª±a v√†o h√¨nh", "s∆° ƒë·ªì", "h√¨nh tr√™n",
            "trong h√¨nh", "h√¨nh d∆∞·ªõi"
        ]
        
        # Ki·ªÉm tra b·∫£ng tr∆∞·ªõc
        if any(keyword in lower_line for keyword in table_keywords):
            for j in range(fig_idx, len(figures_sorted)):
                fig = figures_sorted[j]
                if fig['is_table'] and fig['name'] not in used_figures:
                    tag = f"\n[B·∫¢NG: {fig['name']}]\n"
                    processed_lines.append(tag)
                    used_figures.add(fig['name'])
                    return j + 1
        
        # Ki·ªÉm tra h√¨nh ·∫£nh
        elif any(keyword in lower_line for keyword in image_keywords):
            for j in range(fig_idx, len(figures_sorted)):
                fig = figures_sorted[j]
                if not fig['is_table'] and fig['name'] not in used_figures:
                    tag = f"\n[H√åNH: {fig['name']}]\n"
                    processed_lines.append(tag)
                    used_figures.add(fig['name'])
                    return j + 1
        
        return fig_idx
    
    def _insert_remaining_figures(self, processed_lines, figures_sorted, used_figures, fig_idx):
        """Ch√®n c√°c ·∫£nh c√≤n l·∫°i"""
        question_patterns = [
            r"^(C√¢u|Question|Problem)\s*\d+",
            r"^\d+[\.\)]\s*",
            r"^[A-D][\.\)]\s*",
            r"^[a-d][\.\)]\s*"
        ]
        
        for i, line in enumerate(processed_lines):
            is_question = any(re.match(pattern, line.strip()) for pattern in question_patterns)
            
            if is_question and fig_idx < len(figures_sorted):
                next_line = processed_lines[i+1] if i+1 < len(processed_lines) else ""
                has_image = re.match(r"\[(H√åNH|B·∫¢NG):.*\]", next_line.strip())
                
                if not has_image:
                    while (fig_idx < len(figures_sorted) and 
                           figures_sorted[fig_idx]['name'] in used_figures):
                        fig_idx += 1
                    
                    if fig_idx < len(figures_sorted):
                        fig = figures_sorted[fig_idx]
                        tag = (f"\n[B·∫¢NG: {fig['name']}]\n" if fig['is_table'] 
                               else f"\n[H√åNH: {fig['name']}]\n")
                        processed_lines.insert(i+1, tag)
                        used_figures.add(fig['name'])
                        fig_idx += 1
        
        return processed_lines

class GeminiAPI:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"
    
    def encode_image(self, image_data: bytes) -> str:
        """M√£ h√≥a ·∫£nh th√†nh base64"""
        return base64.b64encode(image_data).decode('utf-8')
    
    def convert_to_latex(self, content_data: bytes, content_type: str, prompt: str) -> str:
        """Chuy·ªÉn ƒë·ªïi n·ªôi dung sang LaTeX s·ª≠ d·ª•ng Gemini API"""
        headers = {"Content-Type": "application/json"}
        
        if content_type.startswith('image/'):
            mime_type = content_type
        else:
            mime_type = "image/png"
        
        encoded_content = self.encode_image(content_data)
        
        payload = {
            "contents": [
                {
                    "parts": [
                        {"text": prompt},
                        {
                            "inline_data": {
                                "mime_type": mime_type,
                                "data": encoded_content
                            }
                        }
                    ]
                }
            ],
            "generationConfig": {
                "temperature": 0.1,
                "topK": 1,
                "topP": 0.8,
                "maxOutputTokens": 8192,
            }
        }
        
        try:
            response = requests.post(
                f"{self.base_url}?key={self.api_key}",
                headers=headers,
                json=payload,
                timeout=90
            )
            
            if response.status_code == 200:
                result = response.json()
                if 'candidates' in result and len(result['candidates']) > 0:
                    content = result['candidates'][0]['content']['parts'][0]['text']
                    return content.strip()
                else:
                    raise Exception("API kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£ h·ª£p l·ªá")
            elif response.status_code == 401:
                raise Exception("API key kh√¥ng h·ª£p l·ªá ho·∫∑c ƒë√£ h·∫øt h·∫°n")
            elif response.status_code == 429:
                raise Exception("ƒê√£ v∆∞·ª£t qu√° gi·ªõi h·∫°n rate limit")
            else:
                raise Exception(f"API Error {response.status_code}: {response.text}")
        
        except requests.exceptions.Timeout:
            raise Exception("Request timeout - th·ª≠ l·∫°i sau √≠t ph√∫t")
        except requests.exceptions.ConnectionError:
            raise Exception("L·ªói k·∫øt n·ªëi m·∫°ng")
        except Exception as e:
            raise Exception(str(e))

class PDFProcessor:
    @staticmethod
    def extract_images_and_text(pdf_file):
        """Tr√≠ch xu·∫•t ·∫£nh v√† chuy·ªÉn ƒë·ªïi trang PDF th√†nh ·∫£nh"""
        pdf_document = fitz.open(stream=pdf_file.read(), filetype="pdf")
        images = []
        
        for page_num in range(pdf_document.page_count):
            page = pdf_document[page_num]
            mat = fitz.Matrix(3.0, 3.0)  # TƒÉng ƒë·ªô ph√¢n gi·∫£i l√™n 3x
            pix = page.get_pixmap(matrix=mat)
            img_data = pix.tobytes("png")
            img = Image.open(io.BytesIO(img_data))
            images.append((img, page_num + 1))
        
        pdf_document.close()
        return images

class WordExporter:
    @staticmethod
    def create_word_document(latex_content: str, extracted_figures=None, images=None) -> io.BytesIO:
        """T·∫°o file Word v·ªõi ƒë·ªãnh d·∫°ng LaTeX chu·∫©n"""
        doc = Document()
        
        # Th√™m ti√™u ƒë·ªÅ
        title = doc.add_heading('T√†i li·ªáu ƒë√£ chuy·ªÉn ƒë·ªïi t·ª´ PDF/·∫¢nh', 0)
        title.alignment = 1
        
        # Th√™m th√¥ng tin
        doc.add_paragraph(f"ƒê∆∞·ª£c t·∫°o b·ªüi PDF/Image to LaTeX Converter Ultra")
        doc.add_paragraph(f"Th·ªùi gian: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        doc.add_paragraph("")
        
        # X·ª≠ l√Ω n·ªôi dung LaTeX v·ªõi ƒë·ªãnh d·∫°ng ${......}$
        lines = latex_content.split('\n')
        
        for line in lines:
            line = line.strip()
            
            # B·ªè qua c√°c d√≤ng ```latex n·∫øu c√≥
            if line.startswith('```') or line.endswith('```'):
                continue
            
            # X·ª≠ l√Ω tag ·∫£nh/b·∫£ng ƒë√£ t√°ch
            if line.startswith('[H√åNH:') and line.endswith(']'):
                img_name = line.replace('[H√åNH:', '').replace(']', '').strip()
                WordExporter._insert_extracted_image(doc, img_name, extracted_figures, "H√¨nh minh h·ªça")
                continue
            elif line.startswith('[B·∫¢NG:') and line.endswith(']'):
                img_name = line.replace('[B·∫¢NG:', '').replace(']', '').strip()
                WordExporter._insert_extracted_image(doc, img_name, extracted_figures, "B·∫£ng s·ªë li·ªáu")
                continue
            
            # Skip comments
            if line.startswith('<!--') and line.endswith('-->'):
                if 'Trang' in line or '·∫¢nh' in line:
                    doc.add_heading(line.replace('<!--', '').replace('-->', '').strip(), level=2)
                continue
            
            if not line:
                continue
            
            # X·ª≠ l√Ω c√¥ng th·ª©c LaTeX v·ªõi ƒë·ªãnh d·∫°ng ${......}$
            if '${' in line and '}
        
        # Th√™m ·∫£nh g·ªëc n·∫øu c√≥ (fallback)
        if images and not extracted_figures:
            doc.add_page_break()
            doc.add_heading('H√¨nh ·∫£nh g·ªëc', level=1)
            
            for i, img in enumerate(images):
                try:
                    doc.add_heading(f'H√¨nh {i+1}', level=2)
                    
                    if img.mode in ('RGBA', 'LA', 'P'):
                        img = img.convert('RGB')
                    
                    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
                        img.save(tmp.name, 'PNG')
                        try:
                            doc.add_picture(tmp.name, width=doc.sections[0].page_width * 0.8)
                        except Exception:
                            doc.add_paragraph(f"[H√¨nh ·∫£nh {i+1} - Kh√¥ng th·ªÉ hi·ªÉn th·ªã]")
                        os.unlink(tmp.name)
                except Exception:
                    doc.add_paragraph(f"[L·ªói hi·ªÉn th·ªã h√¨nh {i+1}]")
        
        buffer = io.BytesIO()
        doc.save(buffer)
        buffer.seek(0)
        return buffer
    
    @staticmethod
    def _insert_extracted_image(doc, img_name, extracted_figures, caption_prefix):
        """Ch√®n ·∫£nh ƒë√£ t√°ch v√†o Word document"""
        if not extracted_figures:
            doc.add_paragraph(f"[{caption_prefix}: {img_name} - Kh√¥ng t√¨m th·∫•y]")
            return
        
        target_figure = None
        for fig in extracted_figures:
            if fig['name'] == img_name:
                target_figure = fig
                break
        
        if not target_figure:
            doc.add_paragraph(f"[{caption_prefix}: {img_name} - Kh√¥ng t√¨m th·∫•y]")
            return
        
        try:
            doc.add_heading(f"{caption_prefix}: {img_name}", level=3)
            
            img_data = base64.b64decode(target_figure['base64'])
            img_pil = Image.open(io.BytesIO(img_data))
            
            if img_pil.mode in ('RGBA', 'LA', 'P'):
                img_pil = img_pil.convert('RGB')
            
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
                img_pil.save(tmp.name, 'PNG')
                try:
                    max_width = doc.sections[0].page_width * 0.8
                    doc.add_picture(tmp.name, width=max_width)
                except Exception:
                    doc.add_paragraph(f"[Kh√¥ng th·ªÉ hi·ªÉn th·ªã {img_name}]")
                os.unlink(tmp.name)
        
        except Exception as e:
            doc.add_paragraph(f"[L·ªói hi·ªÉn th·ªã {img_name}: {str(e)}]")

def validate_api_key(api_key: str) -> bool:
    """Ki·ªÉm tra t√≠nh h·ª£p l·ªá c·ªßa API key"""
    if not api_key or len(api_key) < 20:
        return False
    return re.match(r'^[A-Za-z0-9_-]+$', api_key) is not None

def format_file_size(size_bytes: int) -> str:
    """Chuy·ªÉn ƒë·ªïi k√≠ch th∆∞·ªõc file sang ƒë·ªãnh d·∫°ng human-readable"""
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"

def main():
    st.markdown('<h1 class="main-header">üìù PDF/Image to LaTeX Converter - Ultra Enhanced</h1>', unsafe_allow_html=True)
    
    # Sidebar cho API key
    with st.sidebar:
        st.header("‚öôÔ∏è C√†i ƒë·∫∑t")
        api_key = st.text_input(
            "Gemini API Key", 
            type="password", 
            help="Nh·∫≠p API key t·ª´ Google AI Studio",
            placeholder="Paste your API key here..."
        )
        
        if api_key:
            if validate_api_key(api_key):
                st.success("‚úÖ API key h·ª£p l·ªá")
            else:
                st.error("‚ùå API key kh√¥ng h·ª£p l·ªá")
        
        st.markdown("---")
        
        # C√†i ƒë·∫∑t t√°ch ·∫£nh si√™u n√¢ng cao
        st.subheader("üñºÔ∏è T√°ch ·∫£nh si√™u ch√≠nh x√°c")
        enable_extraction = st.checkbox("B·∫≠t t√°ch ·∫£nh/b·∫£ng si√™u n√¢ng cao", value=True, 
                                       help="Thu·∫≠t to√°n AI t√°ch ·∫£nh v·ªõi ƒë·ªô ch√≠nh x√°c c·ª±c cao")
        
        if enable_extraction:
            st.write("**C√†i ƒë·∫∑t si√™u n√¢ng cao:**")
            min_area = st.slider("Di·ªán t√≠ch t·ªëi thi·ªÉu (%)", 0.1, 5.0, 0.3, 0.1,
                               help="% di·ªán t√≠ch ·∫£nh g·ªëc") / 100
            max_figures = st.slider("S·ªë ·∫£nh t·ªëi ƒëa", 1, 25, 12, 1)
            min_size = st.slider("K√≠ch th∆∞·ªõc t·ªëi thi·ªÉu (px)", 30, 300, 40, 10)
            padding = st.slider("Padding xung quanh (px)", 0, 30, 8, 1)
            confidence_threshold = st.slider("Ng∆∞·ª°ng confidence (%)", 30, 90, 50, 5)
            
            show_debug = st.checkbox("Hi·ªÉn th·ªã ·∫£nh debug n√¢ng cao", value=True,
                                   help="Hi·ªÉn th·ªã ·∫£nh v·ªõi confidence score v√† ph√¢n t√≠ch chi ti·∫øt")
        
        st.markdown("---")
        st.markdown("""
        ### üìã H∆∞·ªõng d·∫´n:
        1. Nh·∫≠p API key Gemini
        2. Ch·ªçn tab PDF ho·∫∑c ·∫¢nh  
        3. Upload file
        4. Ch·ªù x·ª≠ l√Ω v√† t·∫£i file Word
        
        ### üéØ T√≠nh nƒÉng si√™u n√¢ng cao:
        - ‚úÖ Thu·∫≠t to√°n AI c·∫Øt ·∫£nh v·ªõi NMS
        - ‚úÖ Confidence scoring th√¥ng minh
        - ‚úÖ ƒê·ªãnh d·∫°ng LaTeX chu·∫©n: `${......}$`
        - ‚úÖ Ph√¢n t√≠ch n·ªôi dung v√πng
        - ‚úÖ Multi-scale edge detection
        

        
        **Tr·∫Øc nghi·ªám 4 ph∆∞∆°ng √°n:**
        ```
        C√¢u X: [n·ªôi dung]
        A. [ƒê√°p √°n]
        B. [ƒê√°p √°n]  
        C. [ƒê√°p √°n]
        D. [ƒê√°p √°n]
        ```
        
        **Tr·∫Øc nghi·ªám ƒë√∫ng sai:**
        ```
        C√¢u X: [n·ªôi dung n·∫øu c√≥]
        a) [ƒê√°p √°n]
        b) [ƒê√°p √°n]
        c) [ƒê√°p √°n]
        d) [ƒê√°p √°n]
        ```
        
        **T·ª± lu·∫≠n:**
        ```
        C√¢u X: [n·ªôi dung]
        ```
        
        ### üîë L·∫•y API Key:
        [Google AI Studio](https://makersuite.google.com/app/apikey)
        """)
    
    if not api_key:
        st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p Gemini API Key ·ªü sidebar ƒë·ªÉ b·∫Øt ƒë·∫ßu!")
        st.info("üí° B·∫°n c√≥ th·ªÉ l·∫•y API key mi·ªÖn ph√≠ t·∫°i Google AI Studio")
        return
    
    if not validate_api_key(api_key):
        st.error("‚ùå API key kh√¥ng h·ª£p l·ªá. Vui l√≤ng ki·ªÉm tra l·∫°i!")
        return
    
    # T·∫°o tabs
    tab1, tab2 = st.tabs(["üìÑ PDF to LaTeX + Ultra Extract", "üñºÔ∏è Image to LaTeX + Ultra Extract"])
    
    # Kh·ªüi t·∫°o API v√† ImageExtractor
    try:
        gemini_api = GeminiAPI(api_key)
        if enable_extraction:
            image_extractor = UltraImageExtractor()
            image_extractor.min_area_ratio = min_area
            image_extractor.max_figures = max_figures
            image_extractor.min_width = min_size
            image_extractor.min_height = min_size
            image_extractor.padding = padding
            image_extractor.confidence_threshold = confidence_threshold
    except Exception as e:
        st.error(f"‚ùå L·ªói kh·ªüi t·∫°o: {str(e)}")
        return
    
    # Tab x·ª≠ l√Ω PDF
    with tab1:
        st.header("üìÑ Chuy·ªÉn ƒë·ªïi PDF sang LaTeX + T√°ch ·∫£nh si√™u ch√≠nh x√°c")
        
        uploaded_pdf = st.file_uploader(
            "Ch·ªçn file PDF",
            type=['pdf'],
            help="Upload file PDF ch·ª©a c√¥ng th·ª©c to√°n h·ªçc v√† h√¨nh ·∫£nh"
        )
        
        if uploaded_pdf:
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.subheader("üìã Preview PDF")
                st.info(f"üìÅ File: {uploaded_pdf.name}")
                st.info(f"üìè K√≠ch th∆∞·ªõc: {format_file_size(uploaded_pdf.size)}")
                
                with st.spinner("üîÑ ƒêang x·ª≠ l√Ω PDF v·ªõi ƒë·ªô ph√¢n gi·∫£i cao..."):
                    try:
                        pdf_images = PDFProcessor.extract_images_and_text(uploaded_pdf)
                        st.success(f"‚úÖ ƒê√£ tr√≠ch xu·∫•t {len(pdf_images)} trang (3x resolution)")
                        
                        # Hi·ªÉn th·ªã preview
                        for img, page_num in pdf_images[:2]:
                            st.write(f"**Trang {page_num}:**")
                            st.image(img, use_column_width=True)
                        
                        if len(pdf_images) > 2:
                            st.info(f"... v√† {len(pdf_images) - 2} trang kh√°c")
                    
                    except Exception as e:
                        st.error(f"‚ùå L·ªói x·ª≠ l√Ω PDF: {str(e)}")
                        pdf_images = []
            
            with col2:
                st.subheader("‚ö° Chuy·ªÉn ƒë·ªïi sang LaTeX")
                
                if st.button("üöÄ B·∫Øt ƒë·∫ßu chuy·ªÉn ƒë·ªïi si√™u n√¢ng cao", key="convert_pdf"):
                    if pdf_images:
                        all_latex_content = []
                        all_extracted_figures = []
                        all_debug_images = []
                        
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        for i, (img, page_num) in enumerate(pdf_images):
                            status_text.text(f"ƒêang x·ª≠ l√Ω trang {page_num}/{len(pdf_images)} v·ªõi AI si√™u n√¢ng cao...")
                            
                            # Chuy·ªÉn ·∫£nh th√†nh bytes
                            img_buffer = io.BytesIO()
                            img.save(img_buffer, format='PNG')
                            img_bytes = img_buffer.getvalue()
                            
                            # T√°ch ·∫£nh/b·∫£ng n·∫øu ƒë∆∞·ª£c b·∫≠t
                            extracted_figures = []
                            if enable_extraction:
                                try:
                                    figures, h, w = image_extractor.extract_figures_and_tables(img_bytes)
                                    extracted_figures = figures
                                    all_extracted_figures.extend(figures)
                                    
                                    # T·∫°o ·∫£nh debug
                                    if show_debug and figures:
                                        debug_img = image_extractor.create_debug_image(img_bytes, figures)
                                        all_debug_images.append((debug_img, page_num, figures))
                                    
                                    high_conf = len([f for f in figures if f['confidence'] > 80])
                                    st.write(f"üéØ Trang {page_num}: T√°ch ƒë∆∞·ª£c {len(figures)} ·∫£nh/b·∫£ng (High conf: {high_conf})")
                                    
                                except Exception as e:
                                    st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t√°ch ·∫£nh trang {page_num}: {str(e)}")
                            
                            # T·∫°o prompt si√™u c·∫£i ti·∫øn cho Gemini
                            prompt = f"""
H√£y chuy·ªÉn ƒë·ªïi T·∫§T C·∫¢ n·ªôi dung trong ·∫£nh trang {page_num} th√†nh vƒÉn b·∫£n thu·∫ßn t√∫y v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n.

üéØ QUAN TR·ªåNG - CH·ªà XU·∫§T RA V√ÑN B·∫¢N THU·∫¶N T√öY, KH√îNG D√ôNG ```latex hay markdown:

üìù ƒê·ªäNH D·∫†NG B·∫ÆT BU·ªòC:

1. **Tr·∫Øc nghi·ªám 4 ph∆∞∆°ng √°n - ƒë·ªãnh d·∫°ng ch√≠nh x√°c:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß]
A. [ƒë√°p √°n A chi ti·∫øt]
B. [ƒë√°p √°n B chi ti·∫øt]  
C. [ƒë√°p √°n C chi ti·∫øt]
D. [ƒë√°p √°n D chi ti·∫øt]

2. **Tr·∫Øc nghi·ªám ƒë√∫ng sai - ƒë·ªãnh d·∫°ng ch√≠nh x√°c:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi n·∫øu c√≥]
a) [n·ªôi dung ƒë√°p √°n a ƒë·∫ßy ƒë·ªß]
b) [n·ªôi dung ƒë√°p √°n b ƒë·∫ßy ƒë·ªß]  
c) [n·ªôi dung ƒë√°p √°n c ƒë·∫ßy ƒë·ªß]
d) [n·ªôi dung ƒë√°p √°n d ƒë·∫ßy ƒë·ªß]

3. **Tr·∫£ l·ªùi ng·∫Øn/T·ª± lu·∫≠n:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß]

4. **C√¥ng th·ª©c to√°n h·ªçc - TUY·ªÜT ƒê·ªêI QUAN TR·ªåNG:**
- **CH·ªà s·ª≠ d·ª•ng ƒë·ªãnh d·∫°ng:** ${{x^2 + y^2}}$ cho M·ªåI c√¥ng th·ª©c
- **V√ç D·ª§ ƒê√öNG:** ${{\\frac{{a+b}}{{c-d}}}}$, ${{\\int_0^1 x dx}}$, ${{\\sqrt{{x^2+1}}}}$, ${{\\perp}}$, ${{\\parallel}}$
- **TUY·ªÜT ƒê·ªêI KH√îNG d√πng:** ```latex, $...$, $...$, hay b·∫•t k·ª≥ markdown n√†o

5. **K√Ω hi·ªáu ƒë·∫∑c bi·ªát:**
- Vu√¥ng g√≥c: ${{\\perp}}$
- Song song: ${{\\parallel}}$ ho·∫∑c //
- G√≥c: ${{\\angle}}$ ho·∫∑c d√πng t·ª´ "g√≥c"
- ƒê·ªô: ¬∞ ho·∫∑c ${{^\\circ}}$

6. **H√¨nh ·∫£nh v√† b·∫£ng:**
{'- Khi th·∫•y h√¨nh ·∫£nh/ƒë·ªì th·ªã: d√πng "xem h√¨nh", "theo h√¨nh", "h√¨nh sau"' if enable_extraction else ''}
{'- Khi th·∫•y b·∫£ng: d√πng "b·∫£ng sau", "theo b·∫£ng", "quan s√°t b·∫£ng"' if enable_extraction else ''}

‚ö†Ô∏è L∆ØU √ù QUAN TR·ªåNG:
- KH√îNG xu·∫•t ra ```latex hay b·∫•t k·ª≥ code block n√†o
- KH√îNG d√πng markdown formatting
- CH·ªà xu·∫•t ra vƒÉn b·∫£n thu·∫ßn t√∫y v·ªõi c√¥ng th·ª©c ${{...}}$
- Gi·ªØ CH√çNH X√ÅC 100% th·ª© t·ª± v√† c·∫•u tr√∫c n·ªôi dung
- Bao g·ªìm T·∫§T C·∫¢ text, s·ªë, k√Ω hi·ªáu v√† c√¥ng th·ª©c t·ª´ ·∫£nh
- Vi·∫øt ƒë·∫ßy ƒë·ªß n·ªôi dung, kh√¥ng r√∫t g·ªçn ho·∫∑c t√≥m t·∫Øt

V√ç D·ª§ OUTPUT ƒê√öNG:
C√¢u 64: Trong h√¨nh h·ªôp ${{ABCD.A'B'C'D'}}$ c√≥ t·∫•t c·∫£ c√°c c·∫°nh ƒë·ªÅu b·∫±ng nhau. X√©t t√≠nh ƒë√∫ng sai c·ªßa c√°c kh·∫≥ng ƒë·ªãnh sau:
a) ${{ABCD}}$ l√† h√¨nh ch·ªØ nh·∫≠t.
b) ${{A'C' \\perp BD}}$
c) ${{A'B \\perp D'C}}$  
d) ${{BC' \\perp A'D}}$
"""
                            
                            # G·ªçi API
                            try:
                                latex_result = gemini_api.convert_to_latex(img_bytes, "image/png", prompt)
                                if latex_result:
                                    # Ch√®n ·∫£nh v√†o vƒÉn b·∫£n n·∫øu c√≥ t√°ch ·∫£nh
                                    if enable_extraction and extracted_figures:
                                        latex_result = image_extractor.insert_figures_into_text(
                                            latex_result, extracted_figures, h, w
                                        )
                                    
                                    all_latex_content.append(f"<!-- Trang {page_num} -->\n{latex_result}\n")
                                else:
                                    st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ x·ª≠ l√Ω trang {page_num}")
                            except Exception as e:
                                st.error(f"‚ùå L·ªói x·ª≠ l√Ω trang {page_num}: {str(e)}")
                            
                            progress_bar.progress((i + 1) / len(pdf_images))
                        
                        status_text.text("‚úÖ Ho√†n th√†nh chuy·ªÉn ƒë·ªïi si√™u n√¢ng cao!")
                        
                        # Hi·ªÉn th·ªã k·∫øt qu·∫£
                        combined_latex = "\n".join(all_latex_content)
                        
                        st.markdown('<div class="latex-output">', unsafe_allow_html=True)
                        st.text_area("üìù K·∫øt qu·∫£ (ƒë·ªãnh d·∫°ng chu·∫©n - vƒÉn b·∫£n thu·∫ßn t√∫y):", combined_latex, height=300)
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                        # Hi·ªÉn th·ªã th·ªëng k√™ chi ti·∫øt
                        if enable_extraction:
                            total_figs = len(all_extracted_figures)
                            high_conf = len([f for f in all_extracted_figures if f['confidence'] > 80])
                            medium_conf = len([f for f in all_extracted_figures if 60 <= f['confidence'] <= 80])
                            low_conf = len([f for f in all_extracted_figures if f['confidence'] < 60])
                            
                            st.markdown(f"""
                            **üìä Th·ªëng k√™ chi ti·∫øt:**
                            - üéØ T·ªïng c·ªông: **{total_figs}** ·∫£nh/b·∫£ng ƒë√£ t√°ch
                            - <span class="confidence-high">üü¢ High confidence (>80%): {high_conf}</span>
                            - <span class="confidence-medium">üü° Medium confidence (60-80%): {medium_conf}</span>  
                            - <span class="confidence-low">üî¥ Low confidence (<60%): {low_conf}</span>
                            """, unsafe_allow_html=True)
                            
                            # Hi·ªÉn th·ªã ·∫£nh debug v√† ·∫£nh ƒë√£ c·∫Øt
                            if show_debug and all_debug_images:
                                st.subheader("üîç Debug Si√™u N√¢ng Cao - Ph√¢n T√≠ch AI")
                                
                                for debug_img, page_num, figures in all_debug_images:
                                    st.write(f"**üîç Trang {page_num} - AI Detection Analysis:**")
                                    st.image(debug_img, caption=f"AI ph√°t hi·ªán {len(figures)} v√πng v·ªõi confidence scores", use_column_width=True)
                                    
                                    # Hi·ªÉn th·ªã t·ª´ng ·∫£nh ƒë√£ c·∫Øt v·ªõi th√¥ng tin si√™u chi ti·∫øt
                                    if figures:
                                        st.write("**üìã Chi ti·∫øt t·ª´ng v√πng ƒë√£ c·∫Øt:**")
                                        cols = st.columns(min(len(figures), 3))
                                        for idx, fig in enumerate(figures):
                                            with cols[idx % 3]:
                                                # Decode v√† hi·ªÉn th·ªã ·∫£nh c·∫Øt
                                                img_data = base64.b64decode(fig['base64'])
                                                img_pil = Image.open(io.BytesIO(img_data))
                                                
                                                st.markdown(f'<div class="extracted-image">', unsafe_allow_html=True)
                                                st.image(img_pil, caption=f"{fig['name']} - {fig['confidence']:.1f}%", use_column_width=True)
                                                
                                                # X√°c ƒë·ªãnh m√†u confidence
                                                conf_class = "confidence-high" if fig['confidence'] > 80 else "confidence-medium" if fig['confidence'] >= 60 else "confidence-low"
                                                
                                                # Th√¥ng tin si√™u chi ti·∫øt
                                                st.markdown(f'''
                                                <div class="image-info">
                                                <strong>{fig['name']}</strong><br>
                                                üè∑Ô∏è Lo·∫°i: {"üìä B·∫£ng" if fig['is_table'] else "üñºÔ∏è H√¨nh ·∫£nh"}<br>
                                                <span class="{conf_class}">üéØ Confidence: {fig['confidence']:.1f}%</span><br>
                                                üìê T·ª∑ l·ªá: {fig['aspect_ratio']:.2f}<br>
                                                üìè K√≠ch th∆∞·ªõc: {fig['bbox'][2]}√ó{fig['bbox'][3]}px<br>
                                                üî∫ Solidity: {fig['solidity']:.2f}<br>
                                                üìä Di·ªán t√≠ch: {fig['area']:,}px¬≤<br>
                                                {'üîç Ph√¢n t√≠ch: ' + str(fig.get('content_analysis', {}).get('has_lines', 0)) + ' ƒë∆∞·ªùng k·∫ª' if 'content_analysis' in fig else ''}
                                                </div>
                                                ''', unsafe_allow_html=True)
                                                st.markdown('</div>', unsafe_allow_html=True)
                        
                        # L∆∞u v√†o session state
                        st.session_state.pdf_latex_content = combined_latex
                        st.session_state.pdf_images = [img for img, _ in pdf_images]
                        st.session_state.pdf_extracted_figures = all_extracted_figures if enable_extraction else None
                
                # T·∫°o file Word
                if 'pdf_latex_content' in st.session_state:
                    st.markdown("---")
                    if st.button("üì• T·∫°o file Word (ƒë·ªãnh d·∫°ng chu·∫©n ${......}$)", key="create_word_pdf"):
                        with st.spinner("üîÑ ƒêang t·∫°o file Word v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n..."):
                            try:
                                extracted_figs = st.session_state.get('pdf_extracted_figures')
                                original_imgs = st.session_state.pdf_images
                                
                                word_buffer = WordExporter.create_word_document(
                                    st.session_state.pdf_latex_content, 
                                    extracted_figures=extracted_figs,
                                    images=original_imgs
                                )
                                
                                filename = f"{uploaded_pdf.name.split('.')[0]}_ultra_latex.docx"
                                
                                st.download_button(
                                    label="üì• T·∫£i file Word (Ultra Enhanced)",
                                    data=word_buffer.getvalue(),
                                    file_name=filename,
                                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                                )
                                
                                st.download_button(
                                    label="üìù T·∫£i LaTeX source (.tex)",
                                    data=st.session_state.pdf_latex_content,
                                    file_name=uploaded_pdf.name.replace('.pdf', '.tex'),
                                    mime="text/plain"
                                )
                                
                                st.success("‚úÖ File Word v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n ${......}$ ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
                            
                            except Exception as e:
                                st.error(f"‚ùå L·ªói t·∫°o file Word: {str(e)}")
    
    # Tab x·ª≠ l√Ω ·∫£nh (t∆∞∆°ng t·ª± nh∆∞ PDF tab)
    with tab2:
        st.header("üñºÔ∏è Chuy·ªÉn ƒë·ªïi ·∫¢nh sang LaTeX + T√°ch ·∫£nh si√™u ch√≠nh x√°c")
        
        uploaded_images = st.file_uploader(
            "Ch·ªçn ·∫£nh (c√≥ th·ªÉ ch·ªçn nhi·ªÅu)",
            type=['png', 'jpg', 'jpeg', 'bmp', 'tiff'],
            accept_multiple_files=True,
            help="Upload ·∫£nh ch·ª©a c√¥ng th·ª©c to√°n h·ªçc v√† h√¨nh minh h·ªça"
        )
        
        if uploaded_images:
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.subheader("üñºÔ∏è Preview ·∫¢nh")
                
                total_size = sum(img.size for img in uploaded_images)
                st.info(f"üìÅ S·ªë ·∫£nh: {len(uploaded_images)}")
                st.info(f"üìè T·ªïng k√≠ch th∆∞·ªõc: {format_file_size(total_size)}")
                
                for i, uploaded_image in enumerate(uploaded_images[:2]):
                    st.write(f"**·∫¢nh {i+1}: {uploaded_image.name}**")
                    image = Image.open(uploaded_image)
                    st.image(image, use_column_width=True)
                
                if len(uploaded_images) > 2:
                    st.info(f"... v√† {len(uploaded_images) - 2} ·∫£nh kh√°c")
            
            with col2:
                st.subheader("‚ö° Chuy·ªÉn ƒë·ªïi sang LaTeX")
                
                if st.button("üöÄ B·∫Øt ƒë·∫ßu chuy·ªÉn ƒë·ªïi si√™u n√¢ng cao", key="convert_images"):
                    all_latex_content = []
                    all_extracted_figures = []
                    all_original_images = []
                    all_debug_images = []
                    
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    for i, uploaded_image in enumerate(uploaded_images):
                        status_text.text(f"ƒêang x·ª≠ l√Ω ·∫£nh {i+1}/{len(uploaded_images)} v·ªõi AI si√™u n√¢ng cao...")
                        
                        image_bytes = uploaded_image.getvalue()
                        image_pil = Image.open(uploaded_image)
                        all_original_images.append(image_pil)
                        
                        # T√°ch ·∫£nh/b·∫£ng n·∫øu ƒë∆∞·ª£c b·∫≠t
                        extracted_figures = []
                        if enable_extraction:
                            try:
                                figures, h, w = image_extractor.extract_figures_and_tables(image_bytes)
                                extracted_figures = figures
                                all_extracted_figures.extend(figures)
                                
                                # T·∫°o ·∫£nh debug
                                if show_debug and figures:
                                    debug_img = image_extractor.create_debug_image(image_bytes, figures)
                                    all_debug_images.append((debug_img, uploaded_image.name, figures))
                                
                                high_conf = len([f for f in figures if f['confidence'] > 80])
                                st.write(f"üéØ {uploaded_image.name}: T√°ch ƒë∆∞·ª£c {len(figures)} ·∫£nh/b·∫£ng (High conf: {high_conf})")
                            except Exception as e:
                                st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t√°ch ·∫£nh {uploaded_image.name}: {str(e)}")
                        
                        prompt = """
H√£y chuy·ªÉn ƒë·ªïi T·∫§T C·∫¢ n·ªôi dung trong ·∫£nh th√†nh vƒÉn b·∫£n thu·∫ßn t√∫y v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n.

üéØ QUAN TR·ªåNG - CH·ªà XU·∫§T RA V√ÑN B·∫¢N THU·∫¶N T√öY, KH√îNG D√ôNG ```latex hay markdown:

üìù ƒê·ªäNH D·∫†NG B·∫ÆT BU·ªòC:

1. **Tr·∫Øc nghi·ªám 4 ph∆∞∆°ng √°n - ƒë·ªãnh d·∫°ng ch√≠nh x√°c:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß]
A. [ƒë√°p √°n A chi ti·∫øt]
B. [ƒë√°p √°n B chi ti·∫øt]  
C. [ƒë√°p √°n C chi ti·∫øt]
D. [ƒë√°p √°n D chi ti·∫øt]

2. **Tr·∫Øc nghi·ªám ƒë√∫ng sai - ƒë·ªãnh d·∫°ng ch√≠nh x√°c:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi n·∫øu c√≥]
a) [n·ªôi dung ƒë√°p √°n a ƒë·∫ßy ƒë·ªß]
b) [n·ªôi dung ƒë√°p √°n b ƒë·∫ßy ƒë·ªß]  
c) [n·ªôi dung ƒë√°p √°n c ƒë·∫ßy ƒë·ªß]
d) [n·ªôi dung ƒë√°p √°n d ƒë·∫ßy ƒë·ªß]

3. **Tr·∫£ l·ªùi ng·∫Øn/T·ª± lu·∫≠n:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß]

4. **C√¥ng th·ª©c to√°n h·ªçc - TUY·ªÜT ƒê·ªêI QUAN TR·ªåNG:**
- **CH·ªà s·ª≠ d·ª•ng ƒë·ªãnh d·∫°ng:** ${x^2 + y^2}$ cho M·ªåI c√¥ng th·ª©c
- **V√ç D·ª§ ƒê√öNG:** ${\\frac{a+b}{c-d}}$, ${\\int_0^1 x dx}$, ${\\sqrt{x^2+1}}$, ${\\perp}$, ${\\parallel}$
- **TUY·ªÜT ƒê·ªêI KH√îNG d√πng:** ```latex, $...$, $...$, hay b·∫•t k·ª≥ markdown n√†o

5. **K√Ω hi·ªáu ƒë·∫∑c bi·ªát:**
- Vu√¥ng g√≥c: ${\\perp}$
- Song song: ${\\parallel}$ ho·∫∑c //
- G√≥c: ${\\angle}$ ho·∫∑c d√πng t·ª´ "g√≥c"
- ƒê·ªô: ¬∞ ho·∫∑c ${^\\circ}$

‚ö†Ô∏è L∆ØU √ù QUAN TR·ªåNG:
- KH√îNG xu·∫•t ra ```latex hay b·∫•t k·ª≥ code block n√†o
- KH√îNG d√πng markdown formatting
- CH·ªà xu·∫•t ra vƒÉn b·∫£n thu·∫ßn t√∫y v·ªõi c√¥ng th·ª©c ${...}$
- Gi·ªØ CH√çNH X√ÅC 100% th·ª© t·ª± v√† c·∫•u tr√∫c n·ªôi dung
- Bao g·ªìm T·∫§T C·∫¢ text, s·ªë, k√Ω hi·ªáu v√† c√¥ng th·ª©c t·ª´ ·∫£nh
- Vi·∫øt ƒë·∫ßy ƒë·ªß n·ªôi dung, kh√¥ng r√∫t g·ªçn ho·∫∑c t√≥m t·∫Øt

V√ç D·ª§ OUTPUT ƒê√öNG:
C√¢u 64: Trong h√¨nh h·ªôp ${ABCD.A'B'C'D'}$ c√≥ t·∫•t c·∫£ c√°c c·∫°nh ƒë·ªÅu b·∫±ng nhau. X√©t t√≠nh ƒë√∫ng sai c·ªßa c√°c kh·∫≥ng ƒë·ªãnh sau:
a) ${ABCD}$ l√† h√¨nh ch·ªØ nh·∫≠t.
b) ${A'C' \\perp BD}$
c) ${A'B \\perp D'C}$  
d) ${BC' \\perp A'D}$
"""
                        
                        try:
                            latex_result = gemini_api.convert_to_latex(
                                image_bytes, uploaded_image.type, prompt
                            )
                            if latex_result:
                                # Ch√®n ·∫£nh v√†o vƒÉn b·∫£n n·∫øu c√≥ t√°ch ·∫£nh
                                if enable_extraction and extracted_figures:
                                    latex_result = image_extractor.insert_figures_into_text(
                                        latex_result, extracted_figures, h, w
                                    )
                                
                                all_latex_content.append(
                                    f"<!-- ·∫¢nh {i+1}: {uploaded_image.name} -->\n{latex_result}\n"
                                )
                            else:
                                st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ x·ª≠ l√Ω ·∫£nh {uploaded_image.name}")
                        except Exception as e:
                            st.error(f"‚ùå L·ªói x·ª≠ l√Ω {uploaded_image.name}: {str(e)}")
                        
                        progress_bar.progress((i + 1) / len(uploaded_images))
                    
                    status_text.text("‚úÖ Ho√†n th√†nh chuy·ªÉn ƒë·ªïi si√™u n√¢ng cao!")
                    
                    # Hi·ªÉn th·ªã k·∫øt qu·∫£
                    combined_latex = "\n".join(all_latex_content)
                    
                    st.markdown('<div class="latex-output">', unsafe_allow_html=True)
                    st.text_area("üìù K·∫øt qu·∫£ (ƒë·ªãnh d·∫°ng chu·∫©n - vƒÉn b·∫£n thu·∫ßn t√∫y):", combined_latex, height=300)
                    st.markdown('</div>', unsafe_allow_html=True)
                    
                    # Hi·ªÉn th·ªã th·ªëng k√™ v√† ·∫£nh debug (t∆∞∆°ng t·ª± PDF tab)
                    if enable_extraction:
                        total_figs = len(all_extracted_figures)
                        high_conf = len([f for f in all_extracted_figures if f['confidence'] > 80])
                        medium_conf = len([f for f in all_extracted_figures if 60 <= f['confidence'] <= 80])
                        low_conf = len([f for f in all_extracted_figures if f['confidence'] < 60])
                        
                        st.markdown(f"""
                        **üìä Th·ªëng k√™ chi ti·∫øt:**
                        - üéØ T·ªïng c·ªông: **{total_figs}** ·∫£nh/b·∫£ng ƒë√£ t√°ch
                        - <span class="confidence-high">üü¢ High confidence (>80%): {high_conf}</span>
                        - <span class="confidence-medium">üü° Medium confidence (60-80%): {medium_conf}</span>  
                        - <span class="confidence-low">üî¥ Low confidence (<60%): {low_conf}</span>
                        """, unsafe_allow_html=True)
                        
                        if show_debug and all_debug_images:
                            st.subheader("üîç Debug Si√™u N√¢ng Cao - Ph√¢n T√≠ch AI")
                            
                            for debug_img, img_name, figures in all_debug_images:
                                st.write(f"**üîç {img_name} - AI Detection Analysis:**")
                                st.image(debug_img, caption=f"AI ph√°t hi·ªán {len(figures)} v√πng", use_column_width=True)
                                
                                if figures:
                                    st.write("**üìã Chi ti·∫øt t·ª´ng v√πng ƒë√£ c·∫Øt:**")
                                    cols = st.columns(min(len(figures), 3))
                                    for idx, fig in enumerate(figures):
                                        with cols[idx % 3]:
                                            img_data = base64.b64decode(fig['base64'])
                                            img_pil = Image.open(io.BytesIO(img_data))
                                            
                                            st.markdown(f'<div class="extracted-image">', unsafe_allow_html=True)
                                            st.image(img_pil, caption=f"{fig['name']} - {fig['confidence']:.1f}%", use_column_width=True)
                                            
                                            conf_class = "confidence-high" if fig['confidence'] > 80 else "confidence-medium" if fig['confidence'] >= 60 else "confidence-low"
                                            
                                            st.markdown(f'''
                                            <div class="image-info">
                                            <strong>{fig['name']}</strong><br>
                                            üè∑Ô∏è Lo·∫°i: {"üìä B·∫£ng" if fig['is_table'] else "üñºÔ∏è H√¨nh ·∫£nh"}<br>
                                            <span class="{conf_class}">üéØ Confidence: {fig['confidence']:.1f}%</span><br>
                                            üìê T·ª∑ l·ªá: {fig['aspect_ratio']:.2f}<br>
                                            üìè K√≠ch th∆∞·ªõc: {fig['bbox'][2]}√ó{fig['bbox'][3]}px<br>
                                            üî∫ Solidity: {fig['solidity']:.2f}<br>
                                            üìä Di·ªán t√≠ch: {fig['area']:,}px¬≤
                                            </div>
                                            ''', unsafe_allow_html=True)
                                            st.markdown('</div>', unsafe_allow_html=True)
                    
                    # L∆∞u v√†o session
                    st.session_state.image_latex_content = combined_latex
                    st.session_state.image_list = all_original_images
                    st.session_state.image_extracted_figures = all_extracted_figures if enable_extraction else None
                
                # T·∫°o file Word
                if 'image_latex_content' in st.session_state:
                    st.markdown("---")
                    if st.button("üì• T·∫°o file Word (ƒë·ªãnh d·∫°ng chu·∫©n ${......}$)", key="create_word_images"):
                        with st.spinner("üîÑ ƒêang t·∫°o file Word v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n..."):
                            try:
                                extracted_figs = st.session_state.get('image_extracted_figures')
                                original_imgs = st.session_state.image_list
                                
                                word_buffer = WordExporter.create_word_document(
                                    st.session_state.image_latex_content,
                                    extracted_figures=extracted_figs,
                                    images=original_imgs
                                )
                                
                                st.download_button(
                                    label="üì• T·∫£i file Word (Ultra Enhanced)",
                                    data=word_buffer.getvalue(),
                                    file_name="images_ultra_latex.docx",
                                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                                )
                                
                                st.download_button(
                                    label="üìù T·∫£i LaTeX source (.tex)",
                                    data=st.session_state.image_latex_content,
                                    file_name="images_converted.tex",
                                    mime="text/plain"
                                )
                                
                                st.success("‚úÖ File Word v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n ${......}$ ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
                            
                            except Exception as e:
                                st.error(f"‚ùå L·ªói t·∫°o file Word: {str(e)}")
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666;'>
        <p>ƒê∆∞·ª£c ph√°t tri·ªÉn v·ªõi ‚ù§Ô∏è s·ª≠ d·ª•ng Streamlit v√† Gemini 2.0 API</p>
        <p>‚ú® <strong>Ultra Enhanced Version:</strong> AI si√™u th√¥ng minh + ƒê·ªãnh d·∫°ng LaTeX chu·∫©n ${......}$!</p>
        <p>üéØ Thu·∫≠t to√°n NMS + Multi-scale Detection + Content Analysis + Confidence Scoring</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main() in line:
                p = doc.add_paragraph()
                
                # X·ª≠ l√Ω t·∫•t c·∫£ c√¥ng th·ª©c ${......}$ trong d√≤ng
                while '${' in line and '}
        
        # Th√™m ·∫£nh g·ªëc n·∫øu c√≥ (fallback)
        if images and not extracted_figures:
            doc.add_page_break()
            doc.add_heading('H√¨nh ·∫£nh g·ªëc', level=1)
            
            for i, img in enumerate(images):
                try:
                    doc.add_heading(f'H√¨nh {i+1}', level=2)
                    
                    if img.mode in ('RGBA', 'LA', 'P'):
                        img = img.convert('RGB')
                    
                    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
                        img.save(tmp.name, 'PNG')
                        try:
                            doc.add_picture(tmp.name, width=doc.sections[0].page_width * 0.8)
                        except Exception:
                            doc.add_paragraph(f"[H√¨nh ·∫£nh {i+1} - Kh√¥ng th·ªÉ hi·ªÉn th·ªã]")
                        os.unlink(tmp.name)
                except Exception:
                    doc.add_paragraph(f"[L·ªói hi·ªÉn th·ªã h√¨nh {i+1}]")
        
        buffer = io.BytesIO()
        doc.save(buffer)
        buffer.seek(0)
        return buffer
    
    @staticmethod
    def _insert_extracted_image(doc, img_name, extracted_figures, caption_prefix):
        """Ch√®n ·∫£nh ƒë√£ t√°ch v√†o Word document"""
        if not extracted_figures:
            doc.add_paragraph(f"[{caption_prefix}: {img_name} - Kh√¥ng t√¨m th·∫•y]")
            return
        
        target_figure = None
        for fig in extracted_figures:
            if fig['name'] == img_name:
                target_figure = fig
                break
        
        if not target_figure:
            doc.add_paragraph(f"[{caption_prefix}: {img_name} - Kh√¥ng t√¨m th·∫•y]")
            return
        
        try:
            doc.add_heading(f"{caption_prefix}: {img_name}", level=3)
            
            img_data = base64.b64decode(target_figure['base64'])
            img_pil = Image.open(io.BytesIO(img_data))
            
            if img_pil.mode in ('RGBA', 'LA', 'P'):
                img_pil = img_pil.convert('RGB')
            
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
                img_pil.save(tmp.name, 'PNG')
                try:
                    max_width = doc.sections[0].page_width * 0.8
                    doc.add_picture(tmp.name, width=max_width)
                except Exception:
                    doc.add_paragraph(f"[Kh√¥ng th·ªÉ hi·ªÉn th·ªã {img_name}]")
                os.unlink(tmp.name)
        
        except Exception as e:
            doc.add_paragraph(f"[L·ªói hi·ªÉn th·ªã {img_name}: {str(e)}]")

def validate_api_key(api_key: str) -> bool:
    """Ki·ªÉm tra t√≠nh h·ª£p l·ªá c·ªßa API key"""
    if not api_key or len(api_key) < 20:
        return False
    return re.match(r'^[A-Za-z0-9_-]+$', api_key) is not None

def format_file_size(size_bytes: int) -> str:
    """Chuy·ªÉn ƒë·ªïi k√≠ch th∆∞·ªõc file sang ƒë·ªãnh d·∫°ng human-readable"""
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"

def main():
    st.markdown('<h1 class="main-header">üìù PDF/Image to LaTeX Converter - Ultra Enhanced</h1>', unsafe_allow_html=True)
    
    # Sidebar cho API key
    with st.sidebar:
        st.header("‚öôÔ∏è C√†i ƒë·∫∑t")
        api_key = st.text_input(
            "Gemini API Key", 
            type="password", 
            help="Nh·∫≠p API key t·ª´ Google AI Studio",
            placeholder="Paste your API key here..."
        )
        
        if api_key:
            if validate_api_key(api_key):
                st.success("‚úÖ API key h·ª£p l·ªá")
            else:
                st.error("‚ùå API key kh√¥ng h·ª£p l·ªá")
        
        st.markdown("---")
        
        # C√†i ƒë·∫∑t t√°ch ·∫£nh si√™u n√¢ng cao
        st.subheader("üñºÔ∏è T√°ch ·∫£nh si√™u ch√≠nh x√°c")
        enable_extraction = st.checkbox("B·∫≠t t√°ch ·∫£nh/b·∫£ng si√™u n√¢ng cao", value=True, 
                                       help="Thu·∫≠t to√°n AI t√°ch ·∫£nh v·ªõi ƒë·ªô ch√≠nh x√°c c·ª±c cao")
        
        if enable_extraction:
            st.write("**C√†i ƒë·∫∑t si√™u n√¢ng cao:**")
            min_area = st.slider("Di·ªán t√≠ch t·ªëi thi·ªÉu (%)", 0.1, 5.0, 0.3, 0.1,
                               help="% di·ªán t√≠ch ·∫£nh g·ªëc") / 100
            max_figures = st.slider("S·ªë ·∫£nh t·ªëi ƒëa", 1, 25, 12, 1)
            min_size = st.slider("K√≠ch th∆∞·ªõc t·ªëi thi·ªÉu (px)", 30, 300, 40, 10)
            padding = st.slider("Padding xung quanh (px)", 0, 30, 8, 1)
            confidence_threshold = st.slider("Ng∆∞·ª°ng confidence (%)", 30, 90, 50, 5)
            
            show_debug = st.checkbox("Hi·ªÉn th·ªã ·∫£nh debug n√¢ng cao", value=True,
                                   help="Hi·ªÉn th·ªã ·∫£nh v·ªõi confidence score v√† ph√¢n t√≠ch chi ti·∫øt")
        
        st.markdown("---")
        st.markdown("""
        ### üìã H∆∞·ªõng d·∫´n:
        1. Nh·∫≠p API key Gemini
        2. Ch·ªçn tab PDF ho·∫∑c ·∫¢nh  
        3. Upload file
        4. Ch·ªù x·ª≠ l√Ω v√† t·∫£i file Word
        
        ### üéØ T√≠nh nƒÉng si√™u n√¢ng cao:
        - ‚úÖ Thu·∫≠t to√°n AI c·∫Øt ·∫£nh v·ªõi NMS
        - ‚úÖ Confidence scoring th√¥ng minh
        - ‚úÖ ƒê·ªãnh d·∫°ng LaTeX chu·∫©n: `${......}$`
        - ‚úÖ Ph√¢n t√≠ch n·ªôi dung v√πng
        - ‚úÖ Multi-scale edge detection
        
        ### üìù ƒê·ªãnh d·∫°ng LaTeX chu·∫©n:
        **C√¥ng th·ª©c inline:** `${x^2 + y^2}$`
        
        **Tr·∫Øc nghi·ªám 4 ph∆∞∆°ng √°n:**
        ```
        C√¢u X: [n·ªôi dung]
        A. [ƒê√°p √°n]
        B. [ƒê√°p √°n]  
        C. [ƒê√°p √°n]
        D. [ƒê√°p √°n]
        ```
        
        **Tr·∫Øc nghi·ªám ƒë√∫ng sai:**
        ```
        a) [ƒê√°p √°n]
        b) [ƒê√°p √°n]
        c) [ƒê√°p √°n]
        d) [ƒê√°p √°n]
        ```
        
        ### üîë L·∫•y API Key:
        [Google AI Studio](https://makersuite.google.com/app/apikey)
        """)
    
    if not api_key:
        st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p Gemini API Key ·ªü sidebar ƒë·ªÉ b·∫Øt ƒë·∫ßu!")
        st.info("üí° B·∫°n c√≥ th·ªÉ l·∫•y API key mi·ªÖn ph√≠ t·∫°i Google AI Studio")
        return
    
    if not validate_api_key(api_key):
        st.error("‚ùå API key kh√¥ng h·ª£p l·ªá. Vui l√≤ng ki·ªÉm tra l·∫°i!")
        return
    
    # T·∫°o tabs
    tab1, tab2 = st.tabs(["üìÑ PDF to LaTeX + Ultra Extract", "üñºÔ∏è Image to LaTeX + Ultra Extract"])
    
    # Kh·ªüi t·∫°o API v√† ImageExtractor
    try:
        gemini_api = GeminiAPI(api_key)
        if enable_extraction:
            image_extractor = UltraImageExtractor()
            image_extractor.min_area_ratio = min_area
            image_extractor.max_figures = max_figures
            image_extractor.min_width = min_size
            image_extractor.min_height = min_size
            image_extractor.padding = padding
            image_extractor.confidence_threshold = confidence_threshold
    except Exception as e:
        st.error(f"‚ùå L·ªói kh·ªüi t·∫°o: {str(e)}")
        return
    
    # Tab x·ª≠ l√Ω PDF
    with tab1:
        st.header("üìÑ Chuy·ªÉn ƒë·ªïi PDF sang LaTeX + T√°ch ·∫£nh si√™u ch√≠nh x√°c")
        
        uploaded_pdf = st.file_uploader(
            "Ch·ªçn file PDF",
            type=['pdf'],
            help="Upload file PDF ch·ª©a c√¥ng th·ª©c to√°n h·ªçc v√† h√¨nh ·∫£nh"
        )
        
        if uploaded_pdf:
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.subheader("üìã Preview PDF")
                st.info(f"üìÅ File: {uploaded_pdf.name}")
                st.info(f"üìè K√≠ch th∆∞·ªõc: {format_file_size(uploaded_pdf.size)}")
                
                with st.spinner("üîÑ ƒêang x·ª≠ l√Ω PDF v·ªõi ƒë·ªô ph√¢n gi·∫£i cao..."):
                    try:
                        pdf_images = PDFProcessor.extract_images_and_text(uploaded_pdf)
                        st.success(f"‚úÖ ƒê√£ tr√≠ch xu·∫•t {len(pdf_images)} trang (3x resolution)")
                        
                        # Hi·ªÉn th·ªã preview
                        for img, page_num in pdf_images[:2]:
                            st.write(f"**Trang {page_num}:**")
                            st.image(img, use_column_width=True)
                        
                        if len(pdf_images) > 2:
                            st.info(f"... v√† {len(pdf_images) - 2} trang kh√°c")
                    
                    except Exception as e:
                        st.error(f"‚ùå L·ªói x·ª≠ l√Ω PDF: {str(e)}")
                        pdf_images = []
            
            with col2:
                st.subheader("‚ö° Chuy·ªÉn ƒë·ªïi sang LaTeX")
                
                if st.button("üöÄ B·∫Øt ƒë·∫ßu chuy·ªÉn ƒë·ªïi si√™u n√¢ng cao", key="convert_pdf"):
                    if pdf_images:
                        all_latex_content = []
                        all_extracted_figures = []
                        all_debug_images = []
                        
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        for i, (img, page_num) in enumerate(pdf_images):
                            status_text.text(f"ƒêang x·ª≠ l√Ω trang {page_num}/{len(pdf_images)} v·ªõi AI si√™u n√¢ng cao...")
                            
                            # Chuy·ªÉn ·∫£nh th√†nh bytes
                            img_buffer = io.BytesIO()
                            img.save(img_buffer, format='PNG')
                            img_bytes = img_buffer.getvalue()
                            
                            # T√°ch ·∫£nh/b·∫£ng n·∫øu ƒë∆∞·ª£c b·∫≠t
                            extracted_figures = []
                            if enable_extraction:
                                try:
                                    figures, h, w = image_extractor.extract_figures_and_tables(img_bytes)
                                    extracted_figures = figures
                                    all_extracted_figures.extend(figures)
                                    
                                    # T·∫°o ·∫£nh debug
                                    if show_debug and figures:
                                        debug_img = image_extractor.create_debug_image(img_bytes, figures)
                                        all_debug_images.append((debug_img, page_num, figures))
                                    
                                    high_conf = len([f for f in figures if f['confidence'] > 80])
                                    st.write(f"üéØ Trang {page_num}: T√°ch ƒë∆∞·ª£c {len(figures)} ·∫£nh/b·∫£ng (High conf: {high_conf})")
                                    
                                except Exception as e:
                                    st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t√°ch ·∫£nh trang {page_num}: {str(e)}")
                            
                            # T·∫°o prompt si√™u c·∫£i ti·∫øn cho Gemini
                            prompt = f"""
H√£y chuy·ªÉn ƒë·ªïi T·∫§T C·∫¢ n·ªôi dung trong ·∫£nh trang {page_num} th√†nh vƒÉn b·∫£n thu·∫ßn t√∫y v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n.

üéØ QUAN TR·ªåNG - CH·ªà XU·∫§T RA V√ÑN B·∫¢N THU·∫¶N T√öY, KH√îNG D√ôNG ```latex hay markdown:

üìù ƒê·ªäNH D·∫†NG B·∫ÆT BU·ªòC:

1. **Tr·∫Øc nghi·ªám 4 ph∆∞∆°ng √°n - ƒë·ªãnh d·∫°ng ch√≠nh x√°c:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß]
A. [ƒë√°p √°n A chi ti·∫øt]
B. [ƒë√°p √°n B chi ti·∫øt]  
C. [ƒë√°p √°n C chi ti·∫øt]
D. [ƒë√°p √°n D chi ti·∫øt]

2. **Tr·∫Øc nghi·ªám ƒë√∫ng sai - ƒë·ªãnh d·∫°ng ch√≠nh x√°c:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi n·∫øu c√≥]
a) [n·ªôi dung ƒë√°p √°n a ƒë·∫ßy ƒë·ªß]
b) [n·ªôi dung ƒë√°p √°n b ƒë·∫ßy ƒë·ªß]  
c) [n·ªôi dung ƒë√°p √°n c ƒë·∫ßy ƒë·ªß]
d) [n·ªôi dung ƒë√°p √°n d ƒë·∫ßy ƒë·ªß]

3. **Tr·∫£ l·ªùi ng·∫Øn/T·ª± lu·∫≠n:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß]

4. **C√¥ng th·ª©c to√°n h·ªçc - TUY·ªÜT ƒê·ªêI QUAN TR·ªåNG:**
- **CH·ªà s·ª≠ d·ª•ng ƒë·ªãnh d·∫°ng:** ${{x^2 + y^2}}$ cho M·ªåI c√¥ng th·ª©c
- **V√ç D·ª§ ƒê√öNG:** ${{\\frac{{a+b}}{{c-d}}}}$, ${{\\int_0^1 x dx}}$, ${{\\sqrt{{x^2+1}}}}$, ${{\\perp}}$, ${{\\parallel}}$
- **TUY·ªÜT ƒê·ªêI KH√îNG d√πng:** ```latex, $...$, $...$, hay b·∫•t k·ª≥ markdown n√†o

5. **K√Ω hi·ªáu ƒë·∫∑c bi·ªát:**
- Vu√¥ng g√≥c: ${{\\perp}}$
- Song song: ${{\\parallel}}$ ho·∫∑c //
- G√≥c: ${{\\angle}}$ ho·∫∑c d√πng t·ª´ "g√≥c"
- ƒê·ªô: ¬∞ ho·∫∑c ${{^\\circ}}$

6. **H√¨nh ·∫£nh v√† b·∫£ng:**
{'- Khi th·∫•y h√¨nh ·∫£nh/ƒë·ªì th·ªã: d√πng "xem h√¨nh", "theo h√¨nh", "h√¨nh sau"' if enable_extraction else ''}
{'- Khi th·∫•y b·∫£ng: d√πng "b·∫£ng sau", "theo b·∫£ng", "quan s√°t b·∫£ng"' if enable_extraction else ''}

‚ö†Ô∏è L∆ØU √ù QUAN TR·ªåNG:
- KH√îNG xu·∫•t ra ```latex hay b·∫•t k·ª≥ code block n√†o
- KH√îNG d√πng markdown formatting
- CH·ªà xu·∫•t ra vƒÉn b·∫£n thu·∫ßn t√∫y v·ªõi c√¥ng th·ª©c ${{...}}$
- Gi·ªØ CH√çNH X√ÅC 100% th·ª© t·ª± v√† c·∫•u tr√∫c n·ªôi dung
- Bao g·ªìm T·∫§T C·∫¢ text, s·ªë, k√Ω hi·ªáu v√† c√¥ng th·ª©c t·ª´ ·∫£nh
- Vi·∫øt ƒë·∫ßy ƒë·ªß n·ªôi dung, kh√¥ng r√∫t g·ªçn ho·∫∑c t√≥m t·∫Øt

V√ç D·ª§ OUTPUT ƒê√öNG:
C√¢u 64: Trong h√¨nh h·ªôp ${{ABCD.A'B'C'D'}}$ c√≥ t·∫•t c·∫£ c√°c c·∫°nh ƒë·ªÅu b·∫±ng nhau. X√©t t√≠nh ƒë√∫ng sai c·ªßa c√°c kh·∫≥ng ƒë·ªãnh sau:
a) ${{ABCD}}$ l√† h√¨nh ch·ªØ nh·∫≠t.
b) ${{A'C' \\perp BD}}$
c) ${{A'B \\perp D'C}}$  
d) ${{BC' \\perp A'D}}$
"""
                            
                            # G·ªçi API
                            try:
                                latex_result = gemini_api.convert_to_latex(img_bytes, "image/png", prompt)
                                if latex_result:
                                    # Ch√®n ·∫£nh v√†o vƒÉn b·∫£n n·∫øu c√≥ t√°ch ·∫£nh
                                    if enable_extraction and extracted_figures:
                                        latex_result = image_extractor.insert_figures_into_text(
                                            latex_result, extracted_figures, h, w
                                        )
                                    
                                    all_latex_content.append(f"<!-- Trang {page_num} -->\n{latex_result}\n")
                                else:
                                    st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ x·ª≠ l√Ω trang {page_num}")
                            except Exception as e:
                                st.error(f"‚ùå L·ªói x·ª≠ l√Ω trang {page_num}: {str(e)}")
                            
                            progress_bar.progress((i + 1) / len(pdf_images))
                        
                        status_text.text("‚úÖ Ho√†n th√†nh chuy·ªÉn ƒë·ªïi si√™u n√¢ng cao!")
                        
                        # Hi·ªÉn th·ªã k·∫øt qu·∫£
                        combined_latex = "\n".join(all_latex_content)
                        
                        st.markdown('<div class="latex-output">', unsafe_allow_html=True)
                        st.text_area("üìù K·∫øt qu·∫£ LaTeX (ƒë·ªãnh d·∫°ng chu·∫©n ${......}$):", combined_latex, height=300)
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                        # Hi·ªÉn th·ªã th·ªëng k√™ chi ti·∫øt
                        if enable_extraction:
                            total_figs = len(all_extracted_figures)
                            high_conf = len([f for f in all_extracted_figures if f['confidence'] > 80])
                            medium_conf = len([f for f in all_extracted_figures if 60 <= f['confidence'] <= 80])
                            low_conf = len([f for f in all_extracted_figures if f['confidence'] < 60])
                            
                            st.markdown(f"""
                            **üìä Th·ªëng k√™ chi ti·∫øt:**
                            - üéØ T·ªïng c·ªông: **{total_figs}** ·∫£nh/b·∫£ng ƒë√£ t√°ch
                            - <span class="confidence-high">üü¢ High confidence (>80%): {high_conf}</span>
                            - <span class="confidence-medium">üü° Medium confidence (60-80%): {medium_conf}</span>  
                            - <span class="confidence-low">üî¥ Low confidence (<60%): {low_conf}</span>
                            """, unsafe_allow_html=True)
                            
                            # Hi·ªÉn th·ªã ·∫£nh debug v√† ·∫£nh ƒë√£ c·∫Øt
                            if show_debug and all_debug_images:
                                st.subheader("üîç Debug Si√™u N√¢ng Cao - Ph√¢n T√≠ch AI")
                                
                                for debug_img, page_num, figures in all_debug_images:
                                    st.write(f"**üîç Trang {page_num} - AI Detection Analysis:**")
                                    st.image(debug_img, caption=f"AI ph√°t hi·ªán {len(figures)} v√πng v·ªõi confidence scores", use_column_width=True)
                                    
                                    # Hi·ªÉn th·ªã t·ª´ng ·∫£nh ƒë√£ c·∫Øt v·ªõi th√¥ng tin si√™u chi ti·∫øt
                                    if figures:
                                        st.write("**üìã Chi ti·∫øt t·ª´ng v√πng ƒë√£ c·∫Øt:**")
                                        cols = st.columns(min(len(figures), 3))
                                        for idx, fig in enumerate(figures):
                                            with cols[idx % 3]:
                                                # Decode v√† hi·ªÉn th·ªã ·∫£nh c·∫Øt
                                                img_data = base64.b64decode(fig['base64'])
                                                img_pil = Image.open(io.BytesIO(img_data))
                                                
                                                st.markdown(f'<div class="extracted-image">', unsafe_allow_html=True)
                                                st.image(img_pil, caption=f"{fig['name']} - {fig['confidence']:.1f}%", use_column_width=True)
                                                
                                                # X√°c ƒë·ªãnh m√†u confidence
                                                conf_class = "confidence-high" if fig['confidence'] > 80 else "confidence-medium" if fig['confidence'] >= 60 else "confidence-low"
                                                
                                                # Th√¥ng tin si√™u chi ti·∫øt
                                                st.markdown(f'''
                                                <div class="image-info">
                                                <strong>{fig['name']}</strong><br>
                                                üè∑Ô∏è Lo·∫°i: {"üìä B·∫£ng" if fig['is_table'] else "üñºÔ∏è H√¨nh ·∫£nh"}<br>
                                                <span class="{conf_class}">üéØ Confidence: {fig['confidence']:.1f}%</span><br>
                                                üìê T·ª∑ l·ªá: {fig['aspect_ratio']:.2f}<br>
                                                üìè K√≠ch th∆∞·ªõc: {fig['bbox'][2]}√ó{fig['bbox'][3]}px<br>
                                                üî∫ Solidity: {fig['solidity']:.2f}<br>
                                                üìä Di·ªán t√≠ch: {fig['area']:,}px¬≤<br>
                                                {'üîç Ph√¢n t√≠ch: ' + str(fig.get('content_analysis', {}).get('has_lines', 0)) + ' ƒë∆∞·ªùng k·∫ª' if 'content_analysis' in fig else ''}
                                                </div>
                                                ''', unsafe_allow_html=True)
                                                st.markdown('</div>', unsafe_allow_html=True)
                        
                        # L∆∞u v√†o session state
                        st.session_state.pdf_latex_content = combined_latex
                        st.session_state.pdf_images = [img for img, _ in pdf_images]
                        st.session_state.pdf_extracted_figures = all_extracted_figures if enable_extraction else None
                
                # T·∫°o file Word
                if 'pdf_latex_content' in st.session_state:
                    st.markdown("---")
                    if st.button("üì• T·∫°o file Word (ƒë·ªãnh d·∫°ng chu·∫©n ${......}$)", key="create_word_pdf"):
                        with st.spinner("üîÑ ƒêang t·∫°o file Word v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n..."):
                            try:
                                extracted_figs = st.session_state.get('pdf_extracted_figures')
                                original_imgs = st.session_state.pdf_images
                                
                                word_buffer = WordExporter.create_word_document(
                                    st.session_state.pdf_latex_content, 
                                    extracted_figures=extracted_figs,
                                    images=original_imgs
                                )
                                
                                filename = f"{uploaded_pdf.name.split('.')[0]}_ultra_latex.docx"
                                
                                st.download_button(
                                    label="üì• T·∫£i file Word (Ultra Enhanced)",
                                    data=word_buffer.getvalue(),
                                    file_name=filename,
                                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                                )
                                
                                st.download_button(
                                    label="üìù T·∫£i LaTeX source (.tex)",
                                    data=st.session_state.pdf_latex_content,
                                    file_name=uploaded_pdf.name.replace('.pdf', '.tex'),
                                    mime="text/plain"
                                )
                                
                                st.success("‚úÖ File Word v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n ${......}$ ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
                            
                            except Exception as e:
                                st.error(f"‚ùå L·ªói t·∫°o file Word: {str(e)}")
    
    # Tab x·ª≠ l√Ω ·∫£nh (t∆∞∆°ng t·ª± nh∆∞ PDF tab)
    with tab2:
        st.header("üñºÔ∏è Chuy·ªÉn ƒë·ªïi ·∫¢nh sang LaTeX + T√°ch ·∫£nh si√™u ch√≠nh x√°c")
        
        uploaded_images = st.file_uploader(
            "Ch·ªçn ·∫£nh (c√≥ th·ªÉ ch·ªçn nhi·ªÅu)",
            type=['png', 'jpg', 'jpeg', 'bmp', 'tiff'],
            accept_multiple_files=True,
            help="Upload ·∫£nh ch·ª©a c√¥ng th·ª©c to√°n h·ªçc v√† h√¨nh minh h·ªça"
        )
        
        if uploaded_images:
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.subheader("üñºÔ∏è Preview ·∫¢nh")
                
                total_size = sum(img.size for img in uploaded_images)
                st.info(f"üìÅ S·ªë ·∫£nh: {len(uploaded_images)}")
                st.info(f"üìè T·ªïng k√≠ch th∆∞·ªõc: {format_file_size(total_size)}")
                
                for i, uploaded_image in enumerate(uploaded_images[:2]):
                    st.write(f"**·∫¢nh {i+1}: {uploaded_image.name}**")
                    image = Image.open(uploaded_image)
                    st.image(image, use_column_width=True)
                
                if len(uploaded_images) > 2:
                    st.info(f"... v√† {len(uploaded_images) - 2} ·∫£nh kh√°c")
            
            with col2:
                st.subheader("‚ö° Chuy·ªÉn ƒë·ªïi sang LaTeX")
                
                if st.button("üöÄ B·∫Øt ƒë·∫ßu chuy·ªÉn ƒë·ªïi si√™u n√¢ng cao", key="convert_images"):
                    all_latex_content = []
                    all_extracted_figures = []
                    all_original_images = []
                    all_debug_images = []
                    
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    for i, uploaded_image in enumerate(uploaded_images):
                        status_text.text(f"ƒêang x·ª≠ l√Ω ·∫£nh {i+1}/{len(uploaded_images)} v·ªõi AI si√™u n√¢ng cao...")
                        
                        image_bytes = uploaded_image.getvalue()
                        image_pil = Image.open(uploaded_image)
                        all_original_images.append(image_pil)
                        
                        # T√°ch ·∫£nh/b·∫£ng n·∫øu ƒë∆∞·ª£c b·∫≠t
                        extracted_figures = []
                        if enable_extraction:
                            try:
                                figures, h, w = image_extractor.extract_figures_and_tables(image_bytes)
                                extracted_figures = figures
                                all_extracted_figures.extend(figures)
                                
                                # T·∫°o ·∫£nh debug
                                if show_debug and figures:
                                    debug_img = image_extractor.create_debug_image(image_bytes, figures)
                                    all_debug_images.append((debug_img, uploaded_image.name, figures))
                                
                                high_conf = len([f for f in figures if f['confidence'] > 80])
                                st.write(f"üéØ {uploaded_image.name}: T√°ch ƒë∆∞·ª£c {len(figures)} ·∫£nh/b·∫£ng (High conf: {high_conf})")
                            except Exception as e:
                                st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t√°ch ·∫£nh {uploaded_image.name}: {str(e)}")
                        
                        prompt = """
H√£y chuy·ªÉn ƒë·ªïi T·∫§T C·∫¢ n·ªôi dung trong ·∫£nh th√†nh vƒÉn b·∫£n thu·∫ßn t√∫y v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n.

üéØ QUAN TR·ªåNG - CH·ªà XU·∫§T RA V√ÑN B·∫¢N THU·∫¶N T√öY, KH√îNG D√ôNG ```latex hay markdown:

üìù ƒê·ªäNH D·∫†NG B·∫ÆT BU·ªòC:

1. **Tr·∫Øc nghi·ªám 4 ph∆∞∆°ng √°n - ƒë·ªãnh d·∫°ng ch√≠nh x√°c:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß]
A. [ƒë√°p √°n A chi ti·∫øt]
B. [ƒë√°p √°n B chi ti·∫øt]  
C. [ƒë√°p √°n C chi ti·∫øt]
D. [ƒë√°p √°n D chi ti·∫øt]

2. **Tr·∫Øc nghi·ªám ƒë√∫ng sai - ƒë·ªãnh d·∫°ng ch√≠nh x√°c:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi n·∫øu c√≥]
a) [n·ªôi dung ƒë√°p √°n a ƒë·∫ßy ƒë·ªß]
b) [n·ªôi dung ƒë√°p √°n b ƒë·∫ßy ƒë·ªß]  
c) [n·ªôi dung ƒë√°p √°n c ƒë·∫ßy ƒë·ªß]
d) [n·ªôi dung ƒë√°p √°n d ƒë·∫ßy ƒë·ªß]

3. **Tr·∫£ l·ªùi ng·∫Øn/T·ª± lu·∫≠n:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß]

4. **C√¥ng th·ª©c to√°n h·ªçc - TUY·ªÜT ƒê·ªêI QUAN TR·ªåNG:**
- **CH·ªà s·ª≠ d·ª•ng ƒë·ªãnh d·∫°ng:** ${x^2 + y^2}$ cho M·ªåI c√¥ng th·ª©c
- **V√ç D·ª§ ƒê√öNG:** ${\\frac{a+b}{c-d}}$, ${\\int_0^1 x dx}$, ${\\sqrt{x^2+1}}$, ${\\perp}$, ${\\parallel}$
- **TUY·ªÜT ƒê·ªêI KH√îNG d√πng:** ```latex, $...$, $...$, hay b·∫•t k·ª≥ markdown n√†o

5. **K√Ω hi·ªáu ƒë·∫∑c bi·ªát:**
- Vu√¥ng g√≥c: ${\\perp}$
- Song song: ${\\parallel}$ ho·∫∑c //
- G√≥c: ${\\angle}$ ho·∫∑c d√πng t·ª´ "g√≥c"
- ƒê·ªô: ¬∞ ho·∫∑c ${^\\circ}$

‚ö†Ô∏è L∆ØU √ù QUAN TR·ªåNG:
- KH√îNG xu·∫•t ra ```latex hay b·∫•t k·ª≥ code block n√†o
- KH√îNG d√πng markdown formatting
- CH·ªà xu·∫•t ra vƒÉn b·∫£n thu·∫ßn t√∫y v·ªõi c√¥ng th·ª©c ${...}$
- Gi·ªØ CH√çNH X√ÅC 100% th·ª© t·ª± v√† c·∫•u tr√∫c n·ªôi dung
- Bao g·ªìm T·∫§T C·∫¢ text, s·ªë, k√Ω hi·ªáu v√† c√¥ng th·ª©c t·ª´ ·∫£nh
- Vi·∫øt ƒë·∫ßy ƒë·ªß n·ªôi dung, kh√¥ng r√∫t g·ªçn ho·∫∑c t√≥m t·∫Øt

V√ç D·ª§ OUTPUT ƒê√öNG:
C√¢u 64: Trong h√¨nh h·ªôp ${ABCD.A'B'C'D'}$ c√≥ t·∫•t c·∫£ c√°c c·∫°nh ƒë·ªÅu b·∫±ng nhau. X√©t t√≠nh ƒë√∫ng sai c·ªßa c√°c kh·∫≥ng ƒë·ªãnh sau:
a) ${ABCD}$ l√† h√¨nh ch·ªØ nh·∫≠t.
b) ${A'C' \\perp BD}$
c) ${A'B \\perp D'C}$  
d) ${BC' \\perp A'D}$
"""
                        
                        try:
                            latex_result = gemini_api.convert_to_latex(
                                image_bytes, uploaded_image.type, prompt
                            )
                            if latex_result:
                                # Ch√®n ·∫£nh v√†o vƒÉn b·∫£n n·∫øu c√≥ t√°ch ·∫£nh
                                if enable_extraction and extracted_figures:
                                    latex_result = image_extractor.insert_figures_into_text(
                                        latex_result, extracted_figures, h, w
                                    )
                                
                                all_latex_content.append(
                                    f"<!-- ·∫¢nh {i+1}: {uploaded_image.name} -->\n{latex_result}\n"
                                )
                            else:
                                st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ x·ª≠ l√Ω ·∫£nh {uploaded_image.name}")
                        except Exception as e:
                            st.error(f"‚ùå L·ªói x·ª≠ l√Ω {uploaded_image.name}: {str(e)}")
                        
                        progress_bar.progress((i + 1) / len(uploaded_images))
                    
                    status_text.text("‚úÖ Ho√†n th√†nh chuy·ªÉn ƒë·ªïi si√™u n√¢ng cao!")
                    
                    # Hi·ªÉn th·ªã k·∫øt qu·∫£
                    combined_latex = "\n".join(all_latex_content)
                    
                    st.markdown('<div class="latex-output">', unsafe_allow_html=True)
                    st.text_area("üìù K·∫øt qu·∫£ LaTeX (ƒë·ªãnh d·∫°ng chu·∫©n ${......}$):", combined_latex, height=300)
                    st.markdown('</div>', unsafe_allow_html=True)
                    
                    # Hi·ªÉn th·ªã th·ªëng k√™ v√† ·∫£nh debug (t∆∞∆°ng t·ª± PDF tab)
                    if enable_extraction:
                        total_figs = len(all_extracted_figures)
                        high_conf = len([f for f in all_extracted_figures if f['confidence'] > 80])
                        medium_conf = len([f for f in all_extracted_figures if 60 <= f['confidence'] <= 80])
                        low_conf = len([f for f in all_extracted_figures if f['confidence'] < 60])
                        
                        st.markdown(f"""
                        **üìä Th·ªëng k√™ chi ti·∫øt:**
                        - üéØ T·ªïng c·ªông: **{total_figs}** ·∫£nh/b·∫£ng ƒë√£ t√°ch
                        - <span class="confidence-high">üü¢ High confidence (>80%): {high_conf}</span>
                        - <span class="confidence-medium">üü° Medium confidence (60-80%): {medium_conf}</span>  
                        - <span class="confidence-low">üî¥ Low confidence (<60%): {low_conf}</span>
                        """, unsafe_allow_html=True)
                        
                        if show_debug and all_debug_images:
                            st.subheader("üîç Debug Si√™u N√¢ng Cao - Ph√¢n T√≠ch AI")
                            
                            for debug_img, img_name, figures in all_debug_images:
                                st.write(f"**üîç {img_name} - AI Detection Analysis:**")
                                st.image(debug_img, caption=f"AI ph√°t hi·ªán {len(figures)} v√πng", use_column_width=True)
                                
                                if figures:
                                    st.write("**üìã Chi ti·∫øt t·ª´ng v√πng ƒë√£ c·∫Øt:**")
                                    cols = st.columns(min(len(figures), 3))
                                    for idx, fig in enumerate(figures):
                                        with cols[idx % 3]:
                                            img_data = base64.b64decode(fig['base64'])
                                            img_pil = Image.open(io.BytesIO(img_data))
                                            
                                            st.markdown(f'<div class="extracted-image">', unsafe_allow_html=True)
                                            st.image(img_pil, caption=f"{fig['name']} - {fig['confidence']:.1f}%", use_column_width=True)
                                            
                                            conf_class = "confidence-high" if fig['confidence'] > 80 else "confidence-medium" if fig['confidence'] >= 60 else "confidence-low"
                                            
                                            st.markdown(f'''
                                            <div class="image-info">
                                            <strong>{fig['name']}</strong><br>
                                            üè∑Ô∏è Lo·∫°i: {"üìä B·∫£ng" if fig['is_table'] else "üñºÔ∏è H√¨nh ·∫£nh"}<br>
                                            <span class="{conf_class}">üéØ Confidence: {fig['confidence']:.1f}%</span><br>
                                            üìê T·ª∑ l·ªá: {fig['aspect_ratio']:.2f}<br>
                                            üìè K√≠ch th∆∞·ªõc: {fig['bbox'][2]}√ó{fig['bbox'][3]}px<br>
                                            üî∫ Solidity: {fig['solidity']:.2f}<br>
                                            üìä Di·ªán t√≠ch: {fig['area']:,}px¬≤
                                            </div>
                                            ''', unsafe_allow_html=True)
                                            st.markdown('</div>', unsafe_allow_html=True)
                    
                    # L∆∞u v√†o session
                    st.session_state.image_latex_content = combined_latex
                    st.session_state.image_list = all_original_images
                    st.session_state.image_extracted_figures = all_extracted_figures if enable_extraction else None
                
                # T·∫°o file Word
                if 'image_latex_content' in st.session_state:
                    st.markdown("---")
                    if st.button("üì• T·∫°o file Word (ƒë·ªãnh d·∫°ng chu·∫©n ${......}$)", key="create_word_images"):
                        with st.spinner("üîÑ ƒêang t·∫°o file Word v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n..."):
                            try:
                                extracted_figs = st.session_state.get('image_extracted_figures')
                                original_imgs = st.session_state.image_list
                                
                                word_buffer = WordExporter.create_word_document(
                                    st.session_state.image_latex_content,
                                    extracted_figures=extracted_figs,
                                    images=original_imgs
                                )
                                
                                st.download_button(
                                    label="üì• T·∫£i file Word (Ultra Enhanced)",
                                    data=word_buffer.getvalue(),
                                    file_name="images_ultra_latex.docx",
                                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                                )
                                
                                st.download_button(
                                    label="üìù T·∫£i LaTeX source (.tex)",
                                    data=st.session_state.image_latex_content,
                                    file_name="images_converted.tex",
                                    mime="text/plain"
                                )
                                
                                st.success("‚úÖ File Word v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n ${......}$ ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
                            
                            except Exception as e:
                                st.error(f"‚ùå L·ªói t·∫°o file Word: {str(e)}")
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666;'>
        <p>ƒê∆∞·ª£c ph√°t tri·ªÉn v·ªõi ‚ù§Ô∏è s·ª≠ d·ª•ng Streamlit v√† Gemini 2.0 API</p>
        <p>‚ú® <strong>Ultra Enhanced Version:</strong> AI si√™u th√¥ng minh + ƒê·ªãnh d·∫°ng LaTeX chu·∫©n ${......}$!</p>
        <p>üéØ Thu·∫≠t to√°n NMS + Multi-scale Detection + Content Analysis + Confidence Scoring</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main() in line:
                    start_idx = line.find('${')
                    if start_idx != -1:
                        end_idx = line.find('}
        
        # Th√™m ·∫£nh g·ªëc n·∫øu c√≥ (fallback)
        if images and not extracted_figures:
            doc.add_page_break()
            doc.add_heading('H√¨nh ·∫£nh g·ªëc', level=1)
            
            for i, img in enumerate(images):
                try:
                    doc.add_heading(f'H√¨nh {i+1}', level=2)
                    
                    if img.mode in ('RGBA', 'LA', 'P'):
                        img = img.convert('RGB')
                    
                    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
                        img.save(tmp.name, 'PNG')
                        try:
                            doc.add_picture(tmp.name, width=doc.sections[0].page_width * 0.8)
                        except Exception:
                            doc.add_paragraph(f"[H√¨nh ·∫£nh {i+1} - Kh√¥ng th·ªÉ hi·ªÉn th·ªã]")
                        os.unlink(tmp.name)
                except Exception:
                    doc.add_paragraph(f"[L·ªói hi·ªÉn th·ªã h√¨nh {i+1}]")
        
        buffer = io.BytesIO()
        doc.save(buffer)
        buffer.seek(0)
        return buffer
    
    @staticmethod
    def _insert_extracted_image(doc, img_name, extracted_figures, caption_prefix):
        """Ch√®n ·∫£nh ƒë√£ t√°ch v√†o Word document"""
        if not extracted_figures:
            doc.add_paragraph(f"[{caption_prefix}: {img_name} - Kh√¥ng t√¨m th·∫•y]")
            return
        
        target_figure = None
        for fig in extracted_figures:
            if fig['name'] == img_name:
                target_figure = fig
                break
        
        if not target_figure:
            doc.add_paragraph(f"[{caption_prefix}: {img_name} - Kh√¥ng t√¨m th·∫•y]")
            return
        
        try:
            doc.add_heading(f"{caption_prefix}: {img_name}", level=3)
            
            img_data = base64.b64decode(target_figure['base64'])
            img_pil = Image.open(io.BytesIO(img_data))
            
            if img_pil.mode in ('RGBA', 'LA', 'P'):
                img_pil = img_pil.convert('RGB')
            
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
                img_pil.save(tmp.name, 'PNG')
                try:
                    max_width = doc.sections[0].page_width * 0.8
                    doc.add_picture(tmp.name, width=max_width)
                except Exception:
                    doc.add_paragraph(f"[Kh√¥ng th·ªÉ hi·ªÉn th·ªã {img_name}]")
                os.unlink(tmp.name)
        
        except Exception as e:
            doc.add_paragraph(f"[L·ªói hi·ªÉn th·ªã {img_name}: {str(e)}]")

def validate_api_key(api_key: str) -> bool:
    """Ki·ªÉm tra t√≠nh h·ª£p l·ªá c·ªßa API key"""
    if not api_key or len(api_key) < 20:
        return False
    return re.match(r'^[A-Za-z0-9_-]+$', api_key) is not None

def format_file_size(size_bytes: int) -> str:
    """Chuy·ªÉn ƒë·ªïi k√≠ch th∆∞·ªõc file sang ƒë·ªãnh d·∫°ng human-readable"""
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"

def main():
    st.markdown('<h1 class="main-header">üìù PDF/Image to LaTeX Converter - Ultra Enhanced</h1>', unsafe_allow_html=True)
    
    # Sidebar cho API key
    with st.sidebar:
        st.header("‚öôÔ∏è C√†i ƒë·∫∑t")
        api_key = st.text_input(
            "Gemini API Key", 
            type="password", 
            help="Nh·∫≠p API key t·ª´ Google AI Studio",
            placeholder="Paste your API key here..."
        )
        
        if api_key:
            if validate_api_key(api_key):
                st.success("‚úÖ API key h·ª£p l·ªá")
            else:
                st.error("‚ùå API key kh√¥ng h·ª£p l·ªá")
        
        st.markdown("---")
        
        # C√†i ƒë·∫∑t t√°ch ·∫£nh si√™u n√¢ng cao
        st.subheader("üñºÔ∏è T√°ch ·∫£nh si√™u ch√≠nh x√°c")
        enable_extraction = st.checkbox("B·∫≠t t√°ch ·∫£nh/b·∫£ng si√™u n√¢ng cao", value=True, 
                                       help="Thu·∫≠t to√°n AI t√°ch ·∫£nh v·ªõi ƒë·ªô ch√≠nh x√°c c·ª±c cao")
        
        if enable_extraction:
            st.write("**C√†i ƒë·∫∑t si√™u n√¢ng cao:**")
            min_area = st.slider("Di·ªán t√≠ch t·ªëi thi·ªÉu (%)", 0.1, 5.0, 0.3, 0.1,
                               help="% di·ªán t√≠ch ·∫£nh g·ªëc") / 100
            max_figures = st.slider("S·ªë ·∫£nh t·ªëi ƒëa", 1, 25, 12, 1)
            min_size = st.slider("K√≠ch th∆∞·ªõc t·ªëi thi·ªÉu (px)", 30, 300, 40, 10)
            padding = st.slider("Padding xung quanh (px)", 0, 30, 8, 1)
            confidence_threshold = st.slider("Ng∆∞·ª°ng confidence (%)", 30, 90, 50, 5)
            
            show_debug = st.checkbox("Hi·ªÉn th·ªã ·∫£nh debug n√¢ng cao", value=True,
                                   help="Hi·ªÉn th·ªã ·∫£nh v·ªõi confidence score v√† ph√¢n t√≠ch chi ti·∫øt")
        
        st.markdown("---")
        st.markdown("""
        ### üìã H∆∞·ªõng d·∫´n:
        1. Nh·∫≠p API key Gemini
        2. Ch·ªçn tab PDF ho·∫∑c ·∫¢nh  
        3. Upload file
        4. Ch·ªù x·ª≠ l√Ω v√† t·∫£i file Word
        
        ### üéØ T√≠nh nƒÉng si√™u n√¢ng cao:
        - ‚úÖ Thu·∫≠t to√°n AI c·∫Øt ·∫£nh v·ªõi NMS
        - ‚úÖ Confidence scoring th√¥ng minh
        - ‚úÖ ƒê·ªãnh d·∫°ng LaTeX chu·∫©n: `${......}$`
        - ‚úÖ Ph√¢n t√≠ch n·ªôi dung v√πng
        - ‚úÖ Multi-scale edge detection
        
        ### üìù ƒê·ªãnh d·∫°ng LaTeX chu·∫©n:
        **C√¥ng th·ª©c inline:** `${x^2 + y^2}$`
        
        **Tr·∫Øc nghi·ªám 4 ph∆∞∆°ng √°n:**
        ```
        C√¢u X: [n·ªôi dung]
        A. [ƒê√°p √°n]
        B. [ƒê√°p √°n]  
        C. [ƒê√°p √°n]
        D. [ƒê√°p √°n]
        ```
        
        **Tr·∫Øc nghi·ªám ƒë√∫ng sai:**
        ```
        a) [ƒê√°p √°n]
        b) [ƒê√°p √°n]
        c) [ƒê√°p √°n]
        d) [ƒê√°p √°n]
        ```
        
        ### üîë L·∫•y API Key:
        [Google AI Studio](https://makersuite.google.com/app/apikey)
        """)
    
    if not api_key:
        st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p Gemini API Key ·ªü sidebar ƒë·ªÉ b·∫Øt ƒë·∫ßu!")
        st.info("üí° B·∫°n c√≥ th·ªÉ l·∫•y API key mi·ªÖn ph√≠ t·∫°i Google AI Studio")
        return
    
    if not validate_api_key(api_key):
        st.error("‚ùå API key kh√¥ng h·ª£p l·ªá. Vui l√≤ng ki·ªÉm tra l·∫°i!")
        return
    
    # T·∫°o tabs
    tab1, tab2 = st.tabs(["üìÑ PDF to LaTeX + Ultra Extract", "üñºÔ∏è Image to LaTeX + Ultra Extract"])
    
    # Kh·ªüi t·∫°o API v√† ImageExtractor
    try:
        gemini_api = GeminiAPI(api_key)
        if enable_extraction:
            image_extractor = UltraImageExtractor()
            image_extractor.min_area_ratio = min_area
            image_extractor.max_figures = max_figures
            image_extractor.min_width = min_size
            image_extractor.min_height = min_size
            image_extractor.padding = padding
            image_extractor.confidence_threshold = confidence_threshold
    except Exception as e:
        st.error(f"‚ùå L·ªói kh·ªüi t·∫°o: {str(e)}")
        return
    
    # Tab x·ª≠ l√Ω PDF
    with tab1:
        st.header("üìÑ Chuy·ªÉn ƒë·ªïi PDF sang LaTeX + T√°ch ·∫£nh si√™u ch√≠nh x√°c")
        
        uploaded_pdf = st.file_uploader(
            "Ch·ªçn file PDF",
            type=['pdf'],
            help="Upload file PDF ch·ª©a c√¥ng th·ª©c to√°n h·ªçc v√† h√¨nh ·∫£nh"
        )
        
        if uploaded_pdf:
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.subheader("üìã Preview PDF")
                st.info(f"üìÅ File: {uploaded_pdf.name}")
                st.info(f"üìè K√≠ch th∆∞·ªõc: {format_file_size(uploaded_pdf.size)}")
                
                with st.spinner("üîÑ ƒêang x·ª≠ l√Ω PDF v·ªõi ƒë·ªô ph√¢n gi·∫£i cao..."):
                    try:
                        pdf_images = PDFProcessor.extract_images_and_text(uploaded_pdf)
                        st.success(f"‚úÖ ƒê√£ tr√≠ch xu·∫•t {len(pdf_images)} trang (3x resolution)")
                        
                        # Hi·ªÉn th·ªã preview
                        for img, page_num in pdf_images[:2]:
                            st.write(f"**Trang {page_num}:**")
                            st.image(img, use_column_width=True)
                        
                        if len(pdf_images) > 2:
                            st.info(f"... v√† {len(pdf_images) - 2} trang kh√°c")
                    
                    except Exception as e:
                        st.error(f"‚ùå L·ªói x·ª≠ l√Ω PDF: {str(e)}")
                        pdf_images = []
            
            with col2:
                st.subheader("‚ö° Chuy·ªÉn ƒë·ªïi sang LaTeX")
                
                if st.button("üöÄ B·∫Øt ƒë·∫ßu chuy·ªÉn ƒë·ªïi si√™u n√¢ng cao", key="convert_pdf"):
                    if pdf_images:
                        all_latex_content = []
                        all_extracted_figures = []
                        all_debug_images = []
                        
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        for i, (img, page_num) in enumerate(pdf_images):
                            status_text.text(f"ƒêang x·ª≠ l√Ω trang {page_num}/{len(pdf_images)} v·ªõi AI si√™u n√¢ng cao...")
                            
                            # Chuy·ªÉn ·∫£nh th√†nh bytes
                            img_buffer = io.BytesIO()
                            img.save(img_buffer, format='PNG')
                            img_bytes = img_buffer.getvalue()
                            
                            # T√°ch ·∫£nh/b·∫£ng n·∫øu ƒë∆∞·ª£c b·∫≠t
                            extracted_figures = []
                            if enable_extraction:
                                try:
                                    figures, h, w = image_extractor.extract_figures_and_tables(img_bytes)
                                    extracted_figures = figures
                                    all_extracted_figures.extend(figures)
                                    
                                    # T·∫°o ·∫£nh debug
                                    if show_debug and figures:
                                        debug_img = image_extractor.create_debug_image(img_bytes, figures)
                                        all_debug_images.append((debug_img, page_num, figures))
                                    
                                    high_conf = len([f for f in figures if f['confidence'] > 80])
                                    st.write(f"üéØ Trang {page_num}: T√°ch ƒë∆∞·ª£c {len(figures)} ·∫£nh/b·∫£ng (High conf: {high_conf})")
                                    
                                except Exception as e:
                                    st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t√°ch ·∫£nh trang {page_num}: {str(e)}")
                            
                            # T·∫°o prompt si√™u c·∫£i ti·∫øn cho Gemini
                            prompt = f"""
H√£y chuy·ªÉn ƒë·ªïi T·∫§T C·∫¢ n·ªôi dung trong ·∫£nh trang {page_num} th√†nh vƒÉn b·∫£n thu·∫ßn t√∫y v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n.

üéØ QUAN TR·ªåNG - CH·ªà XU·∫§T RA V√ÑN B·∫¢N THU·∫¶N T√öY, KH√îNG D√ôNG ```latex hay markdown:

üìù ƒê·ªäNH D·∫†NG B·∫ÆT BU·ªòC:

1. **Tr·∫Øc nghi·ªám 4 ph∆∞∆°ng √°n - ƒë·ªãnh d·∫°ng ch√≠nh x√°c:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß]
A. [ƒë√°p √°n A chi ti·∫øt]
B. [ƒë√°p √°n B chi ti·∫øt]  
C. [ƒë√°p √°n C chi ti·∫øt]
D. [ƒë√°p √°n D chi ti·∫øt]

2. **Tr·∫Øc nghi·ªám ƒë√∫ng sai - ƒë·ªãnh d·∫°ng ch√≠nh x√°c:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi n·∫øu c√≥]
a) [n·ªôi dung ƒë√°p √°n a ƒë·∫ßy ƒë·ªß]
b) [n·ªôi dung ƒë√°p √°n b ƒë·∫ßy ƒë·ªß]  
c) [n·ªôi dung ƒë√°p √°n c ƒë·∫ßy ƒë·ªß]
d) [n·ªôi dung ƒë√°p √°n d ƒë·∫ßy ƒë·ªß]

3. **Tr·∫£ l·ªùi ng·∫Øn/T·ª± lu·∫≠n:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß]

4. **C√¥ng th·ª©c to√°n h·ªçc - TUY·ªÜT ƒê·ªêI QUAN TR·ªåNG:**
- **CH·ªà s·ª≠ d·ª•ng ƒë·ªãnh d·∫°ng:** ${{x^2 + y^2}}$ cho M·ªåI c√¥ng th·ª©c
- **V√ç D·ª§ ƒê√öNG:** ${{\\frac{{a+b}}{{c-d}}}}$, ${{\\int_0^1 x dx}}$, ${{\\sqrt{{x^2+1}}}}$, ${{\\perp}}$, ${{\\parallel}}$
- **TUY·ªÜT ƒê·ªêI KH√îNG d√πng:** ```latex, $...$, $...$, hay b·∫•t k·ª≥ markdown n√†o

5. **K√Ω hi·ªáu ƒë·∫∑c bi·ªát:**
- Vu√¥ng g√≥c: ${{\\perp}}$
- Song song: ${{\\parallel}}$ ho·∫∑c //
- G√≥c: ${{\\angle}}$ ho·∫∑c d√πng t·ª´ "g√≥c"
- ƒê·ªô: ¬∞ ho·∫∑c ${{^\\circ}}$

6. **H√¨nh ·∫£nh v√† b·∫£ng:**
{'- Khi th·∫•y h√¨nh ·∫£nh/ƒë·ªì th·ªã: d√πng "xem h√¨nh", "theo h√¨nh", "h√¨nh sau"' if enable_extraction else ''}
{'- Khi th·∫•y b·∫£ng: d√πng "b·∫£ng sau", "theo b·∫£ng", "quan s√°t b·∫£ng"' if enable_extraction else ''}

‚ö†Ô∏è L∆ØU √ù QUAN TR·ªåNG:
- KH√îNG xu·∫•t ra ```latex hay b·∫•t k·ª≥ code block n√†o
- KH√îNG d√πng markdown formatting
- CH·ªà xu·∫•t ra vƒÉn b·∫£n thu·∫ßn t√∫y v·ªõi c√¥ng th·ª©c ${{...}}$
- Gi·ªØ CH√çNH X√ÅC 100% th·ª© t·ª± v√† c·∫•u tr√∫c n·ªôi dung
- Bao g·ªìm T·∫§T C·∫¢ text, s·ªë, k√Ω hi·ªáu v√† c√¥ng th·ª©c t·ª´ ·∫£nh
- Vi·∫øt ƒë·∫ßy ƒë·ªß n·ªôi dung, kh√¥ng r√∫t g·ªçn ho·∫∑c t√≥m t·∫Øt

V√ç D·ª§ OUTPUT ƒê√öNG:
C√¢u 64: Trong h√¨nh h·ªôp ${{ABCD.A'B'C'D'}}$ c√≥ t·∫•t c·∫£ c√°c c·∫°nh ƒë·ªÅu b·∫±ng nhau. X√©t t√≠nh ƒë√∫ng sai c·ªßa c√°c kh·∫≥ng ƒë·ªãnh sau:
a) ${{ABCD}}$ l√† h√¨nh ch·ªØ nh·∫≠t.
b) ${{A'C' \\perp BD}}$
c) ${{A'B \\perp D'C}}$  
d) ${{BC' \\perp A'D}}$
"""
                            
                            # G·ªçi API
                            try:
                                latex_result = gemini_api.convert_to_latex(img_bytes, "image/png", prompt)
                                if latex_result:
                                    # Ch√®n ·∫£nh v√†o vƒÉn b·∫£n n·∫øu c√≥ t√°ch ·∫£nh
                                    if enable_extraction and extracted_figures:
                                        latex_result = image_extractor.insert_figures_into_text(
                                            latex_result, extracted_figures, h, w
                                        )
                                    
                                    all_latex_content.append(f"<!-- Trang {page_num} -->\n{latex_result}\n")
                                else:
                                    st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ x·ª≠ l√Ω trang {page_num}")
                            except Exception as e:
                                st.error(f"‚ùå L·ªói x·ª≠ l√Ω trang {page_num}: {str(e)}")
                            
                            progress_bar.progress((i + 1) / len(pdf_images))
                        
                        status_text.text("‚úÖ Ho√†n th√†nh chuy·ªÉn ƒë·ªïi si√™u n√¢ng cao!")
                        
                        # Hi·ªÉn th·ªã k·∫øt qu·∫£
                        combined_latex = "\n".join(all_latex_content)
                        
                        st.markdown('<div class="latex-output">', unsafe_allow_html=True)
                        st.text_area("üìù K·∫øt qu·∫£ LaTeX (ƒë·ªãnh d·∫°ng chu·∫©n ${......}$):", combined_latex, height=300)
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                        # Hi·ªÉn th·ªã th·ªëng k√™ chi ti·∫øt
                        if enable_extraction:
                            total_figs = len(all_extracted_figures)
                            high_conf = len([f for f in all_extracted_figures if f['confidence'] > 80])
                            medium_conf = len([f for f in all_extracted_figures if 60 <= f['confidence'] <= 80])
                            low_conf = len([f for f in all_extracted_figures if f['confidence'] < 60])
                            
                            st.markdown(f"""
                            **üìä Th·ªëng k√™ chi ti·∫øt:**
                            - üéØ T·ªïng c·ªông: **{total_figs}** ·∫£nh/b·∫£ng ƒë√£ t√°ch
                            - <span class="confidence-high">üü¢ High confidence (>80%): {high_conf}</span>
                            - <span class="confidence-medium">üü° Medium confidence (60-80%): {medium_conf}</span>  
                            - <span class="confidence-low">üî¥ Low confidence (<60%): {low_conf}</span>
                            """, unsafe_allow_html=True)
                            
                            # Hi·ªÉn th·ªã ·∫£nh debug v√† ·∫£nh ƒë√£ c·∫Øt
                            if show_debug and all_debug_images:
                                st.subheader("üîç Debug Si√™u N√¢ng Cao - Ph√¢n T√≠ch AI")
                                
                                for debug_img, page_num, figures in all_debug_images:
                                    st.write(f"**üîç Trang {page_num} - AI Detection Analysis:**")
                                    st.image(debug_img, caption=f"AI ph√°t hi·ªán {len(figures)} v√πng v·ªõi confidence scores", use_column_width=True)
                                    
                                    # Hi·ªÉn th·ªã t·ª´ng ·∫£nh ƒë√£ c·∫Øt v·ªõi th√¥ng tin si√™u chi ti·∫øt
                                    if figures:
                                        st.write("**üìã Chi ti·∫øt t·ª´ng v√πng ƒë√£ c·∫Øt:**")
                                        cols = st.columns(min(len(figures), 3))
                                        for idx, fig in enumerate(figures):
                                            with cols[idx % 3]:
                                                # Decode v√† hi·ªÉn th·ªã ·∫£nh c·∫Øt
                                                img_data = base64.b64decode(fig['base64'])
                                                img_pil = Image.open(io.BytesIO(img_data))
                                                
                                                st.markdown(f'<div class="extracted-image">', unsafe_allow_html=True)
                                                st.image(img_pil, caption=f"{fig['name']} - {fig['confidence']:.1f}%", use_column_width=True)
                                                
                                                # X√°c ƒë·ªãnh m√†u confidence
                                                conf_class = "confidence-high" if fig['confidence'] > 80 else "confidence-medium" if fig['confidence'] >= 60 else "confidence-low"
                                                
                                                # Th√¥ng tin si√™u chi ti·∫øt
                                                st.markdown(f'''
                                                <div class="image-info">
                                                <strong>{fig['name']}</strong><br>
                                                üè∑Ô∏è Lo·∫°i: {"üìä B·∫£ng" if fig['is_table'] else "üñºÔ∏è H√¨nh ·∫£nh"}<br>
                                                <span class="{conf_class}">üéØ Confidence: {fig['confidence']:.1f}%</span><br>
                                                üìê T·ª∑ l·ªá: {fig['aspect_ratio']:.2f}<br>
                                                üìè K√≠ch th∆∞·ªõc: {fig['bbox'][2]}√ó{fig['bbox'][3]}px<br>
                                                üî∫ Solidity: {fig['solidity']:.2f}<br>
                                                üìä Di·ªán t√≠ch: {fig['area']:,}px¬≤<br>
                                                {'üîç Ph√¢n t√≠ch: ' + str(fig.get('content_analysis', {}).get('has_lines', 0)) + ' ƒë∆∞·ªùng k·∫ª' if 'content_analysis' in fig else ''}
                                                </div>
                                                ''', unsafe_allow_html=True)
                                                st.markdown('</div>', unsafe_allow_html=True)
                        
                        # L∆∞u v√†o session state
                        st.session_state.pdf_latex_content = combined_latex
                        st.session_state.pdf_images = [img for img, _ in pdf_images]
                        st.session_state.pdf_extracted_figures = all_extracted_figures if enable_extraction else None
                
                # T·∫°o file Word
                if 'pdf_latex_content' in st.session_state:
                    st.markdown("---")
                    if st.button("üì• T·∫°o file Word (ƒë·ªãnh d·∫°ng chu·∫©n ${......}$)", key="create_word_pdf"):
                        with st.spinner("üîÑ ƒêang t·∫°o file Word v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n..."):
                            try:
                                extracted_figs = st.session_state.get('pdf_extracted_figures')
                                original_imgs = st.session_state.pdf_images
                                
                                word_buffer = WordExporter.create_word_document(
                                    st.session_state.pdf_latex_content, 
                                    extracted_figures=extracted_figs,
                                    images=original_imgs
                                )
                                
                                filename = f"{uploaded_pdf.name.split('.')[0]}_ultra_latex.docx"
                                
                                st.download_button(
                                    label="üì• T·∫£i file Word (Ultra Enhanced)",
                                    data=word_buffer.getvalue(),
                                    file_name=filename,
                                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                                )
                                
                                st.download_button(
                                    label="üìù T·∫£i LaTeX source (.tex)",
                                    data=st.session_state.pdf_latex_content,
                                    file_name=uploaded_pdf.name.replace('.pdf', '.tex'),
                                    mime="text/plain"
                                )
                                
                                st.success("‚úÖ File Word v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n ${......}$ ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
                            
                            except Exception as e:
                                st.error(f"‚ùå L·ªói t·∫°o file Word: {str(e)}")
    
    # Tab x·ª≠ l√Ω ·∫£nh (t∆∞∆°ng t·ª± nh∆∞ PDF tab)
    with tab2:
        st.header("üñºÔ∏è Chuy·ªÉn ƒë·ªïi ·∫¢nh sang LaTeX + T√°ch ·∫£nh si√™u ch√≠nh x√°c")
        
        uploaded_images = st.file_uploader(
            "Ch·ªçn ·∫£nh (c√≥ th·ªÉ ch·ªçn nhi·ªÅu)",
            type=['png', 'jpg', 'jpeg', 'bmp', 'tiff'],
            accept_multiple_files=True,
            help="Upload ·∫£nh ch·ª©a c√¥ng th·ª©c to√°n h·ªçc v√† h√¨nh minh h·ªça"
        )
        
        if uploaded_images:
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.subheader("üñºÔ∏è Preview ·∫¢nh")
                
                total_size = sum(img.size for img in uploaded_images)
                st.info(f"üìÅ S·ªë ·∫£nh: {len(uploaded_images)}")
                st.info(f"üìè T·ªïng k√≠ch th∆∞·ªõc: {format_file_size(total_size)}")
                
                for i, uploaded_image in enumerate(uploaded_images[:2]):
                    st.write(f"**·∫¢nh {i+1}: {uploaded_image.name}**")
                    image = Image.open(uploaded_image)
                    st.image(image, use_column_width=True)
                
                if len(uploaded_images) > 2:
                    st.info(f"... v√† {len(uploaded_images) - 2} ·∫£nh kh√°c")
            
            with col2:
                st.subheader("‚ö° Chuy·ªÉn ƒë·ªïi sang LaTeX")
                
                if st.button("üöÄ B·∫Øt ƒë·∫ßu chuy·ªÉn ƒë·ªïi si√™u n√¢ng cao", key="convert_images"):
                    all_latex_content = []
                    all_extracted_figures = []
                    all_original_images = []
                    all_debug_images = []
                    
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    for i, uploaded_image in enumerate(uploaded_images):
                        status_text.text(f"ƒêang x·ª≠ l√Ω ·∫£nh {i+1}/{len(uploaded_images)} v·ªõi AI si√™u n√¢ng cao...")
                        
                        image_bytes = uploaded_image.getvalue()
                        image_pil = Image.open(uploaded_image)
                        all_original_images.append(image_pil)
                        
                        # T√°ch ·∫£nh/b·∫£ng n·∫øu ƒë∆∞·ª£c b·∫≠t
                        extracted_figures = []
                        if enable_extraction:
                            try:
                                figures, h, w = image_extractor.extract_figures_and_tables(image_bytes)
                                extracted_figures = figures
                                all_extracted_figures.extend(figures)
                                
                                # T·∫°o ·∫£nh debug
                                if show_debug and figures:
                                    debug_img = image_extractor.create_debug_image(image_bytes, figures)
                                    all_debug_images.append((debug_img, uploaded_image.name, figures))
                                
                                high_conf = len([f for f in figures if f['confidence'] > 80])
                                st.write(f"üéØ {uploaded_image.name}: T√°ch ƒë∆∞·ª£c {len(figures)} ·∫£nh/b·∫£ng (High conf: {high_conf})")
                            except Exception as e:
                                st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t√°ch ·∫£nh {uploaded_image.name}: {str(e)}")
                        
                        prompt = """
H√£y chuy·ªÉn ƒë·ªïi T·∫§T C·∫¢ n·ªôi dung trong ·∫£nh th√†nh vƒÉn b·∫£n thu·∫ßn t√∫y v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n.

üéØ QUAN TR·ªåNG - CH·ªà XU·∫§T RA V√ÑN B·∫¢N THU·∫¶N T√öY, KH√îNG D√ôNG ```latex hay markdown:

üìù ƒê·ªäNH D·∫†NG B·∫ÆT BU·ªòC:

1. **Tr·∫Øc nghi·ªám 4 ph∆∞∆°ng √°n - ƒë·ªãnh d·∫°ng ch√≠nh x√°c:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß]
A. [ƒë√°p √°n A chi ti·∫øt]
B. [ƒë√°p √°n B chi ti·∫øt]  
C. [ƒë√°p √°n C chi ti·∫øt]
D. [ƒë√°p √°n D chi ti·∫øt]

2. **Tr·∫Øc nghi·ªám ƒë√∫ng sai - ƒë·ªãnh d·∫°ng ch√≠nh x√°c:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi n·∫øu c√≥]
a) [n·ªôi dung ƒë√°p √°n a ƒë·∫ßy ƒë·ªß]
b) [n·ªôi dung ƒë√°p √°n b ƒë·∫ßy ƒë·ªß]  
c) [n·ªôi dung ƒë√°p √°n c ƒë·∫ßy ƒë·ªß]
d) [n·ªôi dung ƒë√°p √°n d ƒë·∫ßy ƒë·ªß]

3. **Tr·∫£ l·ªùi ng·∫Øn/T·ª± lu·∫≠n:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß]

4. **C√¥ng th·ª©c to√°n h·ªçc - TUY·ªÜT ƒê·ªêI QUAN TR·ªåNG:**
- **CH·ªà s·ª≠ d·ª•ng ƒë·ªãnh d·∫°ng:** ${x^2 + y^2}$ cho M·ªåI c√¥ng th·ª©c
- **V√ç D·ª§ ƒê√öNG:** ${\\frac{a+b}{c-d}}$, ${\\int_0^1 x dx}$, ${\\sqrt{x^2+1}}$, ${\\perp}$, ${\\parallel}$
- **TUY·ªÜT ƒê·ªêI KH√îNG d√πng:** ```latex, $...$, $...$, hay b·∫•t k·ª≥ markdown n√†o

5. **K√Ω hi·ªáu ƒë·∫∑c bi·ªát:**
- Vu√¥ng g√≥c: ${\\perp}$
- Song song: ${\\parallel}$ ho·∫∑c //
- G√≥c: ${\\angle}$ ho·∫∑c d√πng t·ª´ "g√≥c"
- ƒê·ªô: ¬∞ ho·∫∑c ${^\\circ}$

‚ö†Ô∏è L∆ØU √ù QUAN TR·ªåNG:
- KH√îNG xu·∫•t ra ```latex hay b·∫•t k·ª≥ code block n√†o
- KH√îNG d√πng markdown formatting
- CH·ªà xu·∫•t ra vƒÉn b·∫£n thu·∫ßn t√∫y v·ªõi c√¥ng th·ª©c ${...}$
- Gi·ªØ CH√çNH X√ÅC 100% th·ª© t·ª± v√† c·∫•u tr√∫c n·ªôi dung
- Bao g·ªìm T·∫§T C·∫¢ text, s·ªë, k√Ω hi·ªáu v√† c√¥ng th·ª©c t·ª´ ·∫£nh
- Vi·∫øt ƒë·∫ßy ƒë·ªß n·ªôi dung, kh√¥ng r√∫t g·ªçn ho·∫∑c t√≥m t·∫Øt

V√ç D·ª§ OUTPUT ƒê√öNG:
C√¢u 64: Trong h√¨nh h·ªôp ${ABCD.A'B'C'D'}$ c√≥ t·∫•t c·∫£ c√°c c·∫°nh ƒë·ªÅu b·∫±ng nhau. X√©t t√≠nh ƒë√∫ng sai c·ªßa c√°c kh·∫≥ng ƒë·ªãnh sau:
a) ${ABCD}$ l√† h√¨nh ch·ªØ nh·∫≠t.
b) ${A'C' \\perp BD}$
c) ${A'B \\perp D'C}$  
d) ${BC' \\perp A'D}$
"""
                        
                        try:
                            latex_result = gemini_api.convert_to_latex(
                                image_bytes, uploaded_image.type, prompt
                            )
                            if latex_result:
                                # Ch√®n ·∫£nh v√†o vƒÉn b·∫£n n·∫øu c√≥ t√°ch ·∫£nh
                                if enable_extraction and extracted_figures:
                                    latex_result = image_extractor.insert_figures_into_text(
                                        latex_result, extracted_figures, h, w
                                    )
                                
                                all_latex_content.append(
                                    f"<!-- ·∫¢nh {i+1}: {uploaded_image.name} -->\n{latex_result}\n"
                                )
                            else:
                                st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ x·ª≠ l√Ω ·∫£nh {uploaded_image.name}")
                        except Exception as e:
                            st.error(f"‚ùå L·ªói x·ª≠ l√Ω {uploaded_image.name}: {str(e)}")
                        
                        progress_bar.progress((i + 1) / len(uploaded_images))
                    
                    status_text.text("‚úÖ Ho√†n th√†nh chuy·ªÉn ƒë·ªïi si√™u n√¢ng cao!")
                    
                    # Hi·ªÉn th·ªã k·∫øt qu·∫£
                    combined_latex = "\n".join(all_latex_content)
                    
                    st.markdown('<div class="latex-output">', unsafe_allow_html=True)
                    st.text_area("üìù K·∫øt qu·∫£ LaTeX (ƒë·ªãnh d·∫°ng chu·∫©n ${......}$):", combined_latex, height=300)
                    st.markdown('</div>', unsafe_allow_html=True)
                    
                    # Hi·ªÉn th·ªã th·ªëng k√™ v√† ·∫£nh debug (t∆∞∆°ng t·ª± PDF tab)
                    if enable_extraction:
                        total_figs = len(all_extracted_figures)
                        high_conf = len([f for f in all_extracted_figures if f['confidence'] > 80])
                        medium_conf = len([f for f in all_extracted_figures if 60 <= f['confidence'] <= 80])
                        low_conf = len([f for f in all_extracted_figures if f['confidence'] < 60])
                        
                        st.markdown(f"""
                        **üìä Th·ªëng k√™ chi ti·∫øt:**
                        - üéØ T·ªïng c·ªông: **{total_figs}** ·∫£nh/b·∫£ng ƒë√£ t√°ch
                        - <span class="confidence-high">üü¢ High confidence (>80%): {high_conf}</span>
                        - <span class="confidence-medium">üü° Medium confidence (60-80%): {medium_conf}</span>  
                        - <span class="confidence-low">üî¥ Low confidence (<60%): {low_conf}</span>
                        """, unsafe_allow_html=True)
                        
                        if show_debug and all_debug_images:
                            st.subheader("üîç Debug Si√™u N√¢ng Cao - Ph√¢n T√≠ch AI")
                            
                            for debug_img, img_name, figures in all_debug_images:
                                st.write(f"**üîç {img_name} - AI Detection Analysis:**")
                                st.image(debug_img, caption=f"AI ph√°t hi·ªán {len(figures)} v√πng", use_column_width=True)
                                
                                if figures:
                                    st.write("**üìã Chi ti·∫øt t·ª´ng v√πng ƒë√£ c·∫Øt:**")
                                    cols = st.columns(min(len(figures), 3))
                                    for idx, fig in enumerate(figures):
                                        with cols[idx % 3]:
                                            img_data = base64.b64decode(fig['base64'])
                                            img_pil = Image.open(io.BytesIO(img_data))
                                            
                                            st.markdown(f'<div class="extracted-image">', unsafe_allow_html=True)
                                            st.image(img_pil, caption=f"{fig['name']} - {fig['confidence']:.1f}%", use_column_width=True)
                                            
                                            conf_class = "confidence-high" if fig['confidence'] > 80 else "confidence-medium" if fig['confidence'] >= 60 else "confidence-low"
                                            
                                            st.markdown(f'''
                                            <div class="image-info">
                                            <strong>{fig['name']}</strong><br>
                                            üè∑Ô∏è Lo·∫°i: {"üìä B·∫£ng" if fig['is_table'] else "üñºÔ∏è H√¨nh ·∫£nh"}<br>
                                            <span class="{conf_class}">üéØ Confidence: {fig['confidence']:.1f}%</span><br>
                                            üìê T·ª∑ l·ªá: {fig['aspect_ratio']:.2f}<br>
                                            üìè K√≠ch th∆∞·ªõc: {fig['bbox'][2]}√ó{fig['bbox'][3]}px<br>
                                            üî∫ Solidity: {fig['solidity']:.2f}<br>
                                            üìä Di·ªán t√≠ch: {fig['area']:,}px¬≤
                                            </div>
                                            ''', unsafe_allow_html=True)
                                            st.markdown('</div>', unsafe_allow_html=True)
                    
                    # L∆∞u v√†o session
                    st.session_state.image_latex_content = combined_latex
                    st.session_state.image_list = all_original_images
                    st.session_state.image_extracted_figures = all_extracted_figures if enable_extraction else None
                
                # T·∫°o file Word
                if 'image_latex_content' in st.session_state:
                    st.markdown("---")
                    if st.button("üì• T·∫°o file Word (ƒë·ªãnh d·∫°ng chu·∫©n ${......}$)", key="create_word_images"):
                        with st.spinner("üîÑ ƒêang t·∫°o file Word v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n..."):
                            try:
                                extracted_figs = st.session_state.get('image_extracted_figures')
                                original_imgs = st.session_state.image_list
                                
                                word_buffer = WordExporter.create_word_document(
                                    st.session_state.image_latex_content,
                                    extracted_figures=extracted_figs,
                                    images=original_imgs
                                )
                                
                                st.download_button(
                                    label="üì• T·∫£i file Word (Ultra Enhanced)",
                                    data=word_buffer.getvalue(),
                                    file_name="images_ultra_latex.docx",
                                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                                )
                                
                                st.download_button(
                                    label="üìù T·∫£i LaTeX source (.tex)",
                                    data=st.session_state.image_latex_content,
                                    file_name="images_converted.tex",
                                    mime="text/plain"
                                )
                                
                                st.success("‚úÖ File Word v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n ${......}$ ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
                            
                            except Exception as e:
                                st.error(f"‚ùå L·ªói t·∫°o file Word: {str(e)}")
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666;'>
        <p>ƒê∆∞·ª£c ph√°t tri·ªÉn v·ªõi ‚ù§Ô∏è s·ª≠ d·ª•ng Streamlit v√† Gemini 2.0 API</p>
        <p>‚ú® <strong>Ultra Enhanced Version:</strong> AI si√™u th√¥ng minh + ƒê·ªãnh d·∫°ng LaTeX chu·∫©n ${......}$!</p>
        <p>üéØ Thu·∫≠t to√°n NMS + Multi-scale Detection + Content Analysis + Confidence Scoring</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main(), start_idx + 2)
                        if end_idx != -1:
                            # Th√™m text tr∆∞·ªõc c√¥ng th·ª©c
                            if start_idx > 0:
                                p.add_run(line[:start_idx])
                            
                            # Th√™m c√¥ng th·ª©c
                            equation = line[start_idx+2:end_idx]
                            eq_run = p.add_run(f" [{equation}] ")
                            eq_run.font.italic = True
                            eq_run.font.bold = True
                            
                            line = line[end_idx+2:]
                        else:
                            break
                    else:
                        break
                
                # Th√™m ph·∫ßn text c√≤n l·∫°i
                if line.strip():
                    p.add_run(line)
            else:
                # Th√™m ƒëo·∫°n vƒÉn b√¨nh th∆∞·ªùng
                doc.add_paragraph(line)
        
        # Th√™m ·∫£nh g·ªëc n·∫øu c√≥ (fallback)
        if images and not extracted_figures:
            doc.add_page_break()
            doc.add_heading('H√¨nh ·∫£nh g·ªëc', level=1)
            
            for i, img in enumerate(images):
                try:
                    doc.add_heading(f'H√¨nh {i+1}', level=2)
                    
                    if img.mode in ('RGBA', 'LA', 'P'):
                        img = img.convert('RGB')
                    
                    with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
                        img.save(tmp.name, 'PNG')
                        try:
                            doc.add_picture(tmp.name, width=doc.sections[0].page_width * 0.8)
                        except Exception:
                            doc.add_paragraph(f"[H√¨nh ·∫£nh {i+1} - Kh√¥ng th·ªÉ hi·ªÉn th·ªã]")
                        os.unlink(tmp.name)
                except Exception:
                    doc.add_paragraph(f"[L·ªói hi·ªÉn th·ªã h√¨nh {i+1}]")
        
        buffer = io.BytesIO()
        doc.save(buffer)
        buffer.seek(0)
        return buffer
    
    @staticmethod
    def _insert_extracted_image(doc, img_name, extracted_figures, caption_prefix):
        """Ch√®n ·∫£nh ƒë√£ t√°ch v√†o Word document"""
        if not extracted_figures:
            doc.add_paragraph(f"[{caption_prefix}: {img_name} - Kh√¥ng t√¨m th·∫•y]")
            return
        
        target_figure = None
        for fig in extracted_figures:
            if fig['name'] == img_name:
                target_figure = fig
                break
        
        if not target_figure:
            doc.add_paragraph(f"[{caption_prefix}: {img_name} - Kh√¥ng t√¨m th·∫•y]")
            return
        
        try:
            doc.add_heading(f"{caption_prefix}: {img_name}", level=3)
            
            img_data = base64.b64decode(target_figure['base64'])
            img_pil = Image.open(io.BytesIO(img_data))
            
            if img_pil.mode in ('RGBA', 'LA', 'P'):
                img_pil = img_pil.convert('RGB')
            
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as tmp:
                img_pil.save(tmp.name, 'PNG')
                try:
                    max_width = doc.sections[0].page_width * 0.8
                    doc.add_picture(tmp.name, width=max_width)
                except Exception:
                    doc.add_paragraph(f"[Kh√¥ng th·ªÉ hi·ªÉn th·ªã {img_name}]")
                os.unlink(tmp.name)
        
        except Exception as e:
            doc.add_paragraph(f"[L·ªói hi·ªÉn th·ªã {img_name}: {str(e)}]")

def validate_api_key(api_key: str) -> bool:
    """Ki·ªÉm tra t√≠nh h·ª£p l·ªá c·ªßa API key"""
    if not api_key or len(api_key) < 20:
        return False
    return re.match(r'^[A-Za-z0-9_-]+$', api_key) is not None

def format_file_size(size_bytes: int) -> str:
    """Chuy·ªÉn ƒë·ªïi k√≠ch th∆∞·ªõc file sang ƒë·ªãnh d·∫°ng human-readable"""
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB"]
    i = 0
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"

def main():
    st.markdown('<h1 class="main-header">üìù PDF/Image to LaTeX Converter - Ultra Enhanced</h1>', unsafe_allow_html=True)
    
    # Sidebar cho API key
    with st.sidebar:
        st.header("‚öôÔ∏è C√†i ƒë·∫∑t")
        api_key = st.text_input(
            "Gemini API Key", 
            type="password", 
            help="Nh·∫≠p API key t·ª´ Google AI Studio",
            placeholder="Paste your API key here..."
        )
        
        if api_key:
            if validate_api_key(api_key):
                st.success("‚úÖ API key h·ª£p l·ªá")
            else:
                st.error("‚ùå API key kh√¥ng h·ª£p l·ªá")
        
        st.markdown("---")
        
        # C√†i ƒë·∫∑t t√°ch ·∫£nh si√™u n√¢ng cao
        st.subheader("üñºÔ∏è T√°ch ·∫£nh si√™u ch√≠nh x√°c")
        enable_extraction = st.checkbox("B·∫≠t t√°ch ·∫£nh/b·∫£ng si√™u n√¢ng cao", value=True, 
                                       help="Thu·∫≠t to√°n AI t√°ch ·∫£nh v·ªõi ƒë·ªô ch√≠nh x√°c c·ª±c cao")
        
        if enable_extraction:
            st.write("**C√†i ƒë·∫∑t si√™u n√¢ng cao:**")
            min_area = st.slider("Di·ªán t√≠ch t·ªëi thi·ªÉu (%)", 0.1, 5.0, 0.3, 0.1,
                               help="% di·ªán t√≠ch ·∫£nh g·ªëc") / 100
            max_figures = st.slider("S·ªë ·∫£nh t·ªëi ƒëa", 1, 25, 12, 1)
            min_size = st.slider("K√≠ch th∆∞·ªõc t·ªëi thi·ªÉu (px)", 30, 300, 40, 10)
            padding = st.slider("Padding xung quanh (px)", 0, 30, 8, 1)
            confidence_threshold = st.slider("Ng∆∞·ª°ng confidence (%)", 30, 90, 50, 5)
            
            show_debug = st.checkbox("Hi·ªÉn th·ªã ·∫£nh debug n√¢ng cao", value=True,
                                   help="Hi·ªÉn th·ªã ·∫£nh v·ªõi confidence score v√† ph√¢n t√≠ch chi ti·∫øt")
        
        st.markdown("---")
        st.markdown("""
        ### üìã H∆∞·ªõng d·∫´n:
        1. Nh·∫≠p API key Gemini
        2. Ch·ªçn tab PDF ho·∫∑c ·∫¢nh  
        3. Upload file
        4. Ch·ªù x·ª≠ l√Ω v√† t·∫£i file Word
        
        ### üéØ T√≠nh nƒÉng si√™u n√¢ng cao:
        - ‚úÖ Thu·∫≠t to√°n AI c·∫Øt ·∫£nh v·ªõi NMS
        - ‚úÖ Confidence scoring th√¥ng minh
        - ‚úÖ ƒê·ªãnh d·∫°ng LaTeX chu·∫©n: `${......}$`
        - ‚úÖ Ph√¢n t√≠ch n·ªôi dung v√πng
        - ‚úÖ Multi-scale edge detection
        
        ### üìù ƒê·ªãnh d·∫°ng LaTeX chu·∫©n:
        **C√¥ng th·ª©c inline:** `${x^2 + y^2}$`
        
        **Tr·∫Øc nghi·ªám 4 ph∆∞∆°ng √°n:**
        ```
        C√¢u X: [n·ªôi dung]
        A. [ƒê√°p √°n]
        B. [ƒê√°p √°n]  
        C. [ƒê√°p √°n]
        D. [ƒê√°p √°n]
        ```
        
        **Tr·∫Øc nghi·ªám ƒë√∫ng sai:**
        ```
        a) [ƒê√°p √°n]
        b) [ƒê√°p √°n]
        c) [ƒê√°p √°n]
        d) [ƒê√°p √°n]
        ```
        
        ### üîë L·∫•y API Key:
        [Google AI Studio](https://makersuite.google.com/app/apikey)
        """)
    
    if not api_key:
        st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p Gemini API Key ·ªü sidebar ƒë·ªÉ b·∫Øt ƒë·∫ßu!")
        st.info("üí° B·∫°n c√≥ th·ªÉ l·∫•y API key mi·ªÖn ph√≠ t·∫°i Google AI Studio")
        return
    
    if not validate_api_key(api_key):
        st.error("‚ùå API key kh√¥ng h·ª£p l·ªá. Vui l√≤ng ki·ªÉm tra l·∫°i!")
        return
    
    # T·∫°o tabs
    tab1, tab2 = st.tabs(["üìÑ PDF to LaTeX + Ultra Extract", "üñºÔ∏è Image to LaTeX + Ultra Extract"])
    
    # Kh·ªüi t·∫°o API v√† ImageExtractor
    try:
        gemini_api = GeminiAPI(api_key)
        if enable_extraction:
            image_extractor = UltraImageExtractor()
            image_extractor.min_area_ratio = min_area
            image_extractor.max_figures = max_figures
            image_extractor.min_width = min_size
            image_extractor.min_height = min_size
            image_extractor.padding = padding
            image_extractor.confidence_threshold = confidence_threshold
    except Exception as e:
        st.error(f"‚ùå L·ªói kh·ªüi t·∫°o: {str(e)}")
        return
    
    # Tab x·ª≠ l√Ω PDF
    with tab1:
        st.header("üìÑ Chuy·ªÉn ƒë·ªïi PDF sang LaTeX + T√°ch ·∫£nh si√™u ch√≠nh x√°c")
        
        uploaded_pdf = st.file_uploader(
            "Ch·ªçn file PDF",
            type=['pdf'],
            help="Upload file PDF ch·ª©a c√¥ng th·ª©c to√°n h·ªçc v√† h√¨nh ·∫£nh"
        )
        
        if uploaded_pdf:
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.subheader("üìã Preview PDF")
                st.info(f"üìÅ File: {uploaded_pdf.name}")
                st.info(f"üìè K√≠ch th∆∞·ªõc: {format_file_size(uploaded_pdf.size)}")
                
                with st.spinner("üîÑ ƒêang x·ª≠ l√Ω PDF v·ªõi ƒë·ªô ph√¢n gi·∫£i cao..."):
                    try:
                        pdf_images = PDFProcessor.extract_images_and_text(uploaded_pdf)
                        st.success(f"‚úÖ ƒê√£ tr√≠ch xu·∫•t {len(pdf_images)} trang (3x resolution)")
                        
                        # Hi·ªÉn th·ªã preview
                        for img, page_num in pdf_images[:2]:
                            st.write(f"**Trang {page_num}:**")
                            st.image(img, use_column_width=True)
                        
                        if len(pdf_images) > 2:
                            st.info(f"... v√† {len(pdf_images) - 2} trang kh√°c")
                    
                    except Exception as e:
                        st.error(f"‚ùå L·ªói x·ª≠ l√Ω PDF: {str(e)}")
                        pdf_images = []
            
            with col2:
                st.subheader("‚ö° Chuy·ªÉn ƒë·ªïi sang LaTeX")
                
                if st.button("üöÄ B·∫Øt ƒë·∫ßu chuy·ªÉn ƒë·ªïi si√™u n√¢ng cao", key="convert_pdf"):
                    if pdf_images:
                        all_latex_content = []
                        all_extracted_figures = []
                        all_debug_images = []
                        
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        for i, (img, page_num) in enumerate(pdf_images):
                            status_text.text(f"ƒêang x·ª≠ l√Ω trang {page_num}/{len(pdf_images)} v·ªõi AI si√™u n√¢ng cao...")
                            
                            # Chuy·ªÉn ·∫£nh th√†nh bytes
                            img_buffer = io.BytesIO()
                            img.save(img_buffer, format='PNG')
                            img_bytes = img_buffer.getvalue()
                            
                            # T√°ch ·∫£nh/b·∫£ng n·∫øu ƒë∆∞·ª£c b·∫≠t
                            extracted_figures = []
                            if enable_extraction:
                                try:
                                    figures, h, w = image_extractor.extract_figures_and_tables(img_bytes)
                                    extracted_figures = figures
                                    all_extracted_figures.extend(figures)
                                    
                                    # T·∫°o ·∫£nh debug
                                    if show_debug and figures:
                                        debug_img = image_extractor.create_debug_image(img_bytes, figures)
                                        all_debug_images.append((debug_img, page_num, figures))
                                    
                                    high_conf = len([f for f in figures if f['confidence'] > 80])
                                    st.write(f"üéØ Trang {page_num}: T√°ch ƒë∆∞·ª£c {len(figures)} ·∫£nh/b·∫£ng (High conf: {high_conf})")
                                    
                                except Exception as e:
                                    st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t√°ch ·∫£nh trang {page_num}: {str(e)}")
                            
                            # T·∫°o prompt si√™u c·∫£i ti·∫øn cho Gemini
                            prompt = f"""
H√£y chuy·ªÉn ƒë·ªïi T·∫§T C·∫¢ n·ªôi dung trong ·∫£nh trang {page_num} th√†nh vƒÉn b·∫£n thu·∫ßn t√∫y v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n.

üéØ QUAN TR·ªåNG - CH·ªà XU·∫§T RA V√ÑN B·∫¢N THU·∫¶N T√öY, KH√îNG D√ôNG ```latex hay markdown:

üìù ƒê·ªäNH D·∫†NG B·∫ÆT BU·ªòC:

1. **Tr·∫Øc nghi·ªám 4 ph∆∞∆°ng √°n - ƒë·ªãnh d·∫°ng ch√≠nh x√°c:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß]
A. [ƒë√°p √°n A chi ti·∫øt]
B. [ƒë√°p √°n B chi ti·∫øt]  
C. [ƒë√°p √°n C chi ti·∫øt]
D. [ƒë√°p √°n D chi ti·∫øt]

2. **Tr·∫Øc nghi·ªám ƒë√∫ng sai - ƒë·ªãnh d·∫°ng ch√≠nh x√°c:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi n·∫øu c√≥]
a) [n·ªôi dung ƒë√°p √°n a ƒë·∫ßy ƒë·ªß]
b) [n·ªôi dung ƒë√°p √°n b ƒë·∫ßy ƒë·ªß]  
c) [n·ªôi dung ƒë√°p √°n c ƒë·∫ßy ƒë·ªß]
d) [n·ªôi dung ƒë√°p √°n d ƒë·∫ßy ƒë·ªß]

3. **Tr·∫£ l·ªùi ng·∫Øn/T·ª± lu·∫≠n:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß]

4. **C√¥ng th·ª©c to√°n h·ªçc - TUY·ªÜT ƒê·ªêI QUAN TR·ªåNG:**
- **CH·ªà s·ª≠ d·ª•ng ƒë·ªãnh d·∫°ng:** ${{x^2 + y^2}}$ cho M·ªåI c√¥ng th·ª©c
- **V√ç D·ª§ ƒê√öNG:** ${{\\frac{{a+b}}{{c-d}}}}$, ${{\\int_0^1 x dx}}$, ${{\\sqrt{{x^2+1}}}}$, ${{\\perp}}$, ${{\\parallel}}$
- **TUY·ªÜT ƒê·ªêI KH√îNG d√πng:** ```latex, $...$, $...$, hay b·∫•t k·ª≥ markdown n√†o

5. **K√Ω hi·ªáu ƒë·∫∑c bi·ªát:**
- Vu√¥ng g√≥c: ${{\\perp}}$
- Song song: ${{\\parallel}}$ ho·∫∑c //
- G√≥c: ${{\\angle}}$ ho·∫∑c d√πng t·ª´ "g√≥c"
- ƒê·ªô: ¬∞ ho·∫∑c ${{^\\circ}}$

6. **H√¨nh ·∫£nh v√† b·∫£ng:**
{'- Khi th·∫•y h√¨nh ·∫£nh/ƒë·ªì th·ªã: d√πng "xem h√¨nh", "theo h√¨nh", "h√¨nh sau"' if enable_extraction else ''}
{'- Khi th·∫•y b·∫£ng: d√πng "b·∫£ng sau", "theo b·∫£ng", "quan s√°t b·∫£ng"' if enable_extraction else ''}

‚ö†Ô∏è L∆ØU √ù QUAN TR·ªåNG:
- KH√îNG xu·∫•t ra ```latex hay b·∫•t k·ª≥ code block n√†o
- KH√îNG d√πng markdown formatting
- CH·ªà xu·∫•t ra vƒÉn b·∫£n thu·∫ßn t√∫y v·ªõi c√¥ng th·ª©c ${{...}}$
- Gi·ªØ CH√çNH X√ÅC 100% th·ª© t·ª± v√† c·∫•u tr√∫c n·ªôi dung
- Bao g·ªìm T·∫§T C·∫¢ text, s·ªë, k√Ω hi·ªáu v√† c√¥ng th·ª©c t·ª´ ·∫£nh
- Vi·∫øt ƒë·∫ßy ƒë·ªß n·ªôi dung, kh√¥ng r√∫t g·ªçn ho·∫∑c t√≥m t·∫Øt

V√ç D·ª§ OUTPUT ƒê√öNG:
C√¢u 64: Trong h√¨nh h·ªôp ${{ABCD.A'B'C'D'}}$ c√≥ t·∫•t c·∫£ c√°c c·∫°nh ƒë·ªÅu b·∫±ng nhau. X√©t t√≠nh ƒë√∫ng sai c·ªßa c√°c kh·∫≥ng ƒë·ªãnh sau:
a) ${{ABCD}}$ l√† h√¨nh ch·ªØ nh·∫≠t.
b) ${{A'C' \\perp BD}}$
c) ${{A'B \\perp D'C}}$  
d) ${{BC' \\perp A'D}}$
"""
                            
                            # G·ªçi API
                            try:
                                latex_result = gemini_api.convert_to_latex(img_bytes, "image/png", prompt)
                                if latex_result:
                                    # Ch√®n ·∫£nh v√†o vƒÉn b·∫£n n·∫øu c√≥ t√°ch ·∫£nh
                                    if enable_extraction and extracted_figures:
                                        latex_result = image_extractor.insert_figures_into_text(
                                            latex_result, extracted_figures, h, w
                                        )
                                    
                                    all_latex_content.append(f"<!-- Trang {page_num} -->\n{latex_result}\n")
                                else:
                                    st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ x·ª≠ l√Ω trang {page_num}")
                            except Exception as e:
                                st.error(f"‚ùå L·ªói x·ª≠ l√Ω trang {page_num}: {str(e)}")
                            
                            progress_bar.progress((i + 1) / len(pdf_images))
                        
                        status_text.text("‚úÖ Ho√†n th√†nh chuy·ªÉn ƒë·ªïi si√™u n√¢ng cao!")
                        
                        # Hi·ªÉn th·ªã k·∫øt qu·∫£
                        combined_latex = "\n".join(all_latex_content)
                        
                        st.markdown('<div class="latex-output">', unsafe_allow_html=True)
                        st.text_area("üìù K·∫øt qu·∫£ LaTeX (ƒë·ªãnh d·∫°ng chu·∫©n ${......}$):", combined_latex, height=300)
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                        # Hi·ªÉn th·ªã th·ªëng k√™ chi ti·∫øt
                        if enable_extraction:
                            total_figs = len(all_extracted_figures)
                            high_conf = len([f for f in all_extracted_figures if f['confidence'] > 80])
                            medium_conf = len([f for f in all_extracted_figures if 60 <= f['confidence'] <= 80])
                            low_conf = len([f for f in all_extracted_figures if f['confidence'] < 60])
                            
                            st.markdown(f"""
                            **üìä Th·ªëng k√™ chi ti·∫øt:**
                            - üéØ T·ªïng c·ªông: **{total_figs}** ·∫£nh/b·∫£ng ƒë√£ t√°ch
                            - <span class="confidence-high">üü¢ High confidence (>80%): {high_conf}</span>
                            - <span class="confidence-medium">üü° Medium confidence (60-80%): {medium_conf}</span>  
                            - <span class="confidence-low">üî¥ Low confidence (<60%): {low_conf}</span>
                            """, unsafe_allow_html=True)
                            
                            # Hi·ªÉn th·ªã ·∫£nh debug v√† ·∫£nh ƒë√£ c·∫Øt
                            if show_debug and all_debug_images:
                                st.subheader("üîç Debug Si√™u N√¢ng Cao - Ph√¢n T√≠ch AI")
                                
                                for debug_img, page_num, figures in all_debug_images:
                                    st.write(f"**üîç Trang {page_num} - AI Detection Analysis:**")
                                    st.image(debug_img, caption=f"AI ph√°t hi·ªán {len(figures)} v√πng v·ªõi confidence scores", use_column_width=True)
                                    
                                    # Hi·ªÉn th·ªã t·ª´ng ·∫£nh ƒë√£ c·∫Øt v·ªõi th√¥ng tin si√™u chi ti·∫øt
                                    if figures:
                                        st.write("**üìã Chi ti·∫øt t·ª´ng v√πng ƒë√£ c·∫Øt:**")
                                        cols = st.columns(min(len(figures), 3))
                                        for idx, fig in enumerate(figures):
                                            with cols[idx % 3]:
                                                # Decode v√† hi·ªÉn th·ªã ·∫£nh c·∫Øt
                                                img_data = base64.b64decode(fig['base64'])
                                                img_pil = Image.open(io.BytesIO(img_data))
                                                
                                                st.markdown(f'<div class="extracted-image">', unsafe_allow_html=True)
                                                st.image(img_pil, caption=f"{fig['name']} - {fig['confidence']:.1f}%", use_column_width=True)
                                                
                                                # X√°c ƒë·ªãnh m√†u confidence
                                                conf_class = "confidence-high" if fig['confidence'] > 80 else "confidence-medium" if fig['confidence'] >= 60 else "confidence-low"
                                                
                                                # Th√¥ng tin si√™u chi ti·∫øt
                                                st.markdown(f'''
                                                <div class="image-info">
                                                <strong>{fig['name']}</strong><br>
                                                üè∑Ô∏è Lo·∫°i: {"üìä B·∫£ng" if fig['is_table'] else "üñºÔ∏è H√¨nh ·∫£nh"}<br>
                                                <span class="{conf_class}">üéØ Confidence: {fig['confidence']:.1f}%</span><br>
                                                üìê T·ª∑ l·ªá: {fig['aspect_ratio']:.2f}<br>
                                                üìè K√≠ch th∆∞·ªõc: {fig['bbox'][2]}√ó{fig['bbox'][3]}px<br>
                                                üî∫ Solidity: {fig['solidity']:.2f}<br>
                                                üìä Di·ªán t√≠ch: {fig['area']:,}px¬≤<br>
                                                {'üîç Ph√¢n t√≠ch: ' + str(fig.get('content_analysis', {}).get('has_lines', 0)) + ' ƒë∆∞·ªùng k·∫ª' if 'content_analysis' in fig else ''}
                                                </div>
                                                ''', unsafe_allow_html=True)
                                                st.markdown('</div>', unsafe_allow_html=True)
                        
                        # L∆∞u v√†o session state
                        st.session_state.pdf_latex_content = combined_latex
                        st.session_state.pdf_images = [img for img, _ in pdf_images]
                        st.session_state.pdf_extracted_figures = all_extracted_figures if enable_extraction else None
                
                # T·∫°o file Word
                if 'pdf_latex_content' in st.session_state:
                    st.markdown("---")
                    if st.button("üì• T·∫°o file Word (ƒë·ªãnh d·∫°ng chu·∫©n ${......}$)", key="create_word_pdf"):
                        with st.spinner("üîÑ ƒêang t·∫°o file Word v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n..."):
                            try:
                                extracted_figs = st.session_state.get('pdf_extracted_figures')
                                original_imgs = st.session_state.pdf_images
                                
                                word_buffer = WordExporter.create_word_document(
                                    st.session_state.pdf_latex_content, 
                                    extracted_figures=extracted_figs,
                                    images=original_imgs
                                )
                                
                                filename = f"{uploaded_pdf.name.split('.')[0]}_ultra_latex.docx"
                                
                                st.download_button(
                                    label="üì• T·∫£i file Word (Ultra Enhanced)",
                                    data=word_buffer.getvalue(),
                                    file_name=filename,
                                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                                )
                                
                                st.download_button(
                                    label="üìù T·∫£i LaTeX source (.tex)",
                                    data=st.session_state.pdf_latex_content,
                                    file_name=uploaded_pdf.name.replace('.pdf', '.tex'),
                                    mime="text/plain"
                                )
                                
                                st.success("‚úÖ File Word v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n ${......}$ ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
                            
                            except Exception as e:
                                st.error(f"‚ùå L·ªói t·∫°o file Word: {str(e)}")
    
    # Tab x·ª≠ l√Ω ·∫£nh (t∆∞∆°ng t·ª± nh∆∞ PDF tab)
    with tab2:
        st.header("üñºÔ∏è Chuy·ªÉn ƒë·ªïi ·∫¢nh sang LaTeX + T√°ch ·∫£nh si√™u ch√≠nh x√°c")
        
        uploaded_images = st.file_uploader(
            "Ch·ªçn ·∫£nh (c√≥ th·ªÉ ch·ªçn nhi·ªÅu)",
            type=['png', 'jpg', 'jpeg', 'bmp', 'tiff'],
            accept_multiple_files=True,
            help="Upload ·∫£nh ch·ª©a c√¥ng th·ª©c to√°n h·ªçc v√† h√¨nh minh h·ªça"
        )
        
        if uploaded_images:
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.subheader("üñºÔ∏è Preview ·∫¢nh")
                
                total_size = sum(img.size for img in uploaded_images)
                st.info(f"üìÅ S·ªë ·∫£nh: {len(uploaded_images)}")
                st.info(f"üìè T·ªïng k√≠ch th∆∞·ªõc: {format_file_size(total_size)}")
                
                for i, uploaded_image in enumerate(uploaded_images[:2]):
                    st.write(f"**·∫¢nh {i+1}: {uploaded_image.name}**")
                    image = Image.open(uploaded_image)
                    st.image(image, use_column_width=True)
                
                if len(uploaded_images) > 2:
                    st.info(f"... v√† {len(uploaded_images) - 2} ·∫£nh kh√°c")
            
            with col2:
                st.subheader("‚ö° Chuy·ªÉn ƒë·ªïi sang LaTeX")
                
                if st.button("üöÄ B·∫Øt ƒë·∫ßu chuy·ªÉn ƒë·ªïi si√™u n√¢ng cao", key="convert_images"):
                    all_latex_content = []
                    all_extracted_figures = []
                    all_original_images = []
                    all_debug_images = []
                    
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    for i, uploaded_image in enumerate(uploaded_images):
                        status_text.text(f"ƒêang x·ª≠ l√Ω ·∫£nh {i+1}/{len(uploaded_images)} v·ªõi AI si√™u n√¢ng cao...")
                        
                        image_bytes = uploaded_image.getvalue()
                        image_pil = Image.open(uploaded_image)
                        all_original_images.append(image_pil)
                        
                        # T√°ch ·∫£nh/b·∫£ng n·∫øu ƒë∆∞·ª£c b·∫≠t
                        extracted_figures = []
                        if enable_extraction:
                            try:
                                figures, h, w = image_extractor.extract_figures_and_tables(image_bytes)
                                extracted_figures = figures
                                all_extracted_figures.extend(figures)
                                
                                # T·∫°o ·∫£nh debug
                                if show_debug and figures:
                                    debug_img = image_extractor.create_debug_image(image_bytes, figures)
                                    all_debug_images.append((debug_img, uploaded_image.name, figures))
                                
                                high_conf = len([f for f in figures if f['confidence'] > 80])
                                st.write(f"üéØ {uploaded_image.name}: T√°ch ƒë∆∞·ª£c {len(figures)} ·∫£nh/b·∫£ng (High conf: {high_conf})")
                            except Exception as e:
                                st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t√°ch ·∫£nh {uploaded_image.name}: {str(e)}")
                        
                        prompt = """
H√£y chuy·ªÉn ƒë·ªïi T·∫§T C·∫¢ n·ªôi dung trong ·∫£nh th√†nh vƒÉn b·∫£n thu·∫ßn t√∫y v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n.

üéØ QUAN TR·ªåNG - CH·ªà XU·∫§T RA V√ÑN B·∫¢N THU·∫¶N T√öY, KH√îNG D√ôNG ```latex hay markdown:

üìù ƒê·ªäNH D·∫†NG B·∫ÆT BU·ªòC:

1. **Tr·∫Øc nghi·ªám 4 ph∆∞∆°ng √°n - ƒë·ªãnh d·∫°ng ch√≠nh x√°c:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß]
A. [ƒë√°p √°n A chi ti·∫øt]
B. [ƒë√°p √°n B chi ti·∫øt]  
C. [ƒë√°p √°n C chi ti·∫øt]
D. [ƒë√°p √°n D chi ti·∫øt]

2. **Tr·∫Øc nghi·ªám ƒë√∫ng sai - ƒë·ªãnh d·∫°ng ch√≠nh x√°c:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi n·∫øu c√≥]
a) [n·ªôi dung ƒë√°p √°n a ƒë·∫ßy ƒë·ªß]
b) [n·ªôi dung ƒë√°p √°n b ƒë·∫ßy ƒë·ªß]  
c) [n·ªôi dung ƒë√°p √°n c ƒë·∫ßy ƒë·ªß]
d) [n·ªôi dung ƒë√°p √°n d ƒë·∫ßy ƒë·ªß]

3. **Tr·∫£ l·ªùi ng·∫Øn/T·ª± lu·∫≠n:**
C√¢u X: [n·ªôi dung c√¢u h·ªèi ƒë·∫ßy ƒë·ªß]

4. **C√¥ng th·ª©c to√°n h·ªçc - TUY·ªÜT ƒê·ªêI QUAN TR·ªåNG:**
- **CH·ªà s·ª≠ d·ª•ng ƒë·ªãnh d·∫°ng:** ${x^2 + y^2}$ cho M·ªåI c√¥ng th·ª©c
- **V√ç D·ª§ ƒê√öNG:** ${\\frac{a+b}{c-d}}$, ${\\int_0^1 x dx}$, ${\\sqrt{x^2+1}}$, ${\\perp}$, ${\\parallel}$
- **TUY·ªÜT ƒê·ªêI KH√îNG d√πng:** ```latex, $...$, $...$, hay b·∫•t k·ª≥ markdown n√†o

5. **K√Ω hi·ªáu ƒë·∫∑c bi·ªát:**
- Vu√¥ng g√≥c: ${\\perp}$
- Song song: ${\\parallel}$ ho·∫∑c //
- G√≥c: ${\\angle}$ ho·∫∑c d√πng t·ª´ "g√≥c"
- ƒê·ªô: ¬∞ ho·∫∑c ${^\\circ}$

‚ö†Ô∏è L∆ØU √ù QUAN TR·ªåNG:
- KH√îNG xu·∫•t ra ```latex hay b·∫•t k·ª≥ code block n√†o
- KH√îNG d√πng markdown formatting
- CH·ªà xu·∫•t ra vƒÉn b·∫£n thu·∫ßn t√∫y v·ªõi c√¥ng th·ª©c ${...}$
- Gi·ªØ CH√çNH X√ÅC 100% th·ª© t·ª± v√† c·∫•u tr√∫c n·ªôi dung
- Bao g·ªìm T·∫§T C·∫¢ text, s·ªë, k√Ω hi·ªáu v√† c√¥ng th·ª©c t·ª´ ·∫£nh
- Vi·∫øt ƒë·∫ßy ƒë·ªß n·ªôi dung, kh√¥ng r√∫t g·ªçn ho·∫∑c t√≥m t·∫Øt

V√ç D·ª§ OUTPUT ƒê√öNG:
C√¢u 64: Trong h√¨nh h·ªôp ${ABCD.A'B'C'D'}$ c√≥ t·∫•t c·∫£ c√°c c·∫°nh ƒë·ªÅu b·∫±ng nhau. X√©t t√≠nh ƒë√∫ng sai c·ªßa c√°c kh·∫≥ng ƒë·ªãnh sau:
a) ${ABCD}$ l√† h√¨nh ch·ªØ nh·∫≠t.
b) ${A'C' \\perp BD}$
c) ${A'B \\perp D'C}$  
d) ${BC' \\perp A'D}$
"""
                        
                        try:
                            latex_result = gemini_api.convert_to_latex(
                                image_bytes, uploaded_image.type, prompt
                            )
                            if latex_result:
                                # Ch√®n ·∫£nh v√†o vƒÉn b·∫£n n·∫øu c√≥ t√°ch ·∫£nh
                                if enable_extraction and extracted_figures:
                                    latex_result = image_extractor.insert_figures_into_text(
                                        latex_result, extracted_figures, h, w
                                    )
                                
                                all_latex_content.append(
                                    f"<!-- ·∫¢nh {i+1}: {uploaded_image.name} -->\n{latex_result}\n"
                                )
                            else:
                                st.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ x·ª≠ l√Ω ·∫£nh {uploaded_image.name}")
                        except Exception as e:
                            st.error(f"‚ùå L·ªói x·ª≠ l√Ω {uploaded_image.name}: {str(e)}")
                        
                        progress_bar.progress((i + 1) / len(uploaded_images))
                    
                    status_text.text("‚úÖ Ho√†n th√†nh chuy·ªÉn ƒë·ªïi si√™u n√¢ng cao!")
                    
                    # Hi·ªÉn th·ªã k·∫øt qu·∫£
                    combined_latex = "\n".join(all_latex_content)
                    
                    st.markdown('<div class="latex-output">', unsafe_allow_html=True)
                    st.text_area("üìù K·∫øt qu·∫£ LaTeX (ƒë·ªãnh d·∫°ng chu·∫©n ${......}$):", combined_latex, height=300)
                    st.markdown('</div>', unsafe_allow_html=True)
                    
                    # Hi·ªÉn th·ªã th·ªëng k√™ v√† ·∫£nh debug (t∆∞∆°ng t·ª± PDF tab)
                    if enable_extraction:
                        total_figs = len(all_extracted_figures)
                        high_conf = len([f for f in all_extracted_figures if f['confidence'] > 80])
                        medium_conf = len([f for f in all_extracted_figures if 60 <= f['confidence'] <= 80])
                        low_conf = len([f for f in all_extracted_figures if f['confidence'] < 60])
                        
                        st.markdown(f"""
                        **üìä Th·ªëng k√™ chi ti·∫øt:**
                        - üéØ T·ªïng c·ªông: **{total_figs}** ·∫£nh/b·∫£ng ƒë√£ t√°ch
                        - <span class="confidence-high">üü¢ High confidence (>80%): {high_conf}</span>
                        - <span class="confidence-medium">üü° Medium confidence (60-80%): {medium_conf}</span>  
                        - <span class="confidence-low">üî¥ Low confidence (<60%): {low_conf}</span>
                        """, unsafe_allow_html=True)
                        
                        if show_debug and all_debug_images:
                            st.subheader("üîç Debug Si√™u N√¢ng Cao - Ph√¢n T√≠ch AI")
                            
                            for debug_img, img_name, figures in all_debug_images:
                                st.write(f"**üîç {img_name} - AI Detection Analysis:**")
                                st.image(debug_img, caption=f"AI ph√°t hi·ªán {len(figures)} v√πng", use_column_width=True)
                                
                                if figures:
                                    st.write("**üìã Chi ti·∫øt t·ª´ng v√πng ƒë√£ c·∫Øt:**")
                                    cols = st.columns(min(len(figures), 3))
                                    for idx, fig in enumerate(figures):
                                        with cols[idx % 3]:
                                            img_data = base64.b64decode(fig['base64'])
                                            img_pil = Image.open(io.BytesIO(img_data))
                                            
                                            st.markdown(f'<div class="extracted-image">', unsafe_allow_html=True)
                                            st.image(img_pil, caption=f"{fig['name']} - {fig['confidence']:.1f}%", use_column_width=True)
                                            
                                            conf_class = "confidence-high" if fig['confidence'] > 80 else "confidence-medium" if fig['confidence'] >= 60 else "confidence-low"
                                            
                                            st.markdown(f'''
                                            <div class="image-info">
                                            <strong>{fig['name']}</strong><br>
                                            üè∑Ô∏è Lo·∫°i: {"üìä B·∫£ng" if fig['is_table'] else "üñºÔ∏è H√¨nh ·∫£nh"}<br>
                                            <span class="{conf_class}">üéØ Confidence: {fig['confidence']:.1f}%</span><br>
                                            üìê T·ª∑ l·ªá: {fig['aspect_ratio']:.2f}<br>
                                            üìè K√≠ch th∆∞·ªõc: {fig['bbox'][2]}√ó{fig['bbox'][3]}px<br>
                                            üî∫ Solidity: {fig['solidity']:.2f}<br>
                                            üìä Di·ªán t√≠ch: {fig['area']:,}px¬≤
                                            </div>
                                            ''', unsafe_allow_html=True)
                                            st.markdown('</div>', unsafe_allow_html=True)
                    
                    # L∆∞u v√†o session
                    st.session_state.image_latex_content = combined_latex
                    st.session_state.image_list = all_original_images
                    st.session_state.image_extracted_figures = all_extracted_figures if enable_extraction else None
                
                # T·∫°o file Word
                if 'image_latex_content' in st.session_state:
                    st.markdown("---")
                    if st.button("üì• T·∫°o file Word (ƒë·ªãnh d·∫°ng chu·∫©n ${......}$)", key="create_word_images"):
                        with st.spinner("üîÑ ƒêang t·∫°o file Word v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n..."):
                            try:
                                extracted_figs = st.session_state.get('image_extracted_figures')
                                original_imgs = st.session_state.image_list
                                
                                word_buffer = WordExporter.create_word_document(
                                    st.session_state.image_latex_content,
                                    extracted_figures=extracted_figs,
                                    images=original_imgs
                                )
                                
                                st.download_button(
                                    label="üì• T·∫£i file Word (Ultra Enhanced)",
                                    data=word_buffer.getvalue(),
                                    file_name="images_ultra_latex.docx",
                                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                                )
                                
                                st.download_button(
                                    label="üìù T·∫£i LaTeX source (.tex)",
                                    data=st.session_state.image_latex_content,
                                    file_name="images_converted.tex",
                                    mime="text/plain"
                                )
                                
                                st.success("‚úÖ File Word v·ªõi ƒë·ªãnh d·∫°ng chu·∫©n ${......}$ ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
                            
                            except Exception as e:
                                st.error(f"‚ùå L·ªói t·∫°o file Word: {str(e)}")
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666;'>
        <p>ƒê∆∞·ª£c ph√°t tri·ªÉn v·ªõi ‚ù§Ô∏è s·ª≠ d·ª•ng Streamlit v√† Gemini 2.0 API</p>
        <p>‚ú® <strong>Ultra Enhanced Version:</strong> AI si√™u th√¥ng minh + ƒê·ªãnh d·∫°ng LaTeX chu·∫©n ${......}$!</p>
        <p>üéØ Thu·∫≠t to√°n NMS + Multi-scale Detection + Content Analysis + Confidence Scoring</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
